{"pages":[{"url":"about/","text":"Это новая версия блога, на pelican . Cтарую версию по прежнему можно найти по ссылке: https://metajiji.blogspot.com/","tags":"pages","title":"About"},{"url":"blog/fedora-chromium-firefox-flashplayer/","text":"Install Adobe repository: sudo dnf install http://linuxdownload.adobe.com/adobe-release/adobe-release-x86_64-1.0-1.noarch.rpm Find and install required package for chromium-browser : dnf provides */libpepflashplayer.so sudo dnf install flash-player-ppapi Activate PepperFlash plugin in chromium-browser: sudo ln -s /usr/lib64/flash-plugin/libpepflashplayer.so /usr/lib64/chromium-browser/PepperFlash/libpepflashplayer.so sudo ln -s /usr/lib64/flash-plugin/manifest.json /usr/lib64/chromium-browser/PepperFlash/manifest.json Install package for firefox : sudo dnf install flash-plugin For Firefox just do sudo dnf install http://linuxdownload.adobe.com/adobe-release/adobe-release-x86_64-1.0-1.noarch.rpm https://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-stable.noarch.rpm https://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-stable.noarch.rpm sudo dnf install flash-plugin freshplayerplugin LINKS [Sticky] How do I install Adobe Flash on Fedora? Install Flash Player in five easy steps Adobe Flash Player 25 on Fedora 25/24, CentOS/RHEL 7.3/6.9/5.11","tags":"Fedora","title":"Fedora 25 install adobe flashplayer"},{"url":"blog/atlassian-crowd-jni-native-lib/","text":"Install Requirements yum install -y gcc make apr-devel Download oracle jdk tar.gz file and extract to /opt, create symlink for convenience: cd /opt tar -xf jdk-8u121-linux-x64.tar.gz ln -s jdk1.8.0_121 jdk-latest Now, for upgrade jdk, just extract new tar.gz file and update symlink to new jdk folder. Extract and build jni-native library cd crowd/apache-tomcat/bin tar -xf tomcat-native.tar.gz cd tomcat-native-1.1.33-src/jni/native JAVA_HOME = /opt/jdk-latest ./configure --with-apr = /usr/bin/apr-1-config make Now we have builded jni native so library in .libs folder, if no errors. Use APR library. Add correct java.library.path option in startup script: Create configuration file /etc/default/crowd if you use my systemd unit for start crowd (link below): JAVA_OPTS = \"-Djava.library.path=/opt/atlassian/crowd/apache-tomcat/bin/tomcat-native-1.1.33-src/jni/native/.libs\" Alternatively edit the /opt/atlassian/crowd/apache-tomcat/bin/setenv.sh and add this to JAVA_OPTS : -Djava.library.path = /opt/atlassian/crowd/apache-tomcat/bin/tomcat-native-1.1.33-src/jni/native/.libs \" Ссылки по теме: Setting Crowd to Run Automatically and Use an Unprivileged System User on UNIX","tags":"Atlassian","title":"Atlassian crowd apache tomcat jni native lib"},{"url":"blog/atlassian-crowd-systemd/","text":"Create systemd service unit in /etc/systemd/system/crowd.service : [Unit] Description = Crowd After = network.target [Service] Type = oneshot RemainAfterExit = yes User = nobody Group = nobody Environment = JAVA_HOME=/opt/jdk-latest Environment = PATH=/opt/jdk-latest/bin:/usr/sbin:/usr/bin EnvironmentFile = -/etc/default/crowd WorkingDirectory = /opt/atlassian/crowd ExecStart = /bin/sh start_crowd.sh ExecStop = /bin/sh stop_crowd.sh [Install] WantedBy = multi-user.target Create configuration file /etc/default/crowd : JAVA_OPTS = \"\" Enable and start service unit on system start: systemctl enable crowd.service systemctl start crowd.service Ссылки по теме: Setting Crowd to Run Automatically and Use an Unprivileged System User on UNIX","tags":"Atlassian","title":"Atlassian crowd systemd unit"},{"url":"blog/flash-player-chrome-incognito/","text":"Flash player now working in chrome private window (incognito), solution is simple stupid! Just open chrome://flags/#prefer-html-over-flash and change the Prefer HTML over Flash dropdown box to disabled . LINKS https://forums.adobe.com/thread/2298071 chrome://flags/#prefer-html-over-flash","tags":"Fedora","title":"Flash player not working in chrome incognito."},{"url":"blog/fedora-nvidia-driver/","text":"Install RPMFusion repository sudo dnf install https://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-stable.noarch.rpm https://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-stable.noarch.rpm Important! Upgrade to latest versions kernel and SELinux packages sudo dnf update kernel* selinux-policy* Install required packages sudo dnf install gcc kernel-headers kernel-devel Install Nvidia drivers sudo dnf install akmod-nvidia xorg-x11-drv-nvidia-304xx xorg-x11-drv-nvidia-304xx-libs Check akmod module sudo akmods Rebuild initramfs sudo dracut -f /boot/initramfs- $( uname -r ) .img $( uname -r ) Known issues Black screen Disable nouveau driver GRUB_CMDLINE_LINUX = \"... rd.drivers.blacklist=nouveau nouveau.modeset=0 ...\" LINKS https://sys-adm.in/os/nix/425-fedora-install-nvidia-driver.html https://rpmfusion.org/Howto/NVIDIA","tags":"Fedora","title":"Fedora - install Nvidia driver"},{"url":"blog/centos7-elrepo-kernel-latest-stable/","text":"Устанавливаем актуальную версию ядра в CentOS 7. Добавляем репозиторий elrepo-kernel из elrepo-release : rpm -- import https : // www . elrepo . org / RPM - GPG - KEY - elrepo . org yum install http : // www . elrepo . org / elrepo - release - 7.0 - 2. el7 . elrepo . noarch . rpm Включаем репозиторий elrepo-kernel : yum install -y yum-utils yum-config-manager --enable elrepo-kernel Установка (какая сейчас актуальная версия смотреть тут https://www.kernel.org/) Перед установкой важно понимать следующее: Нет необходимости устанавливать пакет kernel-lt-firmware или kernel-ml-firmware . В дистрибутивном пакете linux-firmware содержится больше файлов прошивки, чем в пакете kernel-lt-firmware или kernel-ml-firmware . Нет необходимости устанавливать пакет kernel-lt-headers или kernel-ml-headers . Это необходимо, только если вы собираетесь пересобрать glibc и следовательно, всю операционную систему. Если необходимо, чтобы заголовки ядра были установлены, вы должны использовать текущий пакет kernel-headers из вашего дистрибутива, поскольку это связано с текущей версией glibc . Текущая стабильная (latest stable mainline kernel) версия ядра: yum install -y kernel-ml LTS (Long Term Support) версия ядра (предпочтительнее): yum install -y kernel-lt Автозагрузка нового ядра Необходимо убедиться в том, что новая версия ядра установлена и добавлена в загрузчик: awk -F\"'|\\\"\" '/&#94;menuentry/&&/elrepo/{print $2}' /boot/grub2/grub.cfg Должно получиться примерно следующее: CentOS Linux (4.4.70-1.el7.elrepo.x86_64) 7 (Core) На всякий случай проверим какое ядро загружется по умолчанию, для этого проверим каким образом grub выбирает ядро для загруки: grep GRUB_DEFAULT /etc/default/grub Должно быть: GRUB_DEFAULT=saved , если отличается, приводим к этому виду. Это означает, что будет загружена последняя сохраненная версия. Узнать какая версия ядра была загружена последней можно при помощи следующей команды: grub2-editenv list В ответ получим примерно следующее: saved_entry=CentOS Linux (3.10.0-514.21.1.el7.x86_64) 7 (Core) В моем случае грузится старое 3.10 . Изменим загружаемое по умолчанию ядро на свеже-установленное (которое получали при помощи awk ): grub2-set-default 'CentOS Linux (4.4.70-1.el7.elrepo.x86_64) 7 (Core)' Убедимся, что grub выберет правильную версию ядра загружаемого по умолчанию: grub2-editenv list В моем случае я получил то, что написал в grub2-set-default : saved_entry=CentOS Linux (4.4.70-1.el7.elrepo.x86_64) 7 (Core) Сохраняем новую конфигурацию загрузчика: grub2-mkconfig -o /boot/grub2/grub.cfg Если ошибок небыло, то перезагружаем систему: reboot После того, как система перезагрузилась можно проверить текущую версию ядра: uname -r Если в ответ получим 4.4.70-1.el7.elrepo.x86_64 , значит все сделано верно. Ссылки по теме: 8.4.5. Adding, Enabling, and Disabling a Yum Repository The Community Enterprise Linux Repository The Linux Kernel Archives","tags":"CentOS","title":"Actual stable latest kernel in CentOS 7"},{"url":"blog/confluence-cron-delete-backups/","text":"Создать файл /etc/cron.daily/confluence-cleanup : #!/bin/sh ( cd /opt/atlassian/confluence.application-data/backups for f in daily-backup-*.zip ; do [ $( ls daily-backup-*.zip | wc -l ) -gt 10 ] || break rm -vf \" $f \" done ) EXITVALUE = $? if [ $EXITVALUE ! = 0 ] ; then /usr/bin/logger -t confluence \"ALERT exited abnormally with [ $EXITVALUE ]\" fi exit 0 Обазательно укажите верный путь до каталога с бекапами /opt/atlassian/confluence.application-data/backups Дать права на запуск для этого файла: chmod +x /etc/cron.daily/confluence-cleanup","tags":"Atlassian","title":"Автоматическое удаление бекапов confluence"},{"url":"blog/gitlab-smtp-not-work/","text":"When gitlab try to send email via external smtp server, sidekiq mail queue crash with error like: SSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed Fix for package installed gitlab: Edit /etc/gitlab/gitlab.rb and add: For ubuntu system wide ca bundle: gitlab_rails['smtp_ca_file'] = \"/etc/ssl/certs/ca-certificates.crt\" For centos system wide ca bundle: gitlab_rails['smtp_ca_file'] = \"/etc/pki/tls/certs/ca-bundle.crt\" Or omnibus gitlab package: gitlab_rails['smtp_ca_file'] = \"/opt/gitlab/embedded/ssl/cert.pem\" Then run gitlab-ctl reconfigure . For gitlab installed from source code : Edit file config/initializers/smtp_settings.rb : ActionMailer::Base.smtp_settings = { authentication: :login, ... # For ubuntu ca_file: \"/etc/ssl/certs/ca-certificates.crt\", # For centos #ca_file: \"/etc/pki/tls/certs/ca-bundle.crt\", } Finnaly restart gitlab service: service gitlab restart Links SSL certification error #1558 SMTP Gmail account working on gitlab but not on gitlab-ci #2143","tags":"Gitlab","title":"Gitlab SMTP not work via external smtp"},{"url":"blog/linux-enable-ip-forwarding/","text":"Debian/Ubuntu /etc/network/options : ip_forward=yes For restart network service procps : /etc/init.d/procps.sh restart RedHat /etc/sysconfig/network : FORWARD_IPV4=true","tags":"Linux","title":"Enable ip forwarding in linux"},{"url":"blog/openssl_for_check_services/","text":"Проверка шифрования SSL/TLS. Для шифрования трафика в почтовых протоколах между клиентом и сервером используется SSL/TLS в двух вариантах. Использование специальных портов, при соединении с которым сначала осуществляется установка SSL/TLS, после чего уже поверх него идет обычный почтовый трафик. Этот метод, кстати, признан устаревшим (deprecated), относительно SMTP точно. Второй вариант, более предпочтительный — соединение с обычным портом для сервиса и переход сессии в зашифрованный вид с использованием расширения STARTTLS. Для проверки работы почтового сервера поверх SSL/TLS можно использовать утилиту openssl , дальше действуя, как при обычной сессии через telnet . SMTP openssl s_client -starttls smtp -crlf -connect mail.example.com:25 openssl s_client -starttls smtp -crlf -connect mail.example.com:587 openssl s_client -crlf -connect mail.example.com:465 POP3 openssl s_client -connect mail.example.com:995 openssl s_client -starttls pop3 -crlf -connect mail.example.com:110 IMAP openssl s_client -crlf -connect mail.example.com:993 openssl s_client -starttls imap -crlf -connect mail.example.com:143 Можно явным образом указать, что использовать для шифрования, ssl3 или tls1, а также конкретные алгоритмы: openssl s_client -ssl3 -starttls smtp -crlf -connect mail.example.com:25 Посмотреть перечень поддерживаемых протоколов в вашей версии openssl : openssl ciphers -ssl3 openssl ciphers -tls1 Ссылки по теме: Диагностика почтовых протоколов","tags":"Bash","title":"Openssl for check services"},{"url":"blog/centos7-rh-python35-python/","text":"Python35 on CentOS 7 Install packages yum install -y centos-release-scl yum install -y rh-python35-python Enable rh-python35 globally for all users cat > /etc/profile.d/rh_python35.sh <<_EOF #!/bin/sh source /opt/rh/rh-python35/enable _EOF Activate without relogin . /etc/profile.d/rh_python35.sh List available scl packages scl --list Activate rh-python35 in current bash session: scl enable rh-python35 bash Or in bash scripts: export PATH =/opt / rh / rh - python35 / root / usr / bin$ { PATH :+: $ { PATH }} export LD_LIBRARY_PATH =/opt / rh / rh - python35 / root / usr / lib64$ { LD_LIBRARY_PATH :+: $ { LD_LIBRARY_PATH }} export MANPATH =/opt / rh / rh - python35 / root / usr / share / man : $ MANPATH export PKG_CONFIG_PATH =/opt / rh / rh - python35 / root / usr / lib64 / pkgconfig$ { PKG_CONFIG_PATH :+: $ { PKG_CONFIG_PATH }} export XDG_DATA_DIRS = \"/opt/rh/rh-python35/root/usr/share:${XDG_DATA_DIRS:-/usr/local/share:/usr/share}\" python --verion Or this method: . /opt/rh/rh-python35/enable Create virtualenv in Python35: Python 3 has a built-in support for virtual environments https://docs.python.org/3/library/venv.html#module-venv https://docs.python.org/3.6/whatsnew/3.6.html#id7 python3 -m venv venv Use rh-python35 in supervisor [program:app] directory = /srv/app environment = PATH=/srv/app/venv/bin:/opt/rh/rh-python35/root/usr/bin, LD_LIBRARY_PATH=/opt/rh/rh-python35/root/usr/lib64 command = /srv/app/venv/bin/gunicorn ... stdout_logfile = /srv/app/logs/%(program_name)s.log stdout_logfile_maxbytes = 5MB ; max # logfile bytes b4 rotation (default 50MB) stdout_logfile_backups = 5 ; # of stdout logfile backups (default 10) redirect_stderr = true user = nobody numprocs = 1 autostart = true autorestart = true startsecs = 5 stopwaitsecs = 60 Use rh-python35 in systemd [Unit] Description = Foo bar service Requires = nginx.service Before = nginx.service After = network.target [Service] Type = notify User = jenkins Group = jenkins Environment = LD_LIBRARY_PATH=/opt/rh/rh-python35/root/usr/lib64 Environment = PATH=/srv/app/venv/bin:/opt/rh/rh-python35/root/usr/bin WorkingDirectory = /srv/app ExecStart = /srv/app/venv/bin/uwsgi \\ --module app.wsgi \\ --http :8006 \\ ... PIDFile = /srv/app/var/run/app.pid KillMode = process Restart = always KillSignal = SIGTERM NotifyAccess = all [Install] WantedBy = multi-user.target Ссылки по теме: How to enable Software Collections (SCL) on CentOS","tags":"CentOS","title":"CentOS 7 install python 3.5 rh sclo"},{"url":"blog/centos7-rh-sclo-git/","text":"Install requirements yum install -y scl-utils centos-release-scl yum install -y sclo-git25 Enable git globally for all users cat > /etc/profile.d/sclo_git25.sh <<_EOF #!/bin/sh source /opt/rh/sclo-git25/enable source /opt/rh/sclo-git25/root/usr/share/bash-completion/completions/git _EOF Activate without relogin . /etc/profile.d/sclo_git25.sh","tags":"CentOS","title":"CentOS 7 install modern git 2.x rh sclo"},{"url":"blog/git_submodule-update/","text":"Инициализуруются подмодули так: git submodule init Синхронизируются и обновляются так: git submodule sync git submodule update Получить последние версии кода: git submodule update --recursive --remote Ссылки по теме: Управление WordPress-сайтом с помощью Git и Composer. Часть 3. Используем подмодули Git для управления темами и плагинами","tags":"VCS","title":"Обновление подмодулей git"},{"url":"blog/docker-tmpfs-systemd/","text":"Создаем override.conf для сервиса docker командой systemctl edit docker.service : [Service] ExecStartPre = /usr/bin/env install -m 711 -o root -g root -vd /var/lib/docker_ /var/lib/docker ExecStartPre = /usr/bin/env mount -t tmpfs none /var/lib/docker ExecStartPre = /usr/bin/env rsync -a /var/lib/docker_/ /var/lib/docker/ ExecStopPost = /usr/bin/env install -m 711 -o root -g root -vd /var/lib/docker_ ExecStopPost = -/usr/bin/env rsync -a /var/lib/docker/ /var/lib/docker_/ ExecStopPost = /usr/bin/env umount /var/lib/docker Где: /var/lib/docker_ - каталог для хранения образов и контейнеров на диске /var/lib/docker - tmpfs в RAM Перед запуском сервиса docker будут создаваться, при необходимости нужные для работы каталоги, затем монтируется tmpfs в /var/lib/docker после чего в этот каталог будет скопировано содержимое с диска /var/lib/docker_ . При остановке сервиса все происходи в обратной последовательности, после остановки сервиса docker данные копируются из tmpfs на диск, после чего /var/lib/docker отмонтируется, а все данные из этого каталога мгновенно уничтожаются. Таким образом при запуске сервиса автоматически файловая система контейнеров и образов помещается в RAM , а при остановке копируется на диск, чтобы при следующем запуске данные не потерялись.","tags":"Docker","title":"Docker tmpfs systemd"},{"url":"blog/lightbox-markdown-pelican/","text":"В заголовке документа lightbox: true После чего в шаблоне base.html срабатывают условия: < head > ... {% if (article and article.lightbox) %} <!-- Enable lightbox (https://github.com/dimsemenov/Magnific-Popup) --> < link href = \"//cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/magnific-popup.min.css\" rel = \"stylesheet\" > {% endif %} </ head > ... {% if (article and article.lightbox) %} <!-- Enable lightbox gallery plugin for Bootstrap (https://github.com/ashleydw/lightbox) --> < script src = \"//cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/jquery.magnific-popup.min.js\" ></ script > < script type = \"text/javascript\" > $ ( function (){ $ ( '{% if MAGNIFIC_POPUP_SELECTOR %}{{ MAGNIFIC_POPUP_SELECTOR }}{% else %}img[class*=\"mfp-\"]{% endif %}' ). magnificPopup ({ { % if MAGNIFIC_POPUP_OPTIONS % }{{ MAGNIFIC_POPUP_OPTIONS }}{ % endif % } }); }); </ script > {% endif %} </ body > А так же стоит упомянуть конфиг: # Bootstrap magnific lightbox options MAGNIFIC_POPUP_OPTIONS = ''' closeOnContentClick: true, callbacks: { elementParse: function(item){ item.src = item.el.attr('src'); // read src from img tag }, }, gallery: { enabled: true } ''' Эта строка item.src = item.el.attr('src'); помогает извлечь из тега img путь до картинки, изначально скрипт умеет извлекать только из аттрибута href тега a . При написании текстов картинки вставляется так: ![ image alt text ]( {attach}folder/image.jpg \"image title text\" ){: class=\"mfp-image center-block\"} Где: mfp-image - таким образом указывается тип встраиваемый в lightbox center-block - это стандартный bootstrap3 клас для центрирования блока по центру страницы {attach} - относительный путь от текущего документа {attach}/ - путь от корня сайта Вместо {attach} можно использовать {filename} , разница в том, что {attach} копирует \"вложения\" вместе со страницей, а {filename} не копирует, а лишь ссылается более, подробно читайте в документации pelican. Ссылки по теме: Réaliser une galerie d'images avec Pelican et Bootstrap Lightbox — A pure CSS lightbox for Pelican Magnific-Popup Magnific Popup Documentation Attaching static files","tags":"Blog","title":"lightbox markdown pelican"},{"url":"blog/screen-cheatsheet/","text":"~/.screenrc : startup_message off hardstatus alwayslastline hardstatus alwayslastline '%{gk}[ %{G}%H %{g}]%{wk}%?%-Lw%?%{=b kR}(%{W}%n*%f %t%?(%u)%?%{=b kR})%{= kw}%?%+Lw%?%?%= %{W}[%1]' vbell_msg \" *beep* \" # Bind Shift+Arrow Left/Right for switch via screen-tab's bindkey &#94;[[1;2C next bindkey &#94;[[1;2D prev Ссылки по теме: VIM + screen. Организация удаленной среды web-разработки","tags":"Bash","title":"Screen cheatsheet"},{"url":"blog/blog-moved/","text":"Перенес блог на статический генератор сайтов pelican , а в качестве хостинга решил использовать github pages .","tags":"Blog","title":"Смена движка и хостинга"},{"url":"blog/zabbix-in-linux/","text":"Problem: root@host# LC_ALL = C su -m zabbix -c \"ping ya.ru\" ping: icmp open socket: Operation not permitted Solution: sudo chmod u+s ` which ping ` Problem: sudo: sorry, you must have a tty to run sudo Solution: echo 'Defaults:zabbix !requiretty' | sudo tee -a /etc/sudoers.d/zabbix Problem: sudo: no tty present and no askpass program specified Solution: echo 'zabbix ALL=NOPASSWD:/usr/bin/nmap *' | sudo tee -a /etc/sudoers.d/zabbix","tags":"Zabbix","title":"zabbix in linux"},{"url":"blog/centos-7-broken-nfsdcltrack/","text":"После установки и настройки nfs сервера под Centos 7 в логах были обнаружены ошибки: nfsdcltrack[3706]: sqlite_insert_client: insert statement prepare failed: table clients has 2 columns but 3 values were supplied Быстрый поиск привел в багзиллу, где нашлось решение, проблема была в структуре базы, для начала нужно открыть базу: sqlite3 /var/lib/nfs/nfsdcltrack/main.sqlite Затем выполнить запрос: alter table clients add column has_session INTEGER ; . exit После чего необходимо перезапустить nfs сервер: systemctl restart nfs Ссылки по теме: Bug 1285097 - nfs-utils package broke nfsdcltrack","tags":"CentOS","title":"Centos 7 broken nfsdcltrack: sqlite_insert_client"},{"url":"blog/centos-6-install-python-27/","text":"Centos 6 install python2.7 yum install centos-release-SCL yum install python27 python27-python-virtualenv echo '/opt/rh/python27/root/usr/lib64' > /etc/ld.so.conf.d/python27.conf && ldconfig virtualenv --prompt = \"(proj_name)\" -p /opt/rh/python27/root/usr/lib/python2.7 .env А вот так лучше не стоит делать : yum install -y rubygems ruby-devel tar gem install fpm curl https://www.python.org/ftp/python/2.7.11/Python-2.7.11.tgz > Python-2.7.11.tgz tar -xvf Python-2.7.11.tgz cd Python-2.7.11 yum -y install openssl-devel readline-devel bzip2-devel sqlite-devel zlib-devel ncurses-devel db4-devel expat-devel ./configure --prefix = /usr/local --enable-unicode = ucs4 --enable-shared --enable-ipv6 make -j $( nproc ) test -d /tmp/python-2.7 || mkdir /tmp/python-2.7 make install DESTDIR = /tmp/python-2.7 echo '/sbin/ldconfig' > /tmp/python-2.7/run-ldconfig.sh test -d /tmp/python-2.7/etc/ld.so.conf.d || mkdir /tmp/python-2.7/etc/ld.so.conf.d echo '/usr/local/lib' > /tmp/python-2.7/etc/ld.so.conf.d/python27.conf fpm -s dir -t rpm -n python27 -v 2 .7.11_1 -C /tmp/python-2.7 \\ --after-install /tmp/python-2.7/run-ldconfig.sh \\ -d 'openssl' \\ -d 'bzip2' \\ -d 'zlib' \\ -d 'expat' \\ -d 'db4' \\ -d 'sqlite' \\ -d 'ncurses' \\ -d 'readline' \\ --directories = /usr/local/lib/python2.7/ \\ --directories = /usr/local/include/python2.7/ \\ usr/local etc rpm конечно же соберется и даже все будет правильно и лучше, чем просто злобный make install , но python27 есть в официальных репозиториях и лучше ставить оттуда, это избавит от необходимости собирать другие пакеты, например python-virtualenv , python-pip и другие.","tags":"CentOS","title":"Centos 6 install python 2.7"},{"url":"blog/zimbra-reject-self-domain/","text":"Prevent send SPAM emails from self domain to self domain: Modify file /opt/zimbra/conf/zmconfigd/smtpd_sender_restrictions.cf : Add string: %%contains VAR:zimbraMtaSmtpdSenderRestrictions check_sender_access lmdb:/opt/zimbra/conf/postfix_sender_access%% Result full content file: %%exact VAR:zimbraMtaSmtpdSenderRestrictions reject_authenticated_sender_login_mismatch%% %%contains VAR:zimbraMtaSmtpdSenderRestrictions check_sender_access lmdb:/opt/zimbra/conf/postfix_reject_sender%% %%contains VAR:zimbraServiceEnabled cbpolicyd&#94; check_policy_service inet:localhost:%%zimbraCBPolicydBindPort%%%% %%contains VAR:zimbraServiceEnabled amavis&#94; check_sender_access regexp:/opt/zimbra/common/conf/tag_as_originating.re%% permit_mynetworks permit_sasl_authenticated permit_tls_clientcerts %%contains VAR:zimbraMtaSmtpdSenderRestrictions check_sender_access lmdb:/opt/zimbra/conf/postfix_sender_access%% %%contains VAR:zimbraServiceEnabled amavis&#94; check_sender_access regexp:/opt/zimbra/common/conf/tag_as_foreign.re%% Create file /opt/zimbra/conf/postfix_sender_access with content: domain1.ltd REJECT Not authorized domain2.ltd REJECT Not authorized Enable modifications: su - zimbra zmprov mcf zimbraMtaSmtpdSenderRestrictions 'check_sender_access lmdb:/opt/zimbra/conf/postfix_sender_access' postmap /opt/zimbra/conf/postfix_sender_access zmmtactl reload LINKS http://ossportal.org/forum/zimbra/1114","tags":"Zimbra","title":"Zimbra: Prevent send *SPAM* emails from self domain to self domain"},{"url":"blog/postgresql-mysql-create-database-and-user/","text":"PostgreSQL Создать базу и пользователя в PostgreSQL , а так же установить пароль для этого пользователя: Запускаем PostgreSQL клиент psql от пользователя postgres , используя sudo : sudo -u postgres psql Либо через su : su - postgres -c psql CREATE USER someuser WITH PASSWORD 'somepassword' CREATEDB ; CREATE DATABASE somedb WITH encoding = 'UNICODE' OWNER someuser ; GRANT ALL PRIVILEGES ON DATABASE somedb TO someuser ; Сменить пароль уже существующему пользователю: ALTER USER someuser PASSWORD 'superpassword' ; MySQL Создать базу и пользователя в MySQL , а так же установить пароль для этого пользователя: CREATE USER 'someuser' @ '127.0.%.%' IDENTIFIED BY 'somepasswd' ; CREATE DATABASE ` somedb ` CHARACTER SET utf8 COLLATE utf8_general_ci ; GRANT ALL PRIVILEGES ON ` somedb ` . * TO 'someuser' @ '10.135.%.%' WITH GRANT OPTION ; FLUSH PRIVILEGES ;","tags":"Bash","title":"PostgreSQL & MySQL создать базу и пользователя"},{"url":"blog/ubuntu-add-architecture-i386-ia32-libs/","text":"В частности при попытке выполнить в командной строке файл, предназначенный для 32-х битной системы, может возникать ошибка вида: ./somefile: Нет такого файла или каталога ( No such file or directory ) Чтобы 32-х битные приложения могли запускаться в 64-х битной системе Linux нужно установить соответствующие библиотеки, например для Ubuntu 14.04 : sudo dpkg --add-architecture i386 sudo apt-get update sudo apt-get install lib32z1 lib32ncurses5 lib32bz2-1.0 Удаление в обратном порядке: sudo dpkg --remove-architecture i386 sudo apt-get update sudo apt-get purge lib32z1 lib32ncurses5 lib32bz2-1.0 Ссылки по теме: Multiarch: What happened to the ia32-libs package?","tags":"Ubuntu","title":"Ubuntu add-architecture i386 ia32-libs"},{"url":"blog/ubuntu-prevent-open-thunderbird-mailto-links/","text":"Люблю выделять/копировать пароли/строки текста тройным ли двойным кликом мышки, но есть проблема со словами в которых есть символ @ , Ubuntu распознает это как email адрес и запускает Thunderbird , что не желательно, недолго погуглив рамблером в яндексе нашел такой хак: sudo sed -i '2 i exit 0' /usr/bin/xdg-email Как легально отключить это поведение, через пользовательские настройки пока не нашел и остановился на этом варианте.","tags":"Ubuntu","title":"Ubuntu prevent open thunderbird mailto links, xdg-open, xdg-mime, xdg-mail"},{"url":"blog/centos7-lxc/","text":"Сборка из исходных кодов стабильной версии lxc для Centos 7 с поддержкой python . Поддержка python необходима, например для работы команды lxc-ls --fancy Установка зависимостей: yum install -y epel-release yum install -y gcc git rpm-build automake make python34 python34-devel yum install -y libcap-devel docbook2X graphviz Согласно официальному сайту на момент написания статьи доступно 3 версии LXC , я выбрал LTS stable-1.0 Скачивание исходных кодов: git clone git://github.com/lxc/lxc -b stable-1.0 cd lxc Почитав немного доку и исходники, получился такой порядок действий: ./autogen.sh ./configure --enable-python PYTHON = /usr/bin/python3.4 PYTHONDEV_CFLAGS = -I/usr/include/python-3.4m PYTHONDEV_LIBS = -l/usr/include/python-3.4m Как можно заметить, конфигурация происходит с явным указанием версии python3.4 , он появился сравнительно недавно в EPEL , его и будем использовать далее. Т.к. у нас Centos и тут не все как у людей как в других дистрибутивах, изменим в исходниках путь до исполняемого файла Python , но сперва найдем файлы, которые нужно модифицировать: grep -Rn '&#94;#.*/python3' В результате у меня получился такой небольшой скрипт: for f in config/apparmor/lxc-generate-aa-rules.py src/lxc/lxc-device src/lxc/lxc-ls.in src/lxc/lxc-start-ephemeral.in src/lxc/lxc-ls src/lxc/lxc-start-ephemeral src/python-lxc/examples/api_test.py src/python-lxc/examples/pyconsole-vte.py src/python-lxc/examples/pyconsole.py src/python-lxc/setup.py src/python-lxc/setup.py.in ; do sed -i 's|#!/usr/bin/python3|#!/usr/bin/python3.4|' $f done sed -i 's|Requires: python3|Requires: python34|' lxc.spec sed -i 's|BuildRequires: python3-devel|BuildRequires: python34-devel|' lxc.spec sed -i 's|/python3.3/site-packages/|/python3.4/site-packages/|' lxc.spec После изменений проверим результат: grep -Rn '&#94;#.*/python3' Теперь соберем rpm пакеты используя Python3.4 : make rpm PYTHON = /usr/bin/python3.4 PYTHONDEV_CFLAGS = -I/usr/include/python-3.4m PYTHONDEV_LIBS = -l/usr/include/python-3.4m Найти собранные пакеты можно в каталоге cd /root/rpmbuild/RPMS/x86_64 , а установить командой: yum localinstall lxc-libs-1.0.7-1.el7.centos.x86_64.rpm lxc-1.0.7-1.el7.centos.x86_64.rpm Не будем останавливаться на этом! Для запуска Centos 7 контейнера необходимо проделать еще несколько манипуляций: В файле /usr/share/lxc/config/centos.common.conf нужно найти опцию lxc.cap.drop , содержащую значения setfcap и setpcap их нужно убрать, например для хоста Ubuntu 14.04 нужно сделать примерно так: #lxc.cap.drop = mac_admin mac_override setfcap setpcap lxc.cap.drop = mac_admin mac_override Не зависимо от дистрибутива нужно в тот же файл еще добавить в конец сроки: # This lets LXC SUSE containers run on hosts with apparmor. # It does nothing on hosts which do not have apparmor enabled. lxc.aa_profile = unconfined # https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1347020 lxc.kmsg = 0 UPD: 14.10.2016 Под Centos 7 и начиная с Ubuntu 16.06 для персистентных контейнеров лучше использовать systemd-nspawn и управлять ими через machinectl . Ссылки по теме: Bug 1176816 - booting a centos 7 container is extremely slow centos 7 needs setpcap capability systemd does not boot in a container [[lxc-devel] [PATCH] Various fixes for Fedora/CentOS/OpenSUSE templates and systemd.](https://lists.linuxcontainers.org/pipermail/lxc-devel/2014-September/010261.html) big big login delays in CentOS 7 systemd #340 Linux Containers: Downloads [LXC 1.0: Troubleshooting and debugging 10/10","tags":"CentOS","title":"Centos7 LXC"},{"url":"blog/zimbra-google-chrome-45-fix/","text":"Возникла проблема с Zimbra Webmail и Chrome v.45.0.2454.85 , спустя неделю был опубликован фикс на офф сайте Zimbra , я предлагаю очень похожий вариант, но без перезагрузки Zimbra . Нужно найти в файлах, возможно необходимо будет сделать бекап или скопировать и закомментировать изменяемые строки: /opt/zimbra/jetty-distribution-7.6.12.v20130726/webapps/zimbra/skins/_base/base2/skin.css /opt/zimbra/jetty-distribution-7.6.12.v20130726/webapps/zimbra/skins/_base/base3/skin.css Eсли эти строки отличаются - привести их к этому виду: # skin_td_sidebar_ad { width : @ SidebarAdWidth @ ; } # skin_container_sidebar_ad { @AdStyle@ width : @ SidebarAdWidth @ ; } Затем нужно найти строку: # skin_td_main { width : auto ; height : 100 % ; } И привести её к виду: # skin_td_main > TABLE { table-layout : fixed ; } Напомню, сделать это нужно в обоих файлах base3 и base2 Теперь самое интересное, чтобы не перезапускать Zimbra , можно исправить уже имеющие стили в кеше: cd /opt/zimbra/jetty/work/resource-cache/skinres/latest sed -i 's/#skin_td_main{width:auto;height:100%;}/#skin_td_main>TABLE{table-layout:fixed;}/g' ./*.css Ссылки по теме: Anyone else having display problems with Telus Webmail on Chrome v. 45.0.2454.85? Zimbra Web Client in ZCS 8.0.x and Google Chrome 45+ Github: Zimbra Google Chrome 45 Fix","tags":"Zimbra","title":"Zimbra Google Chrome 45 Fix"},{"url":"blog/run-x-applications-without-dm-nodm/","text":"Для запуска в X сессии любой X программы можно воспользоваться nodm . Установка необходимых пакетов: $ sudo apt-get install nodm Настройка nodm в файле /etc/default/nodm : # nodm configuration # Set NODM_ENABLED to something different than 'false' to enable nodm NODM_ENABLED = true # User to autologin for NODM_USER = metall # First vt to try when looking for free VTs NODM_FIRST_VT = '7' ### xinit program ###NODM_XINIT=/usr/bin/xinit # X session NODM_XSESSION = /etc/X11/Xsession # Options for the X server NODM_X_OPTIONS = '-nolisten tcp' # If an X session will run for less than this time in seconds, nodm will wait an # increasing bit of time before restarting the session. NODM_MIN_SESSION_TIME = 60 Ссылки по теме: forum kodi, XBMC Server","tags":"Linux","title":"Запуск X приложений на полный экран в X сервере без DM"},{"url":"blog/ubuntu-1404-lts-php5-fpm-reload/","text":"При установке php-fpm под Ubuntu 14.04 обнаружились проблемы с логами, не работала ротация, а так же не работал reload демона, демон завершал master процесс, при этом оставляя свои дочерние процессы, в следствие чего дальнейшая работа с php-fpm становилась невозможной, без ручной остановки каждого процесса php-fpm и последующим запуском, в общем надоело это безобразие, решил навести порядок. Создаем папку для логов: mkdir /var/log/php5-fpm chmod 777 /var/log/php5-fpm chmod 777 сделан намерено, потому, что у меня php-fpm пулы запускаются от разных пользователей и от разных групп. Затем переложим лог ошибок php-fpm в созданную только что папку с логами, для этого в файле: /etc/php5/fpm/php-fpm.conf : error_log = /var/log/php5-fpm/error.log Теперь займемся правильной ротацией логов, файл /etc/logrotate.d/php5-fpm к такому виду: /var/log/php5-fpm/*.log { rotate 5 # weekly # Не стоит терять логи, обнуляя файл раз в неделю! size 1k missingok notifempty compress delaycompress postrotate # http://stackoverflow.com/questions/19998526/ubuntu-php5-fpm-throws-unknown-instance-on-reload # The original reload command did never work #invoke-rc.d php5-fpm reopen-logs > /dev/null # Workaround for cases when the reload command fails for some reason service php5-fpm reload > /dev/null 2 > & 1 [ $? = 0 ] || ( service php5-fpm stop ; killall php5-fpm ; service php5-fpm start ) > /dev/null endscript } Так же рекомендую привести в порядок логи каждого пула например для пула www в файле /etc/php5/fpm/pool.d/www.conf : access.log = /var/log/php5-fpm/ $pool -access.log slowlog = /var/log/php5-fpm/ $pool -slow.log php_admin_value [ error_log ] = /var/log/php5-fpm/ $pool -error.log php_admin_flag [ log_errors ] = on Обратите внимание в имени файла используется переменная $pool , которая позволяет избавиться от рутины, прописывания имени пула в каждой строчке в каждом пуле. Теперь решим проблему с reload и с удобным хранением php-fpm пулов приводим файл /etc/init/php5-fpm.conf к такому виду: # php5-fpm - The PHP FastCGI Process Manager description \"The PHP FastCGI Process Manager\" author \"Ondřej Surý <ondrej@debian.org>\" start on runlevel [ 2345 ] stop on runlevel [ 016 ] # Precise upstart does not support reload signal, and thus rejects the # job. We'd rather start the daemon, instead of forcing users to # reboot https://bugs.launchpad.net/ubuntu/+source/php5/+bug/1272788 # reload signal USR2 pre-start script [ -d /var/run/php5-fpm ] || install -m 777 -o www-data -g root -d /var/run/php5-fpm /usr/lib/php5/php5-fpm-checkconf end script respawn exec /usr/sbin/php5-fpm --nodaemonize --fpm-config /etc/php5/fpm/php-fpm.conf Для применения изменений в upstart , необходимо выполнить команды, подробнее [2] : root@Ubuntu# initctl reload-configuration root@Ubuntu# initctl stop php5-fpm initctl: Unknown instance: root@Ubuntu# initctl start php5-fpm php5-fpm start/running, process 18467 В файле /etc/init.d/php5-fpm , добавим вверху, после переменной SCRIPTNAME строчку: SOCKETDIR = /var/run/ $NAME А затем, внутри функции do_start() { добавим еще одну строчку: [ -d $SOCKETDIR ] || install -m 777 -o www-data -g root -d $SOCKETDIR -m 777 я указал намеренно, как я уже упоминал ранее, у меня php-fpm пулы запускаются от разных uid:gid Итак после всего этого: Сокеты пулов лежат в ожидаемом месте: /var/run/php5-fpm/ Логи пулов, и лог ошибок демона php-fpm в: /var/log/php5-fpm/ Логи не обнуляются раз в неделю, а ротация логов производится при достижении размера файла в 1Кб и главное она работает ! Команда service php5-fpm reload теперь ничего не ломает и работает корректно. Ссылки по теме: Ubuntu php5-fpm throws unknown instance on reload Автоматическое создание директории /var/run/php5-fpm после перезагрузки","tags":"Ubuntu","title":"Ubuntu 14.04 LTS php5-fpm reload logrotate"},{"url":"blog/ubuntu-motd-ssh/","text":"При подключении по ssh к Ubuntu серверу, при установленном пакете: update-notifier-common apt-get install update-notifier-common В motd будет добавлено примерно следующее: 12 packages can be updated. 0 updates are security updates. Но не все так гладко, ценой за это будет небольшая задержка при подключении... Есть приятные полезности, например, если вызывать скрипт напрямую, то он выдаст информацию о доступных обновлениях, которую можно использовать где угодно в своих целях. /usr/lib/update-notifier/apt-check Результат команды будет примерно таким 12;0 . Где цифры до ; - количество доступных пакетов для обновления в моем случае 12 . А после ; - количество пакетов обновления безопасности. Кому этого мало, то можно еще установить пакет landscape-common : apt-get install landscape-common Этот пакет выдаст более подробную информацию о сервера, но при условии, что сервер не сильно загружен и в чрезвычайной ситуации этот скрипт не помешает админу подключаться по ssh .","tags":"Ubuntu","title":"Ubuntu красивый motd при подключении по ssh."},{"url":"blog/compact-home-powerful-server,minicase,noctua/","text":"Стало не хватать домашнего сервера на Atom D525 с 4Гб оперативной памяти, вот такой он компактный: Вон он в боевом положении, чтобы вы оценили насколько он компактный: Это корпус Mini-ITX Morex T3310 , покупался еще в красноярском DNS-shop , когда процессоры Atom еще были в моде. :) Процессор вместе с радиатором распаяны на материнской плате, внутри нет ни одного вентилятора, и 2 HDD от старых ноутбуков, да я собирал его из того, что было под рукой! :) Еще на плате имеется 1 PCI слот, куда вставлена вторая сетевая карточка, да, вы правильно догадались, это был домашний роутер! Внутри есть Mini-PCIe с Wi-Fi адаптером, но как видно на фото (плохо видно, но статья не о нем же), у меня появился Mikrotik RB951G-2HnD и необходимость во 2 карточке отпала, но виртуалки с разными проектами остались, а так же файлопомойка, PXE установщики и много других полезных вещей. В общем железо сильно устарело и я решил его обновить, получился такой список деталей: Наименование Модель и описание Цена Материнская плата ASRock H81TM-ITX, Scket1150, iH81, 2SODIMM DDRIII, 7.1-ch HDA, GLAN, USB 3.0, DVI, HDMI, Thin mini-ITX, Retail 3807 Блок питания HP-A1501A3B1 19V 7.9A 150W 2400 Кулер+доставка Dynatron K199 1U LGA115X 1794+1090 Память DDR3L SODIMM 16Gb (2x8Gb) PC12800 1600MHz CL9 Kingston HyperX Impact Black Series (HX316LS9IBK2/16) 7650 Процессор Intel Core i7-4790S 3200MHz 8Mb TDP-65W S1150 tray Haswell 24050 Процессор Intel Xeon E3-1246v3 3500MHz 8Mb 5GT/s TDP-84W S1150 tray 20675 Жесткий диск Hitachi (HGST) 1Tb HTS721010A9E630 Travelstar 7K1000 2.5\" 7200rpm 32Mb SATA3 4275+4275 Корпус Lian Li PC-Q05B Black Mini-ITX 47x284x307 3663 53004 руб. Сервер старался делать максимально миниатюрным, поэтому кулер выбрал очень специфичный Dynatron K199 , т.к. процессор хочется мощный и в то же время, чтобы сервер остался бесшумным и компактным. Выбранный кулер на момент покупки был доступен только в европейской части мира, аналогов в росии или китае я не нашел, поэтому пришлось заказать в штатах на * Ebay , тут я изрядно переплатил еще и доставка была платная, но оно того стоит ! (позже я выяснил, что он не очень тихий, турбинка сильно шумит, при нагрузках, взамен купил Noctua NH-L9i ) Выбранный процессор E3-1246v3 имеет 4 ядра, 8 потоков ( Hyper Threading ) и встроенное видео, которое пока никак не планируется использоваться, только для входа в BIOS и при возможных неполадках, IPMI решения или PCI-Ex видеокарточки конечно вариант, но по деньгам дороже и в реализации сложнее, проще процессор с видеокарточкой взять, но есть еще одна проблема рассеиваемая мощность 84Вт у кулера запаса хватает ( 95Вт ), а у материнской платы по паспорту написано 65Вт , но думаю должно работать, если нет, то придется менять процессор на E3-1286LV3 , стоимостью в 2 раза дороже (примерно $774 ). После долгих поисков, сравнений бенчмарков и технических характеристик, пришел к выводу, что наиболее подходящим будет процессор Intel Core i7-4790S c TDP 65W , он вполне производительный и энергоэффективный, судя по бенчмаркам производительность на уровне выбранного ранее E3-1286LV3 с TDP 84W . С блоком питания тоже не все так просто, в городе небыло таких мощных 150Вт , пришлось заказать в китае на Ebay . С выбором дисков одни разочарования, сперва выбрал то, что хотел Seagate-ST2000NX0243 Жесткий диск емкостью 2 ТБ с интерфейсом SAS/SATA с низким энергопотреблением, но когда узнал, что он стоит 21000 рублей в лучшем случае, начал искать аналоги, но и тут проблема стоят они в 2 раза меньше и в объеме тоже меньше, по скорости хуже, поэтому взял самый простой вариант Hitachi Travelstar 7K1000 HTS721010A9E630 , а ведь я планирую RAID1 , значит диска нужно два! А если мне вдруг действительно понадобятся быстрые, ёмкие и компактные диски, то я всегда успею их докупить. Тем более у меня на материнской плате еще Mini-PCIe пустой, можно туда купить SSD с интерфейсом M.2 это будет дешевле и быстрее! Память выбиралась очень просто, материнская плата не умеет ECC , максимальный объем 16Гб , максимальная частота 1600 , процессор все это поддерживает, поэтому взял самую простую и дешевую с таймингами поменьше CL9 , разница с аналогичной, но с таймингами CL11 была небольшой. Корпус, самое интересное оставил на десерт, пока планирую уместить все в старый корпус, но еще не все детали из списка куплены, поэтому я еще выбираю корпуса, присматириваюсь, так сказать. Пригляделся корпус Lian Li PC-Q05B Black когда померял, оказалось, что такой корпус не подходит, по высоте не хватило 6мм :( Немного погуглив заказал сразу два у китайцев minicase.net: E-W80 [6] , они подошли идеально! Ссылки по теме: Dynatron K199 Socket LGA1150 & Sandy Bridge LGA1155 & LGA1156 Жесткий диск Enterprise Capacity 2.5 HDD Интерфейс M.2 Next Generation Form Factor и NGFF Сравнение процессоров Intel® CPU Mark by Socket Type: LGA 1150 minicase.net: E-W80 Intel D525MW mother board Mini PCI express slot not detect our card?","tags":"Hardware","title":"Сборка мощного домашнего сервера"},{"url":"blog/os-x-mavericks-windows-7-ubuntu-1404/","text":"STEP 0: Создание флешки с помощью [UniBeast [6]] [6] STEP 1: Разбиение диска. Создать таблицу разделов GPT . Создать 3 раздела заданного размера. hfs+ Journaled ( Mac ) Ms-DOS FAT32 ( Windows ) Ms-DOS FAT32 ( Linux ) Если вы выберете именно Ms-Dos Fat32 , то дисковая утилита MacOS сама выберет GPT в режиме совместимости с MBR ! (можете вручную этим заняться с помощь gdisk ) Установка OS X Mavericks . Загрузка с флешки и запуск установленной ОС. Выполняете настройки и попадаете на рабочий стол. STEP 2: Создание и монтирование EFI раздела: Открываем терминал - Applications/Utilities/Terminal : $ sudo -s # newfs_hfs -v EFI /dev/disk0s1 # mkdir /Volumes/EFI # mount_hfs /dev/disk0s1 /Volumes/EFI STEP 3: Установка CHAMELEON на EFI раздел: # cd /Volumes/OSX-USB/usr/standalone/i386 # fdisk -f boot0 -u -y /dev/rdisk0 # cp boot /Volumes/EFI/ # cp -R /Volumes/OSX-USB/Extra /Volumes/EFI Загружаемся в Linux и записываем загрузчик на раздел EFI : cd /media/ubuntu/OSX-USB/usr/standalone/i386 # dd if=boot1h of=/dev/sda1 bs=4096 Если у вас диск с размером блоков в 512 байт , то можете обойтись без Linux : # dd if=boot1h of=/dev/rdisk0s1 Чтобы MacOS могла самостоятельно загружаться делаем активным EFI раздел: # fdisk -e /dev/rdisk0 # p # f 1 # w # y # q Теперь у вас полностью рабочая MacOS ! Самое время добавить сюда Windows 7 и Ubuntu . Загружаемся с флешки(диска) и устанавливаем Windows 7 на 2 раздел. После завершения установки Windows - потеряется загрузчик Chameleon , но это легко исправить: Загружаем установленную OS X Mavericks с флешки с которой только что её устанавливали. Прописываем загрузчик на диск: # cd /Volumes/OSX-USB/usr/standalone/i386 # fdisk -f boot0 -u -y /dev/rdisk0 Делаем активным раздел с Windows 7 : # fdisk -e /dev/rdisk0 # p # f 3 # w # y # q Загружаемся снова с диска/флешки Windows 7 , и запускаем восстановление проблем запуска Windows . Перезагружаемся - теперь Windows 7 должна загружаться снова, но сама - без Chamelion , а он нам нужен для запуска OS X ! В Windows используем консольную утилиту diskpart , чтобы сделать EFI раздел активным . Запускаем cmd от администратора . C : \\ > diskpart C : \\ > select disk 0 C : \\ > select partition 1 C : \\ > active Перезагружаемся. Chameleon должен запускаться с HDD ! Windows 7 и OS X должны загружаться корректно. Теперь можно установить Linux в последний раздел. Я устанавливал Ubuntu 14.04 : В установщике выбираем свой вариант установки. Последний 4 раздел отмечаем использовать как , файловая система ext4 . И важно загрузчик GRUB устанавливаем на раздел( sda4 ), не на диск ( sda ) ! По завершению установки Linux - Windows опять поломается и перестанет грузиться! Уж не знаю что там сделал установщик Ubuntu , но GPT теперь в режиме Ptotected MBR , а нам нужно Mixed MBR . Но не беда, исправляем с помощью gdisk (тот же fdisk только для GPT ). Не знаю почему 1 и 4 разделы отображаются в fdisk не корректно (до установки Linux , было все норм). Но зато раздел Windows отображается нормально и загрузка всех ОС будет проходить успешно. STEP 4: MultiBeast [7] Можно загружаться в OS X и запускать MultiBeast [7] , устанавливать драйвера на звук и т.д. Ссылки по теме: UniBeast Install Bootloader and Extra to EFI Partition Tweaking Your System: Install Chameleon, DSDT, & Extras to EFI Partition OS X + Windows 7 + GPT + Chameleon 2 = Finally Works Windows 7 0xc000000e boot error Latest Haswell (LGA1150) Motherboard Info Hackintosh: Chameleon to boot CentOS (Linux) in GPT HDD tonymacx86 Blog: Dual Boot Windows 7 and OS X Snow Leopard Using Chameleon MultiBeast","tags":"MacOSX","title":"OS X Mavericks + Windows 7 + Ubuntu 14.04 на одном HDD с блоками в 4k с GPT"},{"url":"blog/ubuntu-1404-dash-boost/","text":"На мой взгляд Unity Dash в Ubuntu перегружен лишним функционалом, например искать файлы удобнее в Nautilus , а приложения, доступные для установки лучше искать в Software Center , и самое важное выполнять онлайн поиск лучше в браузере. А вот установленные приложения вполне удобно искать в Dash . Скрипт ниже выключает онлайн поиск и все линзы, кроме установленных приложений. Код скрипта disable_all_scopes_enable_listed.sh : #!/bin/sh [ $( id -u ) -eq 0 ] && echo 'Please run from NOT root user!' && exit 1 # Delete unwanted packages. sudo apt-get purge -y unity-lens-shopping unity-lens-friends unity-scope-video-remote unity-lens-music unity-lens-photos unity-webapps-common # Disable online search. gsettings set com.canonical.Unity.Lenses remote-content-search none # Manually remove the link from dash. sudo rm /usr/share/applications/ubuntu-amazon-default.desktop get_application () { find /usr/share/unity/scopes/ \\( \\ -name \"*.scope\" \\ -not -name 'applications.scope' \\ \\) -printf \"'%P',\" | sed 's/\\//-/g;s/,$//' } # Disabling the scopes. gsettings set com.canonical.Unity.Lenses disabled-scopes \"[ $( get_application ) ]\" gsettings get com.canonical.Unity.Lenses disabled-scopes gsettings set com.canonical.Unity.Lenses always-search \"['applications.scope']\" gsettings set com.canonical.Unity.Dash scopes \"['home.scope', 'applications.scope']\" # Disable available apps. gsettings set com.canonical.Unity.ApplicationsLens display-available-apps \"false\" Посмотреть что еще можно покрутить в Unity на свой вкус можно простой командой: gsettings list-recursively | grep Unity Названия опций и их значения вполне интуитивно понятные, можно быстро разобраться что к чему. Например отключить показ доступных приложений: gsettings set com.canonical.Unity.ApplicationsLens display-available-apps \"false\" Проверить результат можно так: gsettings get com.canonical.Unity.ApplicationsLens display-available-apps Сбросить настройки на дефолт можно например так: gsettings reset-recursively com.canonical.Unity.Dash Ссылки по теме: How can I remove Amazon search results from the dash or disable the feature? Remove unsafe packages from Ubuntu","tags":"Ubuntu","title":"Ubuntu 14.04: Ускоряем работу Dash"},{"url":"blog/seagate-1tb-st31000528as-720012/","text":"Перестал определяться в BIOS ST31000528AS ( CC35 ) 7200.12 , первое что подумал - 1Tb данных пропал безвозвратно, но погуглив, понял, что не все так плохо, как кажется и решил побороться за данные и HDD , и так, подключаемся к HDD через serial терминал . Для подключения использовал FTDI232 , в распоряжении был еще BusPirate , но до него дело не дошло, FTDI232 справился отлично. # screen /dev/ttyUSB0 38400 Rst 0x20M ASCII Diag mode F3 T> ; Как видно, тут что-то не так Rst 0x20M - происходит сброс, зайдем в терминал нажатием Ctrl+z и попробуем проверить работу электроники и механики путём отключения/включения шпинделя: F3 F>Z Spin Down Complete Elapsed Time 513 .285 msecs F3 F>U HighPowerMode ExecuteSpinRequest Spin Up Complete Elapsed Time 5 .776 secs F3 F> Ошибок не было, значит с большей долей вероятности все живое и функционирует, поиск по интернету показал, что проблема в SMART данных (они хранятся на пластинах диска) - можно попробовать сбросить SMART данные: F3 T>/1 F3 1 >N1 Init SMART Fail LED:000000CC FAddr:0024EE41 LED:000000CC FAddr:0024EE41 А вот и ошибки, опять же поиск подсказывает, что необходимо форматировать пользовательскую зону с сертификацией, без записи, используя Slip(V1) -лист, т.е. пересчитать транслятор, пробуем, для этого я отключил кабель питания HDD , дождался остановки шпинделя (почему-то я не отключил его) и включил снова: # screen /dev/ttyUSB0 38400 Rst 0x20M ASCII Diag mode F3 T> Снова зашел в терминал диска нажатием Ctrl+z и попробовал пересчитать транслятор, как рекомендуют на форуме: F3 T>V4 Reassigned Sectors List Original New log log log phy phy LBA PBA cyl hd sctr zn cyl hd sctr SFI Alt Pending Total Alted Total Entries Entries Entries Alts Alts Head 0 0 Head 1 0 Head 2 0 Head 3 0 Total 0 0 0 0 0 Total Alt Removals: 0 Checksum = 0000 F3 T>V1 User Slip Defect List log log log phys phys LBA span cumm cyl hd sctr zn cyl sctr SFI PBA 0 0 0 0 0 0 0 0 0 4 0 Head 0 : entries 1 slips 0 Head 1 : entries 0 slips 0 Head 2 : entries 0 slips 0 Head 3 : entries 0 slips 0 Total Entries 1 Total Slips 0 F3 T>m0,2,2,,,,,22 Max Wr Retries = 00 , Max Rd Retries = 00 , Max ECC T-Level = 16 , Max Certify Rewrite Retries = 2DF8 User Partition Format Successful - Elapsed Time 0 mins 00 secs Zone re-format was skipped. Ошибок не было, все прошло успешно, теперь необходимо обязательно отключить питание HDD и можно пробовать подключать SATA кабель и проверять данные! Итак, после включения диск определился в BIOS , после загрузки ос я увидел все свои данные в целости и сохранности, на всякий случай скопировал оттуда фотографии и видео на другой диск. У меня был еще такой же диск, но с прошивкой поновее CC38 , поэтому я решил обновить её, делается это не так сложно, на сайте производителя [2] есть необходимый софт, мне очень подошел вариант с iso образом - я загрузился по сети pxeboot и произвел процедуру обновления, она не сложная. Ссылки по теме: Восстановление работоспособности жесткого диска Barracuda 7200.12 Firmware Update Maxtor DiamondMax 23 STM3500418AS не определяется в BIOS Расширяем стандартные возможности жесткого диска","tags":"Hardware","title":"Восстановление Seagate 1Tb ST31000528AS 7200.12"},{"url":"blog/ubuntu-1404-rhythmbox-indicator-sound/","text":"Столкнулся с проблемой, перестал работать индикатор звука в Ubuntu 14.04 , а именно кнопка Play/Pause в Rhythmbox , поискал в интернете подобные проблемы и кое-что нашел: $ gdbus call --session --dest org.mpris.MediaPlayer2.rhythmbox --object-path /org/mpris/MediaPlayer2 --method org.freedesktop.DBus.Properties.GetAll 'org.mpris.MediaPlayer2.Player' Ошибка: GDBus.Error:org.freedesktop.DBus.Error.ServiceUnknown: The name org.mpris.MediaPlayer2.rhythmbox was not provided by any .service files Как оказалось, я копался в плагинах Rhythmbox и отключил Интерфейс MPRIS D-Bus , не зная для чего он, но теперь я узнал зачем он нужен из [2] и включил, после чего индикатор заработал в штатном режиме. Ссылки по теме: vlc sound menu integration broken 14.04 Rhythmbox controls and track info broken","tags":"Ubuntu","title":"Ubuntu 14.04 Rhythmbox перестал реагировать на кнопки в indicator-sound"},{"url":"blog/zabbix-nginx-status/","text":"Скрипты и файлы конфигурации для мониторинга состояния Nginx . Шаблон для Zabbix 2.2 : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <zabbix_export> <version> 2.0 </version> <date> 2015-11-07T18:31:03Z </date> <groups> <group> <name> Templates </name> </group> </groups> <templates> <template> <template> Template App nginx </template> <name> Template App nginx </name> <groups> <group> <name> Templates </name> </group> </groups> <applications> <application> <name> App nginx </name> </application> </applications> <items> <item> <name> Nginx accepts per second </name> <type> 2 </type> <snmp_community/> <multiplier> 1 </multiplier> <snmp_oid/> <key> nginx.accepts </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 0 </value_type> <allowed_hosts/> <units> r/s </units> <delta> 1 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx active connections </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.active </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx handled per second </name> <type> 2 </type> <snmp_community/> <multiplier> 1 </multiplier> <snmp_oid/> <key> nginx.handled </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 0 </value_type> <allowed_hosts/> <units> r/s </units> <delta> 1 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx latency </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.ping[{HOST.HOST}] </key> <delay> 2 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx memory allocated </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> proc.mem[nginx,nginx] </key> <delay> 60 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx process count </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> proc.num[nginx] </key> <delay> 60 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx reading state connection count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.reading </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx requests per second </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.requests </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 0 </value_type> <allowed_hosts/> <units> r/s </units> <delta> 1 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx waiting state connection count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.waiting </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> <item> <name> Nginx writing state connection count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.writing </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> </item> </items> <discovery_rules/> <macros/> <templates/> <screens/> </template> </templates> <triggers> <trigger> <expression> {Template App nginx:proc.num[nginx].last(0)}=0 </expression> <name> Nginx is down on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> <dependencies/> </trigger> <trigger> <expression> {Template App nginx:nginx.ping[{HOST.HOST}].min(#10)} &gt; 0.01 </expression> <name> Nginx is slow to respond on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 2 </priority> <description/> <type> 0 </type> <dependencies/> </trigger> <trigger> <expression> {Template App nginx:nginx.ping[{HOST.HOST}].last()} &lt; 0 </expression> <name> Nginx response is invalid on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 3 </priority> <description> Nginx is not available via configured url </description> <type> 0 </type> <dependencies/> </trigger> </triggers> <graphs> <graph> <name> Nginx ping </name> <width> 900 </width> <height> 200 </height> <yaxismin> 0.0000 </yaxismin> <yaxismax> 100.0000 </yaxismax> <show_work_period> 1 </show_work_period> <show_triggers> 1 </show_triggers> <type> 0 </type> <show_legend> 1 </show_legend> <show_3d> 0 </show_3d> <percent_left> 0.0000 </percent_left> <percent_right> 0.0000 </percent_right> <ymin_type_1> 1 </ymin_type_1> <ymax_type_1> 0 </ymax_type_1> <ymin_item_1> 0 </ymin_item_1> <ymax_item_1> 0 </ymax_item_1> <graph_items> <graph_item> <sortorder> 0 </sortorder> <drawtype> 2 </drawtype> <color> 009900 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.ping[{HOST.HOST}] </key> </item> </graph_item> </graph_items> </graph> <graph> <name> Nginx status </name> <width> 900 </width> <height> 200 </height> <yaxismin> 0.0000 </yaxismin> <yaxismax> 100.0000 </yaxismax> <show_work_period> 0 </show_work_period> <show_triggers> 0 </show_triggers> <type> 0 </type> <show_legend> 1 </show_legend> <show_3d> 0 </show_3d> <percent_left> 0.0000 </percent_left> <percent_right> 0.0000 </percent_right> <ymin_type_1> 0 </ymin_type_1> <ymax_type_1> 0 </ymax_type_1> <ymin_item_1> 0 </ymin_item_1> <ymax_item_1> 0 </ymax_item_1> <graph_items> <graph_item> <sortorder> 1 </sortorder> <drawtype> 0 </drawtype> <color> FF3333 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.connections.writing </key> </item> </graph_item> <graph_item> <sortorder> 0 </sortorder> <drawtype> 0 </drawtype> <color> 009900 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.connections.active </key> </item> </graph_item> <graph_item> <sortorder> 3 </sortorder> <drawtype> 0 </drawtype> <color> 0000FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.connections.reading </key> </item> </graph_item> <graph_item> <sortorder> 2 </sortorder> <drawtype> 0 </drawtype> <color> FF33FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.connections.waiting </key> </item> </graph_item> </graph_items> </graph> <graph> <name> Nginx workload </name> <width> 900 </width> <height> 200 </height> <yaxismin> 0.0000 </yaxismin> <yaxismax> 100.0000 </yaxismax> <show_work_period> 1 </show_work_period> <show_triggers> 1 </show_triggers> <type> 0 </type> <show_legend> 1 </show_legend> <show_3d> 0 </show_3d> <percent_left> 0.0000 </percent_left> <percent_right> 0.0000 </percent_right> <ymin_type_1> 0 </ymin_type_1> <ymax_type_1> 0 </ymax_type_1> <ymin_item_1> 0 </ymin_item_1> <ymax_item_1> 0 </ymax_item_1> <graph_items> <graph_item> <sortorder> 2 </sortorder> <drawtype> 0 </drawtype> <color> 009900 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.accepts </key> </item> </graph_item> <graph_item> <sortorder> 0 </sortorder> <drawtype> 0 </drawtype> <color> C80000 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.requests </key> </item> </graph_item> <graph_item> <sortorder> 1 </sortorder> <drawtype> 0 </drawtype> <color> 3333FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template App nginx </host> <key> nginx.handled </key> </item> </graph_item> </graph_items> </graph> </graphs> </zabbix_export> Шаблон для Zabbix 2.4 : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <zabbix_export> <version> 2.0 </version> <date> 2015-05-31T06:58:40Z </date> <groups> <group> <name> Templates </name> </group> </groups> <templates> <template> <template> Template APP nginx </template> <name> Template APP nginx </name> <description/> <groups> <group> <name> Templates </name> </group> </groups> <applications> <application> <name> App nginx </name> </application> </applications> <items> <item> <name> Nginx accepts per second </name> <type> 2 </type> <snmp_community/> <multiplier> 1 </multiplier> <snmp_oid/> <key> nginx.accepts </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 0 </value_type> <allowed_hosts/> <units> r/s </units> <delta> 1 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx active connections </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.active </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx handled per second </name> <type> 2 </type> <snmp_community/> <multiplier> 1 </multiplier> <snmp_oid/> <key> nginx.handled </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 0 </value_type> <allowed_hosts/> <units> r/s </units> <delta> 1 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx latency </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.ping[{HOST.HOST}] </key> <delay> 60 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 0 </value_type> <allowed_hosts/> <units> s </units> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx memory allocated </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> proc.mem[nginx,nginx] </key> <delay> 60 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units> B </units> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx process count </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> proc.num[nginx] </key> <delay> 30 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx reading state connection count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.reading </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx requests per second </name> <type> 2 </type> <snmp_community/> <multiplier> 1 </multiplier> <snmp_oid/> <key> nginx.requests </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 0 </value_type> <allowed_hosts/> <units> r/s </units> <delta> 1 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx waiting state connection count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.waiting </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Nginx writing state connection count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> nginx.connections.writing </key> <delay> 0 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App nginx </name> </application> </applications> <valuemap/> <logtimefmt/> </item> </items> <discovery_rules/> <macros/> <templates/> <screens/> </template> </templates> <triggers> <trigger> <expression> {Template APP nginx:proc.num[nginx].last(0)}=0 </expression> <name> Nginx is down on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> <dependencies/> </trigger> <trigger> <expression> {Template APP nginx:nginx.ping[{HOST.HOST}].min(#10)} &gt; 0.01 </expression> <name> Nginx is slow to respond on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 2 </priority> <description/> <type> 0 </type> <dependencies/> </trigger> <trigger> <expression> {Template APP nginx:nginx.ping[{HOST.HOST}].last()} &lt; 0 </expression> <name> Nginx responce is invalid on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 3 </priority> <description> Nginx is not available via configured url </description> <type> 0 </type> <dependencies/> </trigger> </triggers> <graphs> <graph> <name> Nginx ping </name> <width> 900 </width> <height> 200 </height> <yaxismin> 0.0000 </yaxismin> <yaxismax> 100.0000 </yaxismax> <show_work_period> 1 </show_work_period> <show_triggers> 1 </show_triggers> <type> 0 </type> <show_legend> 1 </show_legend> <show_3d> 0 </show_3d> <percent_left> 0.0000 </percent_left> <percent_right> 0.0000 </percent_right> <ymin_type_1> 1 </ymin_type_1> <ymax_type_1> 0 </ymax_type_1> <ymin_item_1> 0 </ymin_item_1> <ymax_item_1> 0 </ymax_item_1> <graph_items> <graph_item> <sortorder> 0 </sortorder> <drawtype> 2 </drawtype> <color> 009900 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.ping[{HOST.HOST}] </key> </item> </graph_item> </graph_items> </graph> <graph> <name> Nginx status </name> <width> 900 </width> <height> 200 </height> <yaxismin> 0.0000 </yaxismin> <yaxismax> 100.0000 </yaxismax> <show_work_period> 0 </show_work_period> <show_triggers> 0 </show_triggers> <type> 0 </type> <show_legend> 1 </show_legend> <show_3d> 0 </show_3d> <percent_left> 0.0000 </percent_left> <percent_right> 0.0000 </percent_right> <ymin_type_1> 0 </ymin_type_1> <ymax_type_1> 0 </ymax_type_1> <ymin_item_1> 0 </ymin_item_1> <ymax_item_1> 0 </ymax_item_1> <graph_items> <graph_item> <sortorder> 1 </sortorder> <drawtype> 0 </drawtype> <color> FF3333 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.connections.writing </key> </item> </graph_item> <graph_item> <sortorder> 0 </sortorder> <drawtype> 2 </drawtype> <color> 009900 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.connections.active </key> </item> </graph_item> <graph_item> <sortorder> 2 </sortorder> <drawtype> 0 </drawtype> <color> FF33FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.connections.waiting </key> </item> </graph_item> <graph_item> <sortorder> 3 </sortorder> <drawtype> 0 </drawtype> <color> 0000FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.connections.reading </key> </item> </graph_item> </graph_items> </graph> <graph> <name> Nginx workload </name> <width> 900 </width> <height> 200 </height> <yaxismin> 0.0000 </yaxismin> <yaxismax> 100.0000 </yaxismax> <show_work_period> 1 </show_work_period> <show_triggers> 1 </show_triggers> <type> 0 </type> <show_legend> 1 </show_legend> <show_3d> 0 </show_3d> <percent_left> 0.0000 </percent_left> <percent_right> 0.0000 </percent_right> <ymin_type_1> 0 </ymin_type_1> <ymax_type_1> 0 </ymax_type_1> <ymin_item_1> 0 </ymin_item_1> <ymax_item_1> 0 </ymax_item_1> <graph_items> <graph_item> <sortorder> 2 </sortorder> <drawtype> 0 </drawtype> <color> 009900 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.accepts </key> </item> </graph_item> <graph_item> <sortorder> 1 </sortorder> <drawtype> 0 </drawtype> <color> 3333FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.handled </key> </item> </graph_item> <graph_item> <sortorder> 0 </sortorder> <drawtype> 0 </drawtype> <color> FF0000 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template APP nginx </host> <key> nginx.requests </key> </item> </graph_item> </graph_items> </graph> </graphs> </zabbix_export> Для удобства установки различных нестандартных метрик для мониторинга я использую директиву Include=/etc/zabbix/zabbix_agentd.conf.d/ после чего можно добавлять отдельные файлы, в которых будут все опции, необходимые для работы необходимой метрики, в данном случае: /etc/zabbix/zabbix_agentd.conf.d/nginx_status.conf : UserParameter = nginx.ping,sh /etc/zabbix/scripts/nginx_status.sh Конфигурация для Nginx файл nginx_status_http.conf : server { listen 127.0.0.1 : 80 ; server_name localhost ; keepalive_timeout 0 ; location = /nginx_status { stub_status on ; #access_log off; allow 127 .0.0.1 ; deny all ; } access_log /var/log/nginx/nginx_status_http.access.log ; error_log /var/log/nginx/nginx_status_http.error.log ; } Нужно положить этот конфигурационный файл nginx в /etc/nginx/sites-available/nginx_status_http.conf : ln -s /etc/nginx/sites-available/nginx_status_http.conf /etc/nginx/sites-enabled/nginx_status_http.conf service nginx reload Затем необходимо создать скрипт, который осуществляет доставку данных в Zabbix - /etc/zabbix/scripts/nginx_status.sh : #!/bin/sh URL = 'http://localhost/nginx_status' TMP = '/tmp/nginx-ping.tmp' ZABBIX_SENDER = '/usr/bin/env zabbix_sender' CONFIG = '/etc/zabbix/zabbix_agentd.conf' # WARNING: Correctly setup 'Hostname=' in config is REQUIRED! # REQUIRED binaries: GNU time, wget, awk, zabbix_sender. ( /usr/bin/env time -f %e /usr/bin/env wget --no-http-keep-alive --quiet --timeout 9 -O - $URL ) 2 > $TMP | \\ awk '/Active connections/ {active=int($NF)} / ([0-9]+) ([0-9]+) ([0-9]+)/ {accepts=int($1); handled=int($2); requests=int($3)} /Reading:/ {reading=int($2); writing=int($4); waiting=int($6)} END { print \"- nginx.connections.active\", active; print \"- nginx.connections.reading\", reading; print \"- nginx.connections.writing\", writing; print \"- nginx.connections.waiting\", waiting; print \"- nginx.accepts\", accepts; print \"- nginx.handled\", handled; print \"- nginx.requests\", requests; }' | $ZABBIX_SENDER \\ --config $CONFIG \\ --input-file - >/dev/null 2 > & 1 [ -f $TMP ] && cat $TMP && rm $TMP exit 1 И сразу выставляем правильные права на скрипт: chmod 600 /etc/zabbix/scripts/nginx_status.sh chown zabbix:zabbix /etc/zabbix/scripts/nginx_status.sh Если каталога /etc/zabbix/scripts у вас еще нет, то его нужно создать: mkdir /etc/zabbix/scripts chmod 700 /etc/zabbix/scripts chown zabbix:zabbix /etc/zabbix/scripts Для корректной работы необходимо вызывать напрямую бинарный файл /usr/bin/time , не путать со встроенной bash функцией time , в Linux есть с этим большая, на мой взгляд, проблема, т.к. bash time работает некорректно, в отличие от /usr/bin/time , к тому же и формат ответа разный, установить можно: Для Ubuntu , Debian : apt-get install time Для CentoOS и подобных: yum install time Все почти готово, теперь можно зайти в панель Zabbix и добавить нужному хосту новый шаблон Template APP nginx . Github repo:zabbix_nginx","tags":"Zabbix","title":"zabbix: мониторинг nginx status"},{"url":"blog/markdown-midnight-commander/","text":"Для просмотра MarkDown файлов в Midnight Commander необходимо добавить тип файлов .md , для этого в файл /etc/mc/mc.ext добавить следующий код: # md regex/ \\. [ Mm ][ Dd ] $ View = %view { ascii,nroff } iconv -t utf-8 %p | pandoc -f markdown -t html | iconv -f utf-8 | ( w3m -dump -T text/html 2 >/dev/null || lynx -force_html -stdin -dump -nolist 2 >/dev/null ) Для конвертирования md в html используется утилита pandoc , она мне показалась более предпочтительной, чем markdown , т.к. последний не умел обрабатывать теги с подобным кодом ```bash . pandoc необходимо установить, например для ubuntu : apt-get install pandoc Если нет желания ставить w3m или lynx браузер, то можно воспользоваться форматом man ( pandoc по прежнему необходим): # md regex/ \\. [ Mm ][ Dd ] $ View = %view { ascii,nroff } iconv -t utf-8 %p | pandoc -s -f markdown -t man | iconv -f utf-8 | man -l - P.S. iconv используется на всякий случай, если вдруг по какой-то причине у вас не UTF8 локаль, а pandoc обрабатывает по умолчанию в UTF8 и результат отдает тоже в UTF8 , поэтому сперва конвертируем исходный текст из вашей локали в UTF8 , отдаем на обработку в pandoc и конвертируем из UTF8 обратно в текущую локаль. Ссылки по теме: Online MarkDown Editor","tags":"Bash","title":"Просмотр Markdown в MidnightCommander"},{"url":"blog/zabbix-supervisord/","text":"Скрипт поддерживает обнаружение ( discovery ) всех программ, которые сконфигурированы для запуска. Отправка данных осуществляется через zabbix_sender . Установка довольно тривиальна: mkdir /etc/zabbix/scripts chown root:zabbix -R /etc/zabbix/scripts chmod 750 /etc/zabbix/scripts Код скрипта /etc/zabbix/scripts/lsimegaraid_discovery_trapper.sh : #!/bin/sh ZABBIX_SENDER = '/usr/bin/env zabbix_sender' ZBX_CONFIG = '/etc/zabbix/zabbix_agentd.conf' ZBX_HOSTNAME = $( awk -F '=' '/&#94;Hostname=/{ print $2 }' /etc/zabbix/zabbix_agentd.d/*.conf ) supervisorctl status | \\ awk 'match($0, /&#94;([&#94;:]+):[&#94;[:blank:]]+[[:blank:]]+([&#94;[:blank:]]+).*$/, line) { SUBSEP=\",\" # Sadly, we can not initialize all the worker,status couples in the BEGIN section. # We have to run these almost useless lines during the input parsing if (status[line[1],\"STOPPED\"] == 0) {status[line[1],\"STOPPED\"] = 0} if (status[line[1],\"STARTING\"] == 0) {status[line[1],\"STARTING\"] = 0} if (status[line[1],\"RUNNING\"] == 0) {status[line[1],\"RUNNING\"] = 0} if (status[line[1],\"BACKOFF\"] == 0) {status[line[1],\"BACKOFF\"] = 0} if (status[line[1],\"STOPPING\"] == 0) {status[line[1],\"STOPPING\"] = 0} if (status[line[1],\"EXITED\"] == 0) {status[line[1],\"EXITED\"] = 0} if (status[line[1],\"FATAL\"] == 0) {status[line[1],\"FATAL\"] = 0} if (status[line[1],\"UNKNOWN\"] == 0) {status[line[1],\"UNKNOWN\"] = 0} status[line[1],line[2]]++ } END { for(i in status) { print \"- supervisord.workerState[\" i \"] \" status[i] } }' | /usr/bin/env zabbix_sender --config $ZBX_CONFIG \\ --input-file - --host $ZBX_HOSTNAME >/dev/null 2 > & 1 echo $? exit 0 Установка прав на скрипт: chown root:zabbix /etc/zabbix/scripts/supervisord_discovery_trapper.sh chmod 750 /etc/zabbix/scripts/supervisord_discovery_trapper.sh Не забываем про настройки в скрипте, где нужно указать полные пути до необходимых программ и конфигурационных файлов: ZABBIX_SENDER = '/usr/bin/env zabbix_sender' ZBX_CONFIG = '/etc/zabbix/zabbix_agentd.conf' ZBX_HOSTNAME = $( awk -F '=' '/&#94;Hostname=/{ print $2 }' /etc/zabbix/zabbix_agentd.d/*.conf ) Конфигурационный файл: /etc/zabbix/zabbix_agentd.conf.d/lsimegaraid.conf AllowRoot = 1 UserParameter = supervisord.discovery,supervisorctl status | awk 'BEGIN {out=\"{\\n\\t\\\"data\\\":[\\n\"; f=0;} {match($0, /&#94;([&#94;:]+):[&#94;[:blank:]]+[[:blank:]]+([&#94;[:blank:]]+).*$/, line);if (!seen[line[1]]++ && line[1] != NULL) {if (f == 1) out=out\",\\n\";out=out \"\\t\\t{\\\"{#PROGRAMM}\\\":\\\"\"line[1]\"\\\"}\";f=1}} END{ if(f == 0){print \"{}\"}else{print out\"\\n\\t]\\n}\"}}' UserParameter = supervisord.trapper,/etc/zabbix/scripts/supervisord_trapper.sh Шаблон для zabbix : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <zabbix_export> <version> 2.0 </version> <date> 2015-03-17T09:01:18Z </date> <groups> <group> <name> Templates </name> </group> </groups> <templates> <template> <template> Template_APP supervisor </template> <name> Template_APP supervisor </name> <description/> <groups> <group> <name> Templates </name> </group> </groups> <applications> <application> <name> App supervisord </name> </application> </applications> <items> <item> <name> Controller </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.trapper </key> <delay> 30 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Supervisord process count </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> proc.num[supervisord] </key> <delay> 30 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item> </items> <discovery_rules> <discovery_rule> <name> supervisord State discovery </name> <type> 0 </type> <snmp_community/> <snmp_oid/> <key> supervisord.discovery </key> <delay> 3600 </delay> <status> 0 </status> <allowed_hosts/> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <delay_flex/> <params/> <ipmi_sensor/> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <filter> <evaltype> 0 </evaltype> <formula/> <conditions/> </filter> <lifetime> 30 </lifetime> <description/> <item_prototypes> <item_prototype> <name> supervisord BACKOFF State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},BACKOFF] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> supervisord EXITED State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},EXITED] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> supervisord FATAL State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},FATAL] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> supervisord RUNNING State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},RUNNING] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> supervisord STARTING State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},STARTING] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> supervisord STOPPED State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},STOPPED] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> supervisord STOPPING State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},STOPPING] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> supervisord UNKNOWN State of worker $1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> supervisord.workerState[{#PROGRAMM},UNKNOWN] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> App supervisord </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> </item_prototypes> <trigger_prototypes> <trigger_prototype> <expression> {Template_APP supervisor:supervisord.workerState[{#PROGRAMM},BACKOFF].last(0)} &gt; 0 </expression> <name> Supervisord BACKOFF State of worker {#PROGRAMM} on host {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template_APP supervisor:supervisord.workerState[{#PROGRAMM},EXITED].last(0)} &gt; 0 </expression> <name> Supervisord EXITED State of worker {#PROGRAMM} on host {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template_APP supervisor:supervisord.workerState[{#PROGRAMM},FATAL].last(0)} &gt; 0 </expression> <name> Supervisord FATAL State of worker {#PROGRAMM} on host {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template_APP supervisor:supervisord.workerState[{#PROGRAMM},RUNNING].last(0)}=0 </expression> <name> Supervisord RUNNING State of worker {#PROGRAMM} on host {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template_APP supervisor:supervisord.workerState[{#PROGRAMM},STOPPED].last(0)} &gt; 0 </expression> <name> Supervisord STOPPED State of worker {#PROGRAMM} on host {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template_APP supervisor:supervisord.workerState[{#PROGRAMM},UNKNOWN].last(0)} &gt; 0 </expression> <name> Supervisord UNKNOWN State of worker {#PROGRAMM} on host {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> </trigger_prototype> </trigger_prototypes> <graph_prototypes/> <host_prototypes/> </discovery_rule> </discovery_rules> <macros/> <templates/> <screens/> </template> </templates> <triggers> <trigger> <expression> {Template_APP supervisor:proc.num[supervisord].last(0)}=0 </expression> <name> Supervisord is down on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> <dependencies/> </trigger> </triggers> </zabbix_export> Не забываем перезапустить агент, чтобы агент прочитал новый конфигурационный файл: service zabbix-agentd restart Проверка: zabbix_get -s HOST -k \"supervisord.discovery\"","tags":"Zabbix","title":"Zabbix: supervisord автообнаружение программ и мониторинг статуса."},{"url":"blog/zabbix-lsi-megaraid/","text":"Скрипт мониторит по-умолчанию адаптер 0 , т.е. когда в системе только одна плата Raid контроллера (опция -a0 ), но можно указать конкретный номер адаптера, если это необходимо. Скрипт имеет встроенную справку: # ./lsimegaraid_discovery_trapper.sh help WARNING: Correctly setup 'Hostname=' in config is REQUIRED! INFO: Number of array is default 0 ; Examples: Discovery is default action: ./lsimegaraid_discovery_trapper.sh - physdiscovery disks for default array 0 . ./lsimegaraid_discovery_trapper.sh discovery - physdiscovery disks for default array 0 . ./lsimegaraid_discovery_trapper.sh discovery virtdiscovery - virtdiscovery disks for custom array 0 . ./lsimegaraid_discovery_trapper.sh discovery virtdiscovery 1 - virtdiscovery disks for custom array 1 . ./lsimegaraid_discovery_trapper.sh discovery physdiscovery 1 - physdiscovery disks for custom array 1 . Data sending to zabbix-server: ./lsimegaraid_discovery_trapper.sh trapper - send data to zabbix for default array 0 . ./lsimegaraid_discovery_trapper.sh trapper 1 - send data to zabbix for custom array 1 . 03 .2015 - metajiji@gmail.com Скрипт поддерживает обнаружение ( discovery ) виртуальных и физических дисков в слотах. Отправка данных осуществляется через zabbix_sender . Установка довольно тривиальна: mkdir /etc/zabbix/scripts chown root:zabbix -R /etc/zabbix/scripts chmod 750 /etc/zabbix/scripts Код скрипта /etc/zabbix/scripts/lsimegaraid_discovery_trapper.sh : #!/bin/sh MEGACLI = '/usr/local/sbin/MegaCli' ZABBIX_SENDER = '/usr/local/bin/zabbix_sender' CONFIG = '/etc/zabbix/zabbix_agentd.conf' usage () { cat <<-_EOF WARNING: Correctly setup 'Hostname=' in config is REQUIRED! INFO: Number of array is default 0; Examples: Discovery is default action: ./$(basename $0) - physdiscovery disks for default array 0. ./$(basename $0) discovery - physdiscovery disks for default array 0. ./$(basename $0) discovery virtdiscovery - virtdiscovery disks for custom array 0. ./$(basename $0) discovery virtdiscovery 1 - virtdiscovery disks for custom array 1. ./$(basename $0) discovery physdiscovery 1 - physdiscovery disks for custom array 1. Data sending to zabbix-server: ./$(basename $0) trapper - send data to zabbix for default array 0. ./$(basename $0) trapper 1 - send data to zabbix for custom array 1. 03.2015 - metajiji@gmail.com _EOF } LC_ALL = \"\" LANG = \"en_US.UTF-8\" discovery () { local TYPE = ${ 1 :- 'physdiscovery' } # Set Default value to physdiscovery. local ARRAY_NUM = ${ 2 :- '0' } # Default value of array number is 0. if [ \" $TYPE \" == \"virtdiscovery\" ] ; then $MEGACLI -LDInfo -LAll -a $ARRAY_NUM -NoLog | awk ' BEGIN { out = \"{\\n\\t\\\"data\\\":[\\n\" f = 0 } /Virtual Drive:/ { if (f == 1) out = out\",\\n\" out=out \"\\t\\t{\\\"{#VIRTNUM}\\\":\\\"VirtualDrive\"$3\"\\\"}\" f = 1 } END { if (f == 0) { print \"{}\" } else { print out\"\\n\\t]\\n}\" } }' elif [ \" $TYPE \" == 'physdiscovery' ] ; then $MEGACLI -PDlist -a $ARRAY_NUM -NoLog | awk -F ': ' ' BEGIN { out = \"{\\n\\t\\\"data\\\":[\\n\" f = 0 } /Slot Number:/ { if (f == 1) out = out\",\\n\" out=out \"\\t\\t{\\\"{#PHYSNUM}\\\":\\\"DriveSlot\"$2\"\\\"}\" f = 1 } END { if (f == 0) { print \"{}\" } else { print out\"\\n\\t]\\n}\" } }' else > & 2 echo 'ERROR : Discovery TYPE \"' $TYPE '\" is not correct!' echo '{}' # Return empty json, if TYPE is not correct. fi } trapper () { local ARRAY_NUM = ${ 1 :- '0' } # Default value of array number is 0. ( $MEGACLI -PDlist -a $ARRAY_NUM -NoLog | awk -F ':' ' function ltrim(s) {sub(/&#94;[ \\t]+/, \"\", s);return s} function rtrim(s) {sub(/[ \\t]+$/, \"\", s);return s} function trim(s) {return rtrim(ltrim(s))} /Slot Number/ {slotcounter += 1; slot[slotcounter] = trim($2)} /Firmware state/ {state[slotcounter] = trim($2)} /S.M.A.R.T/ {smart[slotcounter] = trim($2)} /Inquiry Data/ {inquiry[slotcounter] = trim($2)} /Media Error Count/ {mediaerror[slotcounter] = trim($2)} /Other Error Count/ {othererror[slotcounter] = trim($2)} /Drive Temperature/ {temperature[slotcounter] = trim($2)} /Predictive Failure Count/ {failurecount[slotcounter] = trim($2)} END { for (i = 1; i <= slotcounter; i += 1) { printf (\"- lsimegaraid.data[DriveSlot%d,state] %s\\n\", slot[i], state[i]) printf (\"- lsimegaraid.data[DriveSlot%d,smart] %s\\n\", slot[i], smart[i]) printf (\"- lsimegaraid.data[DriveSlot%d,inquiry] %s\\n\", slot[i], inquiry[i]) printf (\"- lsimegaraid.data[DriveSlot%d,mediaerror] %d\\n\", slot[i], mediaerror[i]) printf (\"- lsimegaraid.data[DriveSlot%d,othererror] %d\\n\", slot[i], othererror[i]) printf (\"- lsimegaraid.data[DriveSlot%d,temperature] %d\\n\", slot[i], temperature[i]) printf (\"- lsimegaraid.data[DriveSlot%d,failurecount] %d\\n\", slot[i], failurecount[i]) } }' ; [ $? -gt 1 ] && echo 'ERROR : MegaCli failed while getting phusical drives data!' && exit 1 ${ MEGACLI } -LDInfo -LAll -a $ARRAY_NUM -NoLog | awk -F ':' ' function ltrim(s) {sub(/&#94;[ \\t]+/, \"\", s);return s} function rtrim(s) {sub(/[ \\t]+$/, \"\", s);return s} function trim(s) {return rtrim(ltrim(s))} /Virtual Drive:/ {drivecounter += 1; slot[drivecounter] = trim($2)} /State/ {state[drivecounter] = trim($2)} /Bad Blocks/ {badblock[drivecounter] = trim($2)} END { for (i = 1; i <= drivecounter; i += 1) { printf (\"- lsimegaraid.data[VirtualDrive%d,state] %s\\n\", slot[i], state[i]) printf (\"- lsimegaraid.data[VirtualDrive%d,badblock] %s\\n\", slot[i], badblock[i]?badblock[i]:\"Unknown\") } }' ; [ $? -gt 1 ] && echo 'ERROR : MegaCli failed while getting virtual drives data!' && exit 1 ) | $ZABBIX_SENDER --config $CONFIG -vv --input-file - >/dev/null 2 > & 1 [ $? -gt 1 ] && echo 0 && exit 1 echo 1 # 1 - Ok | 0 - Fail } case \" $1 \" in help | usage | -h | --help ) usage ;; discovery ) discovery $2 $3 ;; trapper ) trapper $2 ;; * ) discovery ;; esac Установка прав на скрипт: chown root:zabbix /etc/zabbix/scripts/lsimegaraid_discovery_trapper.sh chmod 750 /etc/zabbix/scripts/lsimegaraid_discovery_trapper.sh Не забываем про настройки в скрипте, где нужно указать полные пути до необходимых программ и конфигурационных файлов: MEGACLI = '/usr/local/sbin/MegaCli' ZABBIX_SENDER = '/usr/local/bin/zabbix_sender' CONFIG = '/etc/zabbix/zabbix_agentd.conf' Конфигурационный файл /etc/zabbix/zabbix_agentd.conf.d/lsimegaraid.conf : UserParameter = lsimegaraid.discovery [ * ] ,/usr/local/etc/zabbix24/scripts/lsimegaraid_discovery_trapper.sh \"discovery\" $1 $2 UserParameter = lsimegaraid.trapper [ * ] ,/usr/local/etc/zabbix24/scripts/lsimegaraid_discovery_trapper.sh \"trapper\" $1 Шаблон для zabbix : <zabbix_export> <version> 2.0 </version> <date> 2015-03-16T07:54:05Z </date> <groups> <group> <name> MyTemplates </name> </group> </groups> <templates> <template> <template> Template LSIMegaRaid_trapper </template> <name> Template LSIMegaRaid_trapper </name> <description/> <groups> <group> <name> MyTemplates </name> </group> </groups> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <items> <item> <name> Trapper </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.trapper[0] </key> <delay> 30 </delay> <history> 90 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item> </items> <discovery_rules> <discovery_rule> <name> LSIMegaRaid: Physical disks slot discovery </name> <type> 0 </type> <snmp_community/> <snmp_oid/> <key> lsimegaraid.discovery[physdiscovery,0] </key> <delay> 3600 </delay> <status> 0 </status> <allowed_hosts/> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <delay_flex/> <params/> <ipmi_sensor/> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <filter> <evaltype> 0 </evaltype> <formula/> <conditions/> </filter> <lifetime> 30 </lifetime> <description/> <item_prototypes> <item_prototype> <name> LSIMegaRaid: $1 Firmware State </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#PHYSNUM},state] </key> <delay> 0 </delay> <history> 365 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 4 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> LSIMegaRaid: $1 has flagged a S.M.A.R.T alert </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#PHYSNUM},smart] </key> <delay> 0 </delay> <history> 365 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 4 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> LSIMegaRaid: $1 Inquiry Data </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#PHYSNUM},inquiry] </key> <delay> 0 </delay> <history> 365 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 4 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> LSIMegaRaid: $1 Media Error Count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#PHYSNUM},mediaerror] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> LSIMegaRaid: $1 Other Error Count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#PHYSNUM},othererror] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> LSIMegaRaid: $1 Predictive Failure Count </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#PHYSNUM},failurecount] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> LSIMegaRaid: $1 Temperature </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#PHYSNUM},temperature] </key> <delay> 0 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units> C </units> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> </item_prototypes> <trigger_prototypes> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},smart].str(No)}=0 </expression> <name> LSIMegaRaid: {#PHYSNUM} has flagged a S.M.A.R.T alert on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},inquiry].diff(0)} &gt; 0 </expression> <name> LSIMegaRaid: {#PHYSNUM} inquiry data changed on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 1 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},mediaerror].last(0)} &gt; 0 </expression> <name> LSIMegaRaid: {#PHYSNUM} Media Error Count on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},othererror].last(0)} &gt; 0 </expression> <name> LSIMegaRaid: {#PHYSNUM} Other Error Count on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},failurecount].last(0)} &gt; 0 </expression> <name> LSIMegaRaid: {#PHYSNUM} Predictive Failure Count on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},state].str(Online)}=0 </expression> <name> LSIMegaRaid: {#PHYSNUM} state is not online on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},temperature].last(0)} &gt; 45 </expression> <name> LSIMegaRaid: {#PHYSNUM} temperature is high on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 4 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#PHYSNUM},temperature].last(0)} &gt; 49 </expression> <name> LSIMegaRaid: {#PHYSNUM} temperature is very high on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> </trigger_prototypes> <graph_prototypes/> <host_prototypes/> </discovery_rule> <discovery_rule> <name> LSIMegaRaid: Virtual disks discovery </name> <type> 0 </type> <snmp_community/> <snmp_oid/> <key> lsimegaraid.discovery[virtdiscovery,0] </key> <delay> 3600 </delay> <status> 0 </status> <allowed_hosts/> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <delay_flex/> <params/> <ipmi_sensor/> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <filter> <evaltype> 0 </evaltype> <formula/> <conditions/> </filter> <lifetime> 30 </lifetime> <description/> <item_prototypes> <item_prototype> <name> LSIMegaRaid: $1 Bad Blocks Exist </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#VIRTNUM},badblock] </key> <delay> 0 </delay> <history> 365 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 1 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> <item_prototype> <name> LSIMegaRaid: $1 State </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> lsimegaraid.data[{#VIRTNUM},state] </key> <delay> 0 </delay> <history> 365 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 1 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> LSI MegaRaid </name> </application> </applications> <valuemap/> <logtimefmt/> </item_prototype> </item_prototypes> <trigger_prototypes> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#VIRTNUM},badblock].str(No)}=0 </expression> <name> LSIMegaRaid: {#VIRTNUM} Bad Blocks Exist on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> <trigger_prototype> <expression> {Template LSIMegaRaid_trapper:lsimegaraid.data[{#VIRTNUM},state].str(Optimal)}=0 </expression> <name> LSIMegaRaid: {#VIRTNUM} state is not optimal on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 5 </priority> <description/> <type> 0 </type> </trigger_prototype> </trigger_prototypes> <graph_prototypes/> <host_prototypes/> </discovery_rule> </discovery_rules> <macros/> <templates/> <screens/> </template> </templates> </zabbix_export> Ссылки по теме: Мониторинг LSI MegaRAID в Zabbix Мониторинг состояния HDD в RAID контроллере LSI MegaRAID под Linux, средствами Nagios. Intel Raid Controller RS2BL040 Slow Performance – BBU problems. Perc RAID Controllers Adding a Hard Drive back into RAID on a Web Gateway 5000 or 5500 Intel based Appliance","tags":"Zabbix","title":"Мониторинг LSI MegaRAID в Zabbix"},{"url":"blog/find-all-hardlinks/","text":"#!/bin/sh [ -z \" $1 \" ] && cat <<-_EOF_ && exit 1 Usage: ./$(basename $0) filename _EOF_ FILE = $1 [ ! -f \" $FILE \" ] && echo \"File $FILE not exists! Exiting...\" && exit 1 if [ \" $( ls -ld \" $FILE \" | awk '{print $2}' ) \" -ne 1 ] ; then find ` df \" $FILE \" | tail -n+2 | awk '{print $6}' ` -xdev -inum ` ls -i \" $FILE \" | awk '{print $1}' ` else echo \"File $FILE is got only 1(one) link on filesystem...\" exit 1 fi Ссылки по теме: How can you see the actual hard link by ls?","tags":"Linux","title":"Найти все хардлинки(hardlinks) файла"},{"url":"blog/zabbix-tcp-connections/","text":"Скрипты и файлы конфигурации для мониторинга состояния TCP соединений. Шаблон для zabbix : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <zabbix_export> <version> 2.0 </version> <date> 2015-05-31T06:58:27Z </date> <groups> <group> <name> Linux servers </name> </group> </groups> <templates> <template> <template> Template UnixTcp </template> <name> Template UnixTcp </name> <groups> <group> <name> Linux servers </name> </group> </groups> <applications> <application> <name> TCP </name> </application> </applications> <items> <item> <name> CLOSE_WAIT </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.closew </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> ESTABLISHED </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.establ </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> FIN_WAIT1 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.finw1 </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> FIN_WAIT2 </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.finw2 </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> LISTEN </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.listen </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> SYN_RECV </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.synrecv </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> SYN_SENT </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.synsent </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> TIME_WAIT </name> <type> 2 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.timew </key> <delay> 60 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 0 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> <item> <name> Trapper </name> <type> 0 </type> <snmp_community/> <multiplier> 0 </multiplier> <snmp_oid/> <key> tcp.all </key> <delay> 30 </delay> <history> 7 </history> <trends> 365 </trends> <status> 0 </status> <value_type> 3 </value_type> <allowed_hosts/> <units/> <delta> 0 </delta> <snmpv3_contextname/> <snmpv3_securityname/> <snmpv3_securitylevel> 0 </snmpv3_securitylevel> <snmpv3_authprotocol> 0 </snmpv3_authprotocol> <snmpv3_authpassphrase/> <snmpv3_privprotocol> 0 </snmpv3_privprotocol> <snmpv3_privpassphrase/> <formula> 1 </formula> <delay_flex/> <params/> <ipmi_sensor/> <data_type> 0 </data_type> <authtype> 0 </authtype> <username/> <password/> <publickey/> <privatekey/> <port/> <description/> <inventory_link> 0 </inventory_link> <applications> <application> <name> TCP </name> </application> </applications> <valuemap/> <logtimefmt/> </item> </items> <discovery_rules/> <macros/> <templates/> <screens/> </template> </templates> <triggers> <trigger> <expression> {Template UnixTcp:tcp.establ.last(0)} &gt; 10000 </expression> <name> Too many ESTABLISHED connections on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 3 </priority> <description/> <type> 0 </type> <dependencies/> </trigger> <trigger> <expression> {Template UnixTcp:tcp.timew.last(0)} &gt; 30000 </expression> <name> Too many TIME_WAIT connections on {HOST.NAME} </name> <url/> <status> 0 </status> <priority> 3 </priority> <description/> <type> 0 </type> <dependencies/> </trigger> </triggers> <graphs> <graph> <name> TCP Connections </name> <width> 900 </width> <height> 200 </height> <yaxismin> 0.0000 </yaxismin> <yaxismax> 100.0000 </yaxismax> <show_work_period> 1 </show_work_period> <show_triggers> 1 </show_triggers> <type> 1 </type> <show_legend> 1 </show_legend> <show_3d> 0 </show_3d> <percent_left> 0.0000 </percent_left> <percent_right> 0.0000 </percent_right> <ymin_type_1> 0 </ymin_type_1> <ymax_type_1> 0 </ymax_type_1> <ymin_item_1> 0 </ymin_item_1> <ymax_item_1> 0 </ymax_item_1> <graph_items> <graph_item> <sortorder> 6 </sortorder> <drawtype> 1 </drawtype> <color> 009900 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.establ </key> </item> </graph_item> <graph_item> <sortorder> 3 </sortorder> <drawtype> 1 </drawtype> <color> 9999FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.closew </key> </item> </graph_item> <graph_item> <sortorder> 0 </sortorder> <drawtype> 1 </drawtype> <color> 3333FF </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.timew </key> </item> </graph_item> <graph_item> <sortorder> 5 </sortorder> <drawtype> 1 </drawtype> <color> DDDD00 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.synrecv </key> </item> </graph_item> <graph_item> <sortorder> 1 </sortorder> <drawtype> 1 </drawtype> <color> FFFF66 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.listen </key> </item> </graph_item> <graph_item> <sortorder> 4 </sortorder> <drawtype> 1 </drawtype> <color> BBBB00 </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.synsent </key> </item> </graph_item> <graph_item> <sortorder> 2 </sortorder> <drawtype> 1 </drawtype> <color> DDDDDD </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.finw1 </key> </item> </graph_item> <graph_item> <sortorder> 1 </sortorder> <drawtype> 1 </drawtype> <color> CCCCCC </color> <yaxisside> 0 </yaxisside> <calc_fnc> 2 </calc_fnc> <type> 0 </type> <item> <host> Template UnixTcp </host> <key> tcp.finw2 </key> </item> </graph_item> </graph_items> </graph> </graphs> </zabbix_export> Для удобства установки различных нестандартных метрик для мониторинга я использую директиву Include=/etc/zabbix/zabbix_agentd.conf.d/ после чего можно добавлять отдельные файлы, в которых будут все опции, необходимые для работы необходимой метрики, в данном случае: /etc/zabbix/zabbix_agentd.conf.d/tcp_status.conf : UserParameter = tcp.all,/etc/zabbix/scripts/tcp_status.sh Теперь создадим скрипт, который осуществляет доставку данных в Zabbix - /etc/zabbix/scripts/tcp_status.sh : #!/bin/sh # WARNING: Correctly setup 'Hostname=' in config is REQUIRED! /usr/bin/env ss -ant | \\ awk '{ if (NR>1) state[$1]++; } END { split(\"establ,listen,synsent,synrecv,finw1,finw2,closew,timew\",list,\",\") for (i in list) {array[list[i]]=0} for (i in state) { s=i; sub(/ESTAB/, \"establ\", s); sub(/LISTEN/, \"listen\", s); sub(/SYN-SENT/, \"synsent\", s); sub(/SYN-RECV/, \"synrecv\", s); sub(/FIN-WAIT-1/, \"finw1\", s); sub(/FIN-WAIT-2/, \"finw2\", s); sub(/CLOSE-WAIT/, \"closew\", s); sub(/TIME-WAIT/, \"timew\", s); array[s]=state[i] } for (i in array){print \"- tcp.\"i, array[i]} }' | /usr/bin/env zabbix_sender \\ --config /etc/zabbix/zabbix_agentd.conf \\ --input-file - >/dev/null 2 > & 1 echo $? exit 0 И сразу выставляем правильные права на скрипт: chmod 755 /etc/zabbix/scripts/tcp_status.sh chown zabbix:zabbix /etc/zabbix/scripts/tcp_status.sh Если каталога /etc/zabbix/scripts у вас еще нет, то его нужно создать: mkdir /etc/zabbix/scripts chmod 755 /etc/zabbix/scripts chown zabbix:zabbix /etc/zabbix/scripts Стоит отметить тот факт, что в скрипте используется ss (из пакета iproute2 ), вместо netstat , замеры и опыт использования показал, что ss быстрее. Все почти готово, теперь можно зайти в панель Zabbix и добавить нужному хосту новый шаблон Template UnixTcp .","tags":"Zabbix","title":"Zabbix: TCP connections"},{"url":"blog/taskhost-exe-thread-exit-cpu-high-usage/","text":"Обнаружил, что Windows 8.1 , установленная в Linux KVM со всеми необходимыми kvm драйверами после небольшого простоя начинает необоснованно потреблять процессор - 100% . Решение было не сложным - проблема в одной из штатных запланированных задач Windows : Go to Task Scheduler -> Microsoft -> Windows -> DiskFootPrint and disable the Diagnostics Task. taskhost.exe DfpCommon.dll thread high CPU utilization","tags":"Windows","title":"taskhost.exe \"Thread exit\" CPU high usage"},{"url":"blog/mac-os-hardware-compatible-table/","text":"MB Model Driver Chip P8B75mle VoodoHDA VT1708s VT1708s P7BH55D-M ALC892 ALC892 P8Z77-V ALC887 ALC887 P8H67 ALC887 ALC887","tags":"MacOSX","title":"MAC OS Hardware compatible table"},{"url":"blog/postgresql-create-database-and-user/","text":"Запускаем psql под пользователем postgres : su postgres -c psql Теперь в консоли PostgreSQL вводим следующие команды: create database dbname with encoding = 'UNICODE' ; create user dbuser with password 'dbpass' ; grant all privileges on database dbname to dbuser ; А также не забываем дать доступ новому пользователю к серверу, для этого в файле /var/lib/pgsql/data/pg_hba.conf : # For dbuser: host dbname dbuser 127 .0.0.1/32 md5 local dbname dbuser md5 Где: dbname – имя базы данных dbuser – имя пользователя dbpass – пароль пользователя dbuser И говорим серверу PostgreSQL перечитать измененный конфиг pg_hba.conf : root@Linux# service postgresql reload Скрипт для удобства: #!/bin/sh PGPORT = echo 'Input dbname: ' read dbname dbuser = ${ dbuser :- $dbname } echo \"Input dbuser: [ $dbuser ]\" # Generate by dbname. randpass = $( tr -cd A-Za-z < /dev/urandom | head -c8 ) echo \"Input dbpass [ $randpass ]:\" # Generate random. read dbpass dbpass = ${ dbpass :- $randpass } # Facepalm centos... Need fill path to binary psql: /usr/pgsql-9.3/bin/psql su - postgres -c \"/usr/pgsql-9.3/bin/psql --dbname= $DB --port= $PGPORT <<_EOF \\x CREATE DATABASE $dbname WITH ENCODING='UNICODE'; CREATE USER $dbuser WITH PASSWORD ' $dbpass '; GRANT ALL PRIVILEGES ON DATABASE $dbname TO $dbuser ; _EOF \" # TODO: check error code here. # Do backup modified cfg files. cp /var/lib/pgsql/data/pg_hba.conf /var/lib/pgsql/data/pg_hba.conf_ ` date +%s ` PGPORT = ${ PGPORT :- 5432 } [ -n \" $dbname \" -a -n \" $dbuser \" ] && cat <<-_EOF >>/var/lib/pgsql/data/pg_hba.conf # For $dbuser, generated at `date`: host $dbname $dbuser 127.0.0.1/32 md5 local $dbname $dbuser md5 _EOF # Do reload. service postgresql-9.3 reload Ссылки по теме: PostgreSQL. Как создать базу данных и пользователя для нее.","tags":"PostgreSQL","title":"PostgreSQL. Создать базу данных и пользователя для нее."},{"url":"blog/indent-expand-unexpand-alignment/","text":"Создадим файл с табуляцией: echo -e \"\\t1\\n 2\" | unexpand -t8 > 1 .txt Получим в 1.txt : <------>1 <------> 2 Где <------> - 1 таб. Приведем indent к одному виду - пробелам, где 1 таб равен 8 пробелам: expand -t8 1 .txt > 2 .txt Получим в 2.txt : 1 2 Получаем некий аналог dos2unix и unix2dos , только для табов и пробелов. Теперь о применении такого на практике, до недавнего времени я тоже не знал разницу между indentation и alignment . Приведу примеры о чем идет речь. Это — indentation : for ( int i = 0 ; i < 10 ; i ++ ) { if ( a [ i ] == 0 ) { do_something ( i ); } } А вот это — alignment : int some_variable = 0 ; int v1 = 0 ; Соль в том, что indentation не поплывет в разных редакторах, с разными размерами таба, а вот alignment с табами поплывет 100%. Следовательно, если хотим использовать табы, используем только в indentation , но alignment делаем исключительно пробелами. В таком случае использовать expand и unexpand нужно с особой осторожностью, чтобы не задеть aligement . Ссылки по теме: Пора завязывать использовать пробелы вместо табуляции в коде Примиряем любителей пробелов и табов","tags":"Bash","title":"Приводим документ к одному типу indent - expand, unexpand и немного про alignment."},{"url":"blog/inverted-tail-head/","text":"Очень короткая заметка про tail и head . Как известно head и tail работают с 10 первыми или последними строками соответственно. Но бывает необходимость получить все строки, кроме, например первых трех, или наоборот кроме последних 3. Приведу пример работы, вот простой файл: user@Ubuntu:~$ cat /etc/lsb-release DISTRIB_ID = Ubuntu DISTRIB_RELEASE = 14 .04 DISTRIB_CODENAME = trusty DISTRIB_DESCRIPTION = \"Ubuntu 14.04.1 LTS\" Получим из него все строки, кроме первой: user@Ubuntu:~$ tail -n+2 /etc/lsb-release DISTRIB_ID = Ubuntu DISTRIB_RELEASE = 14 .04 DISTRIB_CODENAME = trusty DISTRIB_DESCRIPTION = \"Ubuntu 14.04.1 LTS\" А теперь все кроме последних двух: bash user@Ubuntu:~$ head -n+3 /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=14.04 DISTRIB_CODENAME=trusty И живой пример использования, нужно получить из netstat количество соединений сгруппированных по типу, исключив первые 2 строки заголовка: user@Ubuntu:~$ netstat -ant | tail -n +3 | awk '{print $6}' | sort | uniq -c 1 CLOSE_WAIT 34 ESTABLISHED 8 LISTEN 2 SYN_SENT Или для удобства в цикле: user@Ubuntu:~$ while true ; do netstat -ant | tail -n +3 | awk '{print $6}' | sort | uniq -c ; echo ----------- ; sleep 1 ; done 1 CLOSE_WAIT 32 ESTABLISHED 8 LISTEN ----------- 1 CLOSE_WAIT 32 ESTABLISHED 8 LISTEN ----------- &#94;C Остановить цикл можно клавишами Ctrl+c .","tags":"Bash","title":"Инвертируем поведение tail и head"},{"url":"blog/wireshark-ubuntu/","text":"По умолчанию wireshark запускается с правами пользователя и не видит сетевые интерфейсы, использование данной возможности влияет на безопасность, поэтому приходится запускать от root . Если сомневаетесь, то используйте запуск wireshark от root . Dumpcap можно установить таким образом, что члены группы wireshark смогут захватывать пакеты - это более рекомендуемый способ захвата пакетов с помощью Wireshark / Tshark , чем запуск самого Wireshark / Tshark с правами root , так как это позволяет выполнять почти весь код с меньшими правами. Чтобы Wireshark начал видеть интерфейсы нужно разрешить группе wireshark использовать Dumpcap , для этого настраиваем пакет wireshark-common и добавляем своего пользователя в группу wireshark . dpkg-reconfigure wireshark-common usermod -aG wireshark $USER Ссылки по теме: Toster: Wireshark не видит сетевой интерфейс в Ubuntu 14.04, что делать?","tags":"Ubuntu","title":"Wireshark не видит сетевой интерфейс в Ubuntu"},{"url":"blog/mikrotik-wpa2-eap-wds-mesh/","text":"Постановка задачи, реализовать Wi-Fi сеть WPA2-EAP с авторизацией через LDAP учетки или сертификаты с бесшовным роумингом, используя WDS-MESH . При этом трафик Wi-Fi клиентов завернуть во vlan ( tagged ), а трафик самого роутера оставить без тега ( untagged ). Подготовка Сброс кнопкой Reset на корпусе. Подключаемся через Windox по кабелю 2-5 порты или Wifi , в открывшемся диалоговом окне сброс пока не нажимаем! Прописываем статический ip на ether1 , основной шлюз, DNS сервер . /ip address add address=10.10.0.101/24 interface=ether1 network=10.10.0.0 /ip dns set servers=10.10.10.254 /ip route add distance=1 gateway=10.10.0.1 Жмем сброс настроек в диалоговом окне (та самая кнопка, которую не нажимали в начале). Роутер произведет сброс заводских настроек, но оставит пользовательские. Если роутер, спустя минуту не ушол в ребут - делаем вручную. Подключаемся по статическому ip и делаем остальные настройки, Identity (я выбрал простой нейминг точек ap1 , ap2 ...), clock , SNTP , отключаем ненужные сервисы ( telnet , api ) и т.д... /system ntp client set enabled=yes primary-ntp=10.10.10.254 /system clock set time-zone-name=Asia/Novosibirsk /system identity set name=ap1 /ip service set telnet disabled=yes /ip service set ftp disabled=yes /ip service set api disabled=yes /ip service set api-ssl disabled=yes Добавляем интерфейс vlan5 от ether1 . /interface vlan add interface=ether1 l2mtu=1594 name=vlan5 vlan-id=5 Создаем Bridge интерфейс Называем его например br-vlan5 , добавляем в него порты wlan1 , vlan5 . /interface bridge add name=br-vlan5 /interface bridge port add bridge=br-vlan5 interface=wlan1 /interface bridge port add bridge=br-vlan5 interface=vlan5 Создаем Mesh интерфейс Называем его например Mesh-Interface , добавляем в него порт br-vlan5 . /interface mesh add hwmp-rann-propagation-delay=5 name=Mesh-Interface /interface mesh port add interface=br-vlan5 mesh=Mesh-Interfacee Создаем Security Profle : /interface wireless security-profiles add authentication-types=wpa2-eap management-protection=allowed mode=dynamic-keys name=WPA2-EAP-MESH Name: WPA2-EAP-MESH Mode: dynamic keys Authentication Types: [v] WPA2 EAP Unicast & Group Ciphers: aes ccm Supplicant Identity: ap1 (для каждой точки свой, на всякий случай, если вдруг точка начнет авторизовываться в RADIUS, будет легче найти проблемную). Management Protection: Disabled EAP Methods: passthrough TLS Mode: no certificates TLS Certificate: none Настраиваем wlan1 интерфейс: /interface wireless set [ find default-name=wlan1 ] band=2ghz-b/g/n disabled=no l2mtu=2290 mode=ap-bridge radio-name=AP1 security-profile=WPA2-EAP-MESH ssid=YOUR_SSID wds-default-bridge=Mesh-Interface wds-mode=dynamic-mesh wireless-protocol=802.11 Выбираем канал Частоту канал , я выбрал 2412 ВАЖНО , для работы WDS необходимо, чтобы канал на ВСЕХ роутерах был один. Mode: ap bridge Band: 2GHz-B/G/N Настройка SSID сети Wireless Protocol: 802.11 Security Profile: WPA2-EAP-MESH Bridge Mode: Enabled WDS Mode: Dynamic-Mesh WDS Default Bridge: Mesh-Interface Настройка WDS : Создаем Security-Profile , чтобы роутеры могли авторизовывать друг друга: /interface wireless security-profiles add authentication-types=wpa2-psk eap-methods=\"\" mode=dynamic-keys name=4WDS supplicant-identity=\"\" wpa2-pre-shared-key=wpa2password4wds Name: 4WDS Mode: dynamic keys Authentication Types: [v] WPA2 PSK Unicast & Group Ciphers: aes ccm WPA2 Pre-Shared Key: ОдинаковыйПарольНаВсехРоутерах Management Protection: Disabled Создаем Connect-List Добавляем в него MAC -адреса каждого роутера. /interface wireless connect-list add interface=wlan1 security-profile=4WDS wireless-protocol=802.11 mac-address=4C:5E:0C:XX:XX:01 comment=ap2 /interface wireless connect-list add interface=wlan1 security-profile=4WDS wireless-protocol=802.11 mac-address=4C:5E:0C:XX:XX:10 comment=ap3 Interface: Wlan1 Mac Address: XX:XX:XX:XX:XX:XX [V] Connect Wireless Protocol: 802.11 Security Profile: 4WDS Добавляем информацию о RADIUS сервере: /radius add address=10.10.10.254 secret=supersecretpwd service=wireless Service: [v] wireless Address: 10.10.10.254 (у меня RADIUS на этом сервере). Secret: ***** (Пароль от радиус сервера). Authentication Port: 1812 (стандартный) Accounting Port: 1813 (стандартный) Настройка RADIUS сервера: Продолжение следует... Технология надежд не оправдала, возможно я неправильно что-то сделал, спустя какое-то время вернули обратно в обычный режим WPA2-EAP с разными частотами каналами и заниженой мощьностью передатчика (исходили из расчета ~10-20 активных клиентов на 1 точку доступа). Ссылки по теме: Manual:Interface/Wireless Wireless WDS Mesh Контроллер Wi-Fi точек доступа на Mikrotik","tags":"Mikrotik","title":"Mikrotik WPA2-EAP WDS MESH"},{"url":"blog/marc-sql-1.5.4-mysql-5.x/","text":"Столкнулся с проблемой, АИБС \"МАРК-SQL\" для школьных библиотек 1.5.4 не работала с MySQL , а разработчики заверяли, что программа не совместима с MySQL . Решил проанализировать запросы, которые ходят между программой и сервером при помощи MySQL-Proxy [2] . И сразу увидел некорректный запрос с использованием зарезервированного слова SEPARATOR : SELECT TAG , SUBTAG , FLAGS , SEPARATOR , CAPTION FROM TAG После добавления обратных кавычек к зарезервированному слову SEPARATOR [1] запрос выполнился в MySQL без проблем: SELECT TAG , SUBTAG , FLAGS , ` SEPARATOR ` , CAPTION FROM TAG Значит для нормальной работы программы АИБС \"МАРК-SQL\" для школьных библиотек 1.5.4 нужно ловить каждый запрос, и если требуется, экранировать зарезервированные слова MySQL на лету. С этой задачей вполне успешно справится MySQL-Proxy [2] с поддержкой lua скриптов [4] . После установки, запуска MySQL-Proxy и подключения lua скрипта: function MyDebug ( str ) -- enable\\disable debug messages print to stdout. local dbg = 0 if dbg == 1 then print ( '[DEBUG] ' .. str ) end end function read_query ( packet ) local file = io.open ( '/var/log/mysql-proxy.log' , 'a' ) local q = string.sub ( packet , 2 ) MyDebug ( 'Orig. Query: ' .. q ) file : write ( 'Orig. Query: ' .. q .. ' \\n ' ) -- Таблица зарезервированных слов MySQL. -- http://dev.mysql.com/doc/mysqld-version-reference/en/mysqld-version-reference-reservedwords-5-7.html q = string.gsub ( q , '(SEPARATOR)' , '`%1`' ) q = string.gsub ( q , '(INT%d)' , '`%1`' ) -- Исправление поискового запроса (захардкоженного в marcp.exe) и регистронезависимый поиск. local _ , _ , str1 , str2 , str3 = string.find ( q , \"SELECT TERM,CNT FROM (.-) WHERE TERM%s*>=%s*('.-')%s(.*)\" ) -- TODO: проверить всегда ли передаются кавычки в поле WHERE TERM >= ''. if str1 ~= nil and str2 ~= nil and str3 ~= nil then MyDebug ( 'str1: ' .. str1 ); MyDebug ( 'str2: ' .. str2 ); MyDebug ( 'str3: ' .. str3 ) str2 = string.gsub ( str2 , \"&#94;'\" , '' ) -- Delete start '. str2 = string.gsub ( str2 , \"'$\" , '' ) -- Delete end '. MyDebug ( 'Fixed str2: ' .. str2 ) q = string.format ( \"SELECT TERM,CNT FROM %s WHERE LOWER(TERM) LIKE LOWER('%s%%') %s\" , str1 , str2 , str3 ) end -- Исправляем кавычки в запросе. q = string.gsub ( q , 'SELECT CODE,NAME FROM%s+\"(.+)\"%s*(.*)' , 'SELECT CODE,NAME FROM `%1` %2' ) -- Del start '. MyDebug ( 'Fixed query: ' .. q .. ' \\n ' ) file : write ( 'Fixed query: ' .. q .. ' \\n ' ) file : close () proxy . queries : append ( 2 , string.char ( proxy . COM_QUERY ) .. q , { resultset_is_needed = true }) return proxy . PROXY_SEND_QUERY end function read_query_result ( inj ) if inj . id == 1 and inj . resultset . rows ~= nil then local file = io.open ( '/var/log/mysql-proxy.log' , 'a' ) for row in inj . resultset . rows do local i = 1 local fields = {} while row [ i ] do if row [ i ] == row then break end file : write ( 'Response field: ' .. inj . resultset . fields [ i ]. name .. ' => ' .. row [ i ] .. ' \\n ' ) i = i + 1 end end file : close () return proxy . PROXY_IGNORE_RESULT end end В ходе экспериментов для подключения к БД был получен такой конфиг dns.ini для работы с MySQL : Универс|DRIVER = MySQL ODBC 5.2 Unicode Driver;NO_SSPS=1;MULTI_STATEMENTS=1;AUTO_RECONNECT=1;LOG_QUERY=0;IGNORE_SPACE=1;COMPRESSED_PROTO=1;NO_PROMPT=1;CHARSET=cp1251;DATABASE=marcsql;SERVER=192.168.4.26;PORT=4040;UID=marcsql;PASSWORD=password; Описание некоторых опций: NO_SSPS=1; - Включение подстановок на стороне клиента, а не сервера (т.е. запросы в которых есть знаки \"?\"). COMPRESSED_PROTO=1; - Включение сжатия (немного повышается скорость работы с большими результатами запросов). NO_PROMPT=1; - Отключение окна запроса, при переподключении к БД. CHARSET=cp1251; - Кодировка в которой будет идти обмен между сервером и клиентом (программа для Windows и работает в cp1251 ). BASE=marcsql; - Имя базы. SERVER=192.168.4.26; - Адрес сервера MySQL-Proxy . PORT=4040; - Порт на котором работает MySQL-Proxy . UID=marcsql; - Логин, для подключения к БД. PASSWORD=password; - Пароль, для подключения к БД. Но на этом рано останавливаться, нужно еще привести в порядок запросы в файлах программы да и самой программе объяснить, что мы будем использовать MySQL , а не MS Access : Добавляем в конец информацию о MySQL в bin/db.ini : [Mysql] ScriptPath = ..\\sql\\Mysql CreateTempTable = CREATE TABLE &Table&TabSuf(DOC_ID INTEGER PRIMARY KEY) DictQuery = SELECT TERM,CNT FROM &Table В файле DbmsParams.ini : [Mysql] $VARCHAR = VARCHAR $COUNTER = INT AUTO_INCREMENT $DOUBLE = FLOAT $LONGTEXT = TEXT $LONGBINARY = TEXT $MIDTEXT = TEXT $TEXT = TEXT $DBPREF_ = marcsql. $COLUMN = $TOP1000 = $ALTERCOLUMN = ALTER COLUMN Добавляем информацию о возрастном маркере в EditMap.ini : [333a] EditForm = TECombo ComboValues = 0+ Для дошкольного возраста,6+ Для младшего школьного возраста,12+ Для среднего школьного возраста,16+ Для старшего школьного возраста,18+ Для взрослых TagValues = Для дошкольного возраста,Для младшего школьного возраста,Для среднего школьного возраста,Для старшего школьного возраста,Для взрослых Separator = , OnlyFormEdit = Yes DefaultMenu = NO [200e] EditForm = TECombo ComboValues = [0+],[6+],[12+],[16+],[18+] TagValues = [0+],[6+],[12+],[16+],[18+] Separator = , OnlyFormEdit = Yes DefaultMenu = NO Добавляем редактор LibreOffice в файле marc.ini в секцию [Editors] : [Editors] LibreOffice = swriter.exe Изменяем файл phase.ini под потребности нашей школы: [Книги] CreateTags = 245anpbco,100ae,700ae,653a,520a,020ac,090ax,084a,110a,260abc,440a,650a,200e,300ab,333a,952be,526cde,250a,998а,773b,773d,773t,773g,013ddee EditTags = 245,100,700,653,520,020,090,084,110,200,260,440,650,300,333,952,526,250,998,773 ViewTags = 100a,100e,700a,700e,245a,245b,245o,245p,245n,260a,260b,260c,300a,300b,333a,440a,020a,020c,650a,090a,090x,084a ShowAllTags = YES RecType = a BibLevel = m В файле RdrData.ini , в секции [Common] исправляем запрос LastReaderQuery : LastReaderQuery = SELECT RDR_ID FROM &ReadersPrefREADERS ORDER BY LEN(RDR_ID) DESC, RDR_ID DESC LIMIT 1 Теперь SQL файлы , заходим в каталог sql : Была проблема при удалении записей из таблиц словарей, исправляется в файле delidx.sql : Ищем строку: DELETE FROM & Table WHERE CNT = 0 ; Заменяем её на: DELETE FROM & Table WHERE CNT <= 0 ; Исправляем проблему с удалением данных из таблицы METAIDX ищем в файле dropdict.sql строку: DELETE FROM METAIDX WHERE NAME = '&Table.TERM' Заменяем её на: DELETE FROM ` METAIDX ` WHERE ` NAME ` = '&Table.`TERM`' ; DELETE FROM ` METAIDX ` WHERE ` NAME ` = '&Table.TERM' ; Теперь создаем каталог Mysql и копируем все файлы из каталога Access в созданный каталог Mysql (напоминаю, мы должны быть в каталоге sql ). Другими словами мы должны получить копию папки sql/Acess , но по адресу sql/Mysql . И приводим в порядок файлы в каталоге sql/Mysql : Файл crdict.sql приводим к такому виду: INSERT INTO METAIDX ( ` NAME ` , ` TYPE ` , ` MAXLEN ` , ` TAGS ` , ` CAPTION ` , ` SEP ` ) VALUES ( '&Table.`TERM`' , '&Type' , & MaxLen , '&Taglist' , '&Caption' , '&Sep' ); CREATE TABLE & Table ( ` IDX_ID ` INT AUTO_INCREMENT NOT NULL PRIMARY KEY , ` TERM ` VARCHAR ( & MaxLen ), ` CNT ` INTEGER ); CREATE TABLE `& TableX ` ( ` IDX_ID ` INTEGER NOT NULL , ` DOC_ID ` INTEGER NOT NULL , FOREIGN KEY ( ` IDX_ID ` ) REFERENCES `& Table ` ( ` IDX_ID ` )); CREATE INDEX & TableXB ON & TableX ( ` DOC_ID ` ); CREATE INDEX & TableXC ON & TableX ( ` IDX_ID ` ); Файл rebuild.sql приводим к такому виду: DROP TABLE IF EXISTS ` IDXTEMP ` ; CREATE TABLE ` IDXTEMP ` ( ` DOC_ID ` INTEGER , & Term Text ); $ BUILD ; $Инициализация таблицы индексов ; DELETE FROM & TableX ; DELETE FROM & Table ; $Заполнение таблицы индексов ; INSERT INTO & Table ( & Term , CNT ) SELECT & Term , Count ( & Term ) FROM IDXTEMP GROUP BY & Term ; $Заполнение таблицы перекрестных ссылок ; INSERT INTO & TableX ( IDX_ID , DOC_ID ) SELECT & Table . IDX_ID , IDXTEMP . DOC_ID FROM & Table , IDXTEMP WHERE IDXTEMP . & Term =& Table . & Term ; $Удаление временной таблицы ; DROP TABLE IDXTEMP ; На этом изменения в файлах программы окончены. Пришло время конвертировать базу, я конвертировал при помощи BullZip Access To MySQL [6] , на выходе получил .sql файл, который был скопирован на сервер и залит в БД. На этом все. Ссылки по теме: Reserved Words in MySQL 5.0 Download MySQL Proxy Download Connector/ODBC 20.1 – Pattern-Matching Functions MySQL On air. Мониторим SQL запросы BullZip Access To MySQL MySQL и MarcSQL Версия АИБС \"МАРК-SQL\" для школьных библиотек находится в свободном доступе для российских школ.","tags":"Windows","title":"Запуск и адаптация МАРК-SQL 1.5.4 для MySQL 5.x"},{"url":"blog/windows-cli-ntp-cmd-bat/","text":"Короткая заметка про настройку NTP клиента в Windows . Для настройки вручную из cmd можно воспользоваться командами: C : \\ >net time /setsntp:<IP-адрес или FQDN-имя NTP-сервера локальной сети> The command completed successfully. C : \\ >net stop w32time The Windows Time service is stopping. The Windows Time service was stopped successfully. C : \\ >net start w32time The Windows Time service is starting. The Windows Time service was started successfully. C : \\ >net time /querysntp The current SNTP value is: < IP-адрес или FQDN-имя NTP-сервера локальной сети> The command completed successfully. Или объединить их в bat или cmd скрипт: @ ECHO OFF : : IP-адрес или FQDN-имя NTP-сервера локальной сети. SET \"NTP_SRV=ntp.domain.ltd\" net time /setsntp: %NTP_SRV% net stop w32time net start w32time net time /querysntp Ссылки по теме: NTP Server на Linux (ntpd)","tags":"Windows","title":"Настройка NTP клиента в Windows из cmd, cli, bat"},{"url":"blog/ubuntu-1404-windows-zip-fix-codepage/","text":"Исправляем проблему с zip архивами между Ubuntu 14.04 и Windows : sudo add-apt-repository ppa:frol/zip-i18n sudo sed -i '' 's/trusty/precise/g' /etc/apt/sources.list.d/frol-zip-i18n-trusty.list sudo apt-get update sudo apt-get install zip unzip p7zip-full В добавляемом репозитории пока нет пакетов для Ubuntu 14.04 ( trusty ), но есть для Ubuntu 12.04 ( precise ). sed 'ом вручную переключаемся на ветку precise - пакеты совместимы с trusty . Должны будут установиться пакеты libnatspec0 и p7zip-full . Ссылки по теме: Zip/unzip internationalization PPA","tags":"Ubuntu","title":"Ubuntu 14.04 и Windows zip архивы - исправляем проблему с кодировками."},{"url":"blog/zimbra-sendasdistlist/","text":"Для начала необходимо переключиться на учетную запись zimbra : sudo su zimbra Для выдачи пользователю права на отправку от списка рассылки: zmprov grr dl list@example.tld usr user@example.tld sendAsDistList Для отзыва, соответственно: zmprov rvr dl list@example.tld usr user@example.tld sendAsDistList Есть еще вариант, который не пробовал: Preferences - Accounts - Add Persona Persona Name: ListName Settings for Sent Messages _From: ListName list@example.ltd Reply-to [v]: ListName list@example.ltd Use this persona: [v] list@example.ltd Письмо будет уходить от его учетки, но в имя будет вписано то, что указано в поле From , ответ клиенты будут отправлять на адрес и имя, которое указано в Reply-to . Так же, будет выбираться автоматически отправитель, при ответе на письма, пришедшие на адрес list@example.ltd (на самом деле это список рассылки и скорей всего у клиента будут указаны все участники списка рассылки). Ссылки по теме: Отправка от списка рассылки","tags":"Zimbra","title":"Zimbra: Отправка от списка рассылки"},{"url":"blog/remmina-rdp-windows/","text":"Перестала подключатся Remmina по RDP , пишет Невозможно подключиться к серверу RDP . Решилось все просто, Remmina использует freerdp для работы по протоколу RDP , и все хосты добавляются в файл ~/.freerdp/known_hosts , наподобие как в ssh . Проблема аналогичная как и в ssh - если сменился ключ/сертификат - значит невозможно подключиться к серверу - в ssh нам рекомендуют удалить запись о сервере куда подключаемся из файла known_hosts , аналогично делаем и с freerdp : mcedit ~/.freerdp/known_hosts Формат записей аналогичный - 1 строка - 1 сервер. Удаляем нужную нам запись, сохраняем файл и подключаемся.","tags":"Ubuntu","title":"Remmina - ошибка \"Невозможно подключиться к серверу RDP\" при подключении к windows"},{"url":"blog/auto-create-dir-var-run-php5-fpm/","text":"После установки php-fpm , иногда бывает удобно хранить все его сокеты в отдельной папке, например /var/run/php5-fpm , но если вручную создать такую папку, то после перезагрузки система ее удаляет, а в логе можно увидеть типа: ERROR: unable to bind listening socket for address '/var/run/php5-fpm/default.sock' : No such file or directory. Это связано с тем, что /var/run монтируется с опцией --bind из /run [1] , где файловая система tmpfs , логично, что после перезагрузки все, что создавал пользователь - удаляется! Но не проблема, значит перед запуском демона, нужно проверять, существует ли каталог, если нет, то создавать. Для решения данной проблемы нужно отредактировать init-скрипт /etc/init.d/php5-fpm , добавив вверху, после переменной SCRIPTNAME строчку: SOCKETDIR = /var/run/ $NAME А затем, под do_start() { добавить еще одну строчку: [ -d $SOCKETDIR ] || install -m 777 -o www-data -g root -d $SOCKETDIR -m 777 я указал намеренно, т.к. у меня fpm пулы запускаются от разных uid:gid , если у вас все пулы работают от 1 пользователя, то можете указать -m 755 . Теперь, при запуске php-fpm демона, каталог с сокетами в /var/run будет создаваться автоматически. UPDATE: 15.10.2014 Для тех кто пользуется upstart , приводим файл /etc/init/php5-fpm.conf к такому виду: # php5-fpm - The PHP FastCGI Process Manager description \"The PHP FastCGI Process Manager\" author \"Ondřej Surý <ondrej@debian.org>\" start on runlevel [ 2345 ] stop on runlevel [ 016 ] # Precise upstart does not support reload signal, and thus rejects the # job. We'd rather start the daemon, instead of forcing users to # reboot https://bugs.launchpad.net/ubuntu/+source/php5/+bug/1272788 # # reload signal USR2 pre-start script [ -d /var/run/php5-fpm ] || install -m 777 -o www-data -g root -d /var/run/php5-fpm /usr/lib/php5/php5-fpm-checkconf end script respawn exec /usr/sbin/php5-fpm --nodaemonize --fpm-config /etc/php5/fpm/php-fpm.conf Изменился блок pre-start , теперь там script , в котором собственно и стоит проверка каталога /var/run/php5-fpm , идея подсмотрена в /etc/init/mysql.conf . Для применения изменений в upstart скрипты, необходимо выполнить команды: root@Ubuntu# initctl reload-configuration root@Ubuntu# initctl stop php5-fpm initctl: Unknown instance: root@Ubuntu# initctl start php5-fpm php5-fpm start/running, process 18467 Обязательно stop (если был запущен демон php5-fpm ), а затем start . Если демон php-fpm не был запущен, то restart скажет вам initctl: Unknown instance: \" и не запустит демона. Так что лучше сперва stop и затем start - это избавит от лишних раздумий, как устроена система upstart и почему restart не запускает демона. Логи запуска через upstart можно подглядеть в dmesg , /var/log/upstart/php5-fpm.log . P.S. команды service php5-fpm start будут обработаны upstart , а init.d скрипты проигнорированы, так вот запутано все в Ubuntu . Ссылки по теме: Opennet.ru: В Fedora и других Linux-дистрибутивах появится директория /run Создание директории /var/run/php5-fpm после перезагрузки","tags":"Ubuntu","title":"Автоматическое создание директории /var/run/php5-fpm после перезагрузки"},{"url":"blog/ubuntu-fix-all-grub-bugs-in-one-script/","text":"Скрипт для исправления проблем в GRUB в 1 клик. Возможно применение в автоматизированных скриптах. #!/bin/sh load_default_grub () { . /etc/default/grub } get_yes_no () { while [ true ] ; do echo -n \" $1 (Y/N) ? \" read a echo if [ $? ! = 0 ] ; then a = 'No' ; return ; fi case $a in [ Yy ][ Ee ][ Ss ] | [ Yy ]) a = 'Yes' ; return ;; [ Nn ][ Oo ] | [ Nn ]) a = 'No' ; return ;; * ) ;; esac done } # Load config and uncomment variable. load_default_grub if ( grep -qwai '&#94;#GRUB_DISABLE_RECOVERY=' /etc/default/grub >/dev/null ) ; then echo 'INFO: Uncomment the GRUB_DISABLE_RECOVERY variable.' sed -i 's/&#94;#GRUB_DISABLE_RECOVERY=\\(.*\\)/GRUB_DISABLE_RECOVERY=\\1/' /etc/default/grub fi # Load config again, check value and set if need. load_default_grub if [ \" $GRUB_DISABLE_RECOVERY \" ! = 'true' ] ; then if [ -z \" $GRUB_DISABLE_RECOVERY \" ] ; then echo 'INFO: Add GRUB_DISABLE_RECOVERY=\"true\"' echo 'GRUB_DISABLE_RECOVERY=\"true\"' >> /etc/default/grub else echo 'INFO: Set GRUB_DISABLE_RECOVERY to \"true\"' sed -i 's/&#94;GRUB_DISABLE_RECOVERY=.*/GRUB_DISABLE_RECOVERY=\"true\"/' /etc/default/grub fi fi # Delete deprecated options GRUB_HIDDEN_TIMEOUT*. if ( grep -qwai '&#94;GRUB_HIDDEN_TIMEOUT.*' /etc/default/grub >/dev/null ) ; then echo 'INFO: Delete deprecated options GRUB_HIDDEN_TIMEOUT*' sed -i '/&#94;GRUB_HIDDEN_TIMEOUT.*/d' /etc/default/grub fi # Add option GRUB_RECORDFAIL_TIMEOUT=15 for automatic boot on fail. if ! ( grep -qwai '&#94;GRUB_RECORDFAIL_TIMEOUT=.*' /etc/default/grub >/dev/null ) ; then echo 'INFO: Add option GRUB_RECORDFAIL_TIMEOUT=15 for automatic boot on fail.' echo 'GRUB_RECORDFAIL_TIMEOUT=15' >> /etc/default/grub fi # GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\" if ( grep -qwai '&#94;GRUB_CMDLINE_LINUX_DEFAULT=.*' /etc/default/grub >/dev/null ) ; then # Load config again, check value and set if need. load_default_grub for i in $GRUB_CMDLINE_LINUX_DEFAULT ; do case \" $i \" in 'splash' ) i = 'nosplash' ;; 'quiet' ) i = 'noquiet' ;; esac if [ -n \" $GRUB_CMDLINE_LINUX_DEFAULT_OUT \" -a -n \" $i \" ] ; then GRUB_CMDLINE_LINUX_DEFAULT_OUT = \" $GRUB_CMDLINE_LINUX_DEFAULT_OUT $i \" else GRUB_CMDLINE_LINUX_DEFAULT_OUT = \" $i \" fi done sed -i -e \"s/&#94;GRUB_CMDLINE_LINUX_DEFAULT=.*/GRUB_CMDLINE_LINUX_DEFAULT=\\\" $GRUB_CMDLINE_LINUX_DEFAULT_OUT \\\"/\" /etc/default/grub fi # Finnaly re-generate grub.cfg. get_yes_no \"Do you want to run update-grub\" [ $a = 'Yes' ] && update-grub","tags":"Ubuntu","title":"Скрипт для исправления проблем в Ubuntu GRUB в 1 клик."},{"url":"blog/ubuntu-1204-samba-bridge/","text":"При старте системы демон Samba не запускался самостоятельно, точнее он запускался, но был недоступен, а если вручную перезапустить его, то все ок. Сетевые интерфейсы у меня объединены в Bridge br0 из wlan0 и eth0 . После недолгих расследований логов загрузки, стало ясно, демон smbd успевает запуститься, до того, как bridge сконфигурируется, отсюда и проблема. Конфигурационный upstart файл /etc/init/smbd.conf привел к такому виду: description \"SMB/CIFS File Server\" author \"Steve Langasek <steve.langasek@ubuntu.com>\" start on ( local-filesystems and net-device-up IFACE! = lo ) start on ( local-filesystems and net-device-up IFACE = br0 ) stop on runlevel [ !2345 ] respawn pre-start script RUN_MODE = \"daemons\" [ -r /etc/default/samba ] && . /etc/default/samba [ \" $RUN_MODE \" = inetd ] && { stop ; exit 0 ; } install -o root -g root -m 755 -d /var/run/samba end script exec smbd -F А именно, добавил опцию IFACE=br0 : start on ( local-filesystems and net-device-up IFACE = br0 ) Теперь, при загрузке сервера, демон smbd запускается самостоятельно. Ссылки по теме: Что такое UpStart","tags":"Ubuntu","title":"Ubuntu 12.04 не запускается автоматически samba на bridge интерфейсе."},{"url":"blog/grub_hidden_timeout-no-longer-supported/","text":"Столкнулся с проблемой после обновления системы Ubuntu 12.04 , а так же Ubuntu 14.04 и Ubuntu 16.04 : root@Ubuntu:/# update-grub Generating grub configuration file ... Найден фон: /home/metall/Изображения/grub/about_1600px.png Предупреждение: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported. Found background image: /home/metall/Изображения/grub/about_1600px.png Найден образ linux: /boot/vmlinuz-3.13.0-24-generic Найден образ initrd: /boot/initrd.img-3.13.0-24-generic Найден Windows 7 ( loader ) на /dev/sda1 завершено root@Ubuntu:/# При генерации grub.cfg появляется сообщение о том, что GRUB_HIDDEN_TIMEOUT больше не поддерживается: Предупреждение: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported. Как выяснилось в установщике Ubuntu имеется баг [1] исправить ситуацию легко, просто закоментируем эту опцию в файле /etc/default/grub : #GRUB_HIDDEN_TIMEOUT=0 И обновим конфигурацию grub : root@Ubuntu:/# update-grub Generating grub configuration file ... Найден фон: /home/metall/Изображения/grub/about_1600px.png Found background image: /home/metall/Изображения/grub/about_1600px.png Найден образ linux: /boot/vmlinuz-3.13.0-24-generic Найден образ initrd: /boot/initrd.img-3.13.0-24-generic Найден Windows 7 ( loader ) на /dev/sda1 завершено root@Ubuntu:/# Как видим проблема ушла. Кстати, если установить конфиг из пакета, то эта опция там закоментирована: dpkg-reconfigure grub-pc Ссылки по теме: Warning: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported.","tags":"Linux","title":"GRUB_HIDDEN_TIMEOUT no longer supported, (deprecated)."},{"url":"blog/ubuntu-grub2-recordfail/","text":"В Ubuntu есть проблема - в случае нештатного отключения компьютера (вырубили свет, потом включили) GRUB2 доходит до меню и ждет выбора. Хотелось, чтобы компьютер рестартовал сам при включении света. Как оказалось за это отвечает переменная recordfail , которая по умолчанию выставляется recordfail=1 , а после успешной загрузки системы она обнуляется через init.d скрипт /etc/init.d/grub-common . При загрузке GRUB2 в файле /boot/grub/grub.cfg идет проверка: if [ ${ recordfail } = 1 ] ; then set timeout = -1 else set timeout = 0 Таким образом GRUB2 в случае если система была выключена не штатно принудительно выводит меню загрузки и ждет пока администратор в ручную выберет что грузить. Это делается для предотвращения зацикливания загрузки системы, если там что-то серьезно навернулось. Прямое редактирование /boot/grub/grub.cfg смысла не имеет, т.к. все изменения затрутся, при запуске команды update-grub , поиск по скриптам GRUB2 показал, что в файле /etc/grub.d/00_header есть описание функции recordfail : function recordfail { set recordfail = 1 EOF FS = \" $( grub-probe --target = fs \" ${ grubdir } \" ) \" case \" $FS \" in btrfs | cpiofs | newc | odc | romfs | squash4 | tarfs | zfs ) cat <<EOF # GRUB lacks write support for $FS, so recordfail support is disabled. EOF ;; * ) cat <<EOF if [ -n \"\\${have_grubenv}\" ]; then if [ -z \"\\${boot_once}\" ]; then save_env recordfail; fi; fi EOF esac cat <<EOF } Затем ниже проверка значения переменной recordfail : make_timeout () { cat << EOF if [ \"\\${recordfail}\" = 1 ] ; then set timeout=${GRUB_RECORDFAIL_TIMEOUT:--1} else EOF Решение проблемы напрашивается сам собой - установить переменную GRUB_RECORDFAIL_TIMEOUT (таймаут при срабатывании recordfail ) в конфигурационном файле GRUB2 /etc/default/grub : GRUB_RECORDFAIL_TIMEOUT = 15 После чего выполнить обновление конфигурации командой: update-grub Ссылки по теме: правильное выключение + GRUB2 отключить подтверждение при перезагрузке recordfail в grub2 [РЕШЕНО]","tags":"Ubuntu","title":"Ubuntu GRUB2 отключить подтверждение при перезагрузке"},{"url":"blog/flock-crontab/","text":"Столкнулся с проблемой, написанный мною бот для сайта запускался раз в минуту и однажды на сервере, где работал бот интернет канал сильно просел, как результат за минуту бот не успел завершить свою работу. crontab запустил его еще раз, бот снова не успел, а crontab продолжал беспощадно запускать копии бота - последствия были не очень приятными. Но проблема решилась очень просто, через flock . Теперь скрипт не запускается до тех пор, пока предыдущий запуск не закончит работу! Например, запуск произвольного скрипта из crontab раз в минуту: * * * * * root flock -n /tmp/script.lock -c /path/to/script.sh Рассмотрим опции: -n /tmp/script.lock - путь до lock файла. -c /path/to/script.sh - путь до скрипта или программы, которую нужно запустить. Эта утилита имеется штатно на FreeBSD и Linux .","tags":"Linux","title":"flock - предотвращение повторного запуска программы/скрипта из crontab."},{"url":"blog/putty-non-printable-tab-and-space/","text":"После обновления Putty до 0.63 столкнулся с проблемой, не отображались непечатаемые символы (табуляция <----> и пробел . ), исправляется установкой опции Change Settings -> Window -> Colours Indicate bolded text by changing : в \" True Color \". Не забываем сохранить настройки в стандартную сессию ( Default Session ). Результат: А вот так выглядит тот же файл, с проблемными, стандартными настройками Putty : Q: При копировании из редактора в буфер обмена тект вставляется с точками . и <----> . A: Убрать подсветку пробелов и табуляции в mc можно, нажав Alt+Shift+- . Ссылки по теме: Ответы на часто задаваемые вопросы","tags":"Windows","title":"Putty и непечатаемые символы табуляции(<----->) и поробела(.)"},{"url":"blog/generate-ssl-certificates/","text":"Скрипт генерации ssl сертификатов и ключей для nginx : #!/bin/sh error () { echo 'ERROR detected! Exiting...' exit 1 } ################################################# DOMAIN = 'domain.com' EMAIL = 'admin@domain.com' ORGANISATION = 'Organisation' CITY = 'you city' RSA_BIT = 2048 DAYS = 99365 ################################################# # Генерируем пароль для ключей. PASS = $( tr -cd A-Za-z < /dev/urandom | head -c8 ) echo 'Generated Password: ' ${ PASS } # Проверим, если не существует каталог для домена, то создаем его. [ ! -d ${ DOMAIN } ] && mkdir ${ DOMAIN } && echo 'Create directory: ' ${ DOMAIN } # http://linuxcmd.ru/openssl-genrsa-sozdanie-fayla-klyuchey echo \"Now create the server private key, you'll be asked for a passphrase:\" openssl genrsa -des3 -out ${ DOMAIN } / ${ DOMAIN } .key -passout pass: ${ PASS } ${ RSA_BIT } [ $? -eq 1 ] && error # http://linuxcmd.ru/openssl-req-sozdanie-csr-zaprosa # В пункте Common Name (eg, YOUR name) []: надо указать именно имя домена (без http, https, /): имя.домена echo 'Create the Certificate Signing Request (CSR):' openssl req -out ${ DOMAIN } / ${ DOMAIN } .csr -new -newkey rsa: ${ RSA_BIT } \\ -subj /C = RU/ST = ${ CITY } /L = ${ CITY } /O = ${ ORGANISATION } /OU = ${ ORGANISATION } /CN = *. ${ DOMAIN } /emailAddress = ${ EMAIL } \\ -nodes -keyout ${ DOMAIN } / ${ DOMAIN } .key -passout pass: ${ PASS } [ $? -eq 1 ] && error # Starting up nginx with SSL using the above private key: echo 'Remove the necessity of entering a passphrase for:' cp ${ DOMAIN } / ${ DOMAIN } .key ${ DOMAIN } / ${ DOMAIN } .key.org openssl rsa -in ${ DOMAIN } / ${ DOMAIN } .key.org -out ${ DOMAIN } / ${ DOMAIN } .key [ $? -eq 1 ] && error echo 'Finally sign the certificate using the above private key and CSR:' openssl x509 -req -days ${ DAYS } -in ${ DOMAIN } / ${ DOMAIN } .csr -signkey ${ DOMAIN } / ${ DOMAIN } .key -out ${ DOMAIN } / ${ DOMAIN } .crt [ $? -eq 1 ] && error # http://wiki.nginx.org/HttpSslModule cat <<_EOF # Update Nginx configuration by including the newly signed certificate and private key: server { listen 443; server_name YOUR_DOMAINNAME_HERE; ssl on; ssl_certificate /usr/local/nginx/conf/server.crt; ssl_certificate_key /usr/local/nginx/conf/server.key; } _EOF #Убедиться в том, что сервер присылает полную цепочку сертификатов, #можно при помощи утилиты командной строки openssl, например: #openssl s_client -connect www.godaddy.com:443 Ссылки по теме: openssl req - создание CSR-запроса openssl genrsa - создание файла ключей","tags":"Bash","title":"Скрипт генерации сертификатов SSL для nginx."},{"url":"blog/freebsd-9x-fix-bsd-tar/","text":"При обновлении портов на FreeBSD ниже 9.x возникают подобные проблемы с xz архивами: # cd usr/ports/misc/mc # make === > License GPLv3 accepted by the user === > Found saved configuration for mc-4.8.1.6 === > Fetching all distfiles required by mc-4.8.1.7 for building === > Extracting for mc-4.8.1.7 = > SHA256 Checksum OK for mc-4.8.1.7.tar.xz. === > mc-4.8.1.7 depends on file: /usr/local/bin/xz - found === > mc-4.8.1.7 depends on file: /usr/local/bin/perl5.14.2 - found tar: Unrecognized archive format: Inappropriate file type or format tar: Error exit delayed from previous errors. *** Error code 1 Stop in /usr/ports/misc/mc. *** Error code 1 Stop in /usr/ports/misc/mc. Лечится довольно просто, установкой libarchive и 1 строчкой в /etc/make.conf : cd /usr/ports/archivers/libarchive make install clean echo 'TAR=/usr/local/bin/bsdtar' >> /etc/make.conf Ссылки по теме: tar: Unrecognized archive format Обновление портов и tar.Xz Исправление ошибки во freebsd tar xz.","tags":"FreeBSD","title":"Решение проблем во FreeBSD < 9.x c bsd tar."},{"url":"blog/jnl-bind-named-named-journalprint/","text":"Для чтения файлов журнала .jnl DNS сервера Named ( bind ), существует утилита named-journalprint . Пример использования: named-journalprint zone.local.jnl Ссылки по теме: Working with a journal-ized bind zone","tags":"Bind","title":"Чтение файлов журнала .jnl bind, named named-journalprint"},{"url":"blog/ubuntu-1204-transmission-samba/","text":"Для успешной с файлами по samba , скаченными при помощи свежеустановленного transmission нужно изменить umask для вновь создаваемых файлов и каталогов демоном transmission и для этого первым делом останавливаем демона: Ubuntu$ sudo service transmission-daemon stop * Stopping bittorrent daemon transmission-daemon [ OK ] Если демона не остановить, то все изменения в конфиге не сохранятся, т.к. при перезапуске transmission перезапишет свой файл из памяти и все изменения пропадут. Убедившись, что демон transmission не запущен - открываем файл настроек: sudo nano /etc/transmission-daemon/settings.json Находим там параметр \"umask\": 18, и изменяем значение на \"umask\": 2, , затем сохраняем файл. С таким значением umask демон transmission будет создавать: Каталоги с маской 775 - читать, писать, исполнять (заходить в каталог) владельцу и группе, остальным только читать и исполнять(заходить в каталог). Файлы с маской 664 - читать, писать владельцу и группе, остальным только читать. Теперь добавляем пользователя, под которым подключаемся к samba шарам, в группу debian-transmission : Ubuntu$ id metajiji uid = 1000 ( metajiji ) gid = 1000 ( metajiji ) группы = 1000 ( metajiji ) ,4 ( adm ) ,27 ( sudo ) ,109 ( sambashare ) Ubuntu$ sudo usermod metajiji -aG debian-transmission Ubuntu$ id metajiji uid = 1000 ( metajiji ) gid = 1000 ( metajiji ) группы = 1000 ( metajiji ) ,4 ( adm ) ,27 ( sudo ) ,109 ( sambashare ) ,111 ( debian-transmission ) Как видим, командой id можно проверить список групп, а так же увидеть uid/gid в которых состоит пользователь. Запускаем демона transmission : sudo service transmission-daemon start * Starting bittorrent daemon transmission-daemon [ OK ] P.S. Если все сделано правильно, то transmission будет скачивать файлы с правильными правами, так, что их можно будет удалять, перемещать, редактировать через samba , не прибегая к редактированию системных файлов( /etc/init.d/transmission-daemon ) и т.п. ухищрений - так делать не нужно, ведь после обновления есть большая вероятность, что этот файл обновится и вам придется заново редактировать его вручную, в то время, как можно было сделать все менее радикально :) Ссылки по теме: Wiki - Umask Ubuntu server 12.04 Transmission-daemon error: Permission denied...","tags":"Ubuntu","title":"Ubuntu 12.04 - transmission и samba"},{"url":"blog/sh-md5-script-for-delete-duplicates/","text":"Скрипт для поиска и удаления одинаковых файлов по md5 : #!/bin/sh #TODO - проверить наличие необходимых утилит #md5 #find #getopts #grep get_yes_no () { while [ true ] ; do echo -n \" $1 (Y/N) ? \" read a if [ $? ! = 0 ] ; then a = 'No' return fi case $a in [ Yy ]) a = 'Yes' ; return ;; [ Nn ]) a = 'No' ; return ;; * ) ;; esac done } build_hash_db () { # Проверяем существует ли указанный файл БД, если да, то спрашиваем что делать - удалить и создать новый или выйти. echo \"Запущено построение базы хешей каталога: \" $1 if [ -f \" $db_FILE \" ] ; then get_yes_no 'Файл БД уже существует, удалить и создать новый?' [ $a = 'No' ] && echo 'Аварийное завершение.' && exit 1 [ $a = 'Yes' ] && echo 'Файл БД удален и будет создан заново.' && rm -f \" $db_FILE \" fi find \" $1 \" -type f -print | while read file ; do echo \"`md5 -q \" $file \"` $file \" >> $db_FILE done } find_and_delete_duplicates_by_hash_from_db (){ # Если база не создана, то предлагаем создать её. echo \"Запущен поиск дубликатов в каталоге $1 по базе хешей $db_FILE \" [ ! -f $db_FILE ] && get_yes_no 'Файл БД не существует, создать новый?' [ \" $a \" = 'No' ] && echo 'Аварийное завершение.' && exit 1 if [ \" $a \" = 'Yes' ] ; then echo 'Создание файла БД: ' $db_FILE while [ true ] ; do echo -n 'Введите путь до каталога по которому будет создаваться файл БД: ' read b [ $? ! = 0 ] && return if [ -d $b ] ; then build_hash_db \" $b \" return else echo 'Вы ввели неверный путь. Повторите попытку.' fi done fi # Ищем дубликаты в каталоге $1 по БД хешей $db_FILE. echo '#--------------------------- ' ` date \"+%d.%m.%Y %H:%M:%S\" ` > ${ db_FILE } .log find \" $1 \" -type f -print | while read file ; do hash = ` md5 -q \" $file \" ` if grep -q $hash $db_FILE ; then echo \" $file \" ' is a duplicate and has been removed.' echo $hash ' ' $file >> \" ${ db_FILE } .log\" rm -vf \" $file \" fi done } usage () { [ -n \" $1 \" ] && echo \" $1 \" cat <<-_EOF Usage: -c Режим построения базы хешей. -d Режим поиска и удаления повторяющихся файлов на основе построенной ранее базы хешей. -f Имя файла БД с хешами, если не будет указан, то будет использоваться значение по умолчанию - file.csv -h | --help Справка. Пример использования: 1. Создать базу хешей каталога 1: $(basename $0) -c -f my_file.csv /path/to/folder 2. Найти и удалить дубликаты по созданной базе хешей в каталоге 2: $(basename $0) -d -f my_file.csv /path/to/folder _EOF exit 2 } # Проверяем на пустые аргументы. [ $# -lt 1 ] && usage c_FLG = 0 ; d_FLG = 0 ; while getopts hcdf: a ; do case \" $a \" in c ) [ $d_FLG = 1 ] && usage 'ОШИБКА! Нельзя использовать одновременно опции -c и -d.' ; c_FLG = 1 ;; d ) [ $c_FLG = 1 ] && usage 'ОШИБКА! Нельзя использовать одновременно опции -c и -d.' ; d_FLG = 1 ;; f ) db_FILE = \" $OPTARG \" ;; ? | h ) usage ;; esac done # Сдвигаем ряд аргументов на количество уже разобранных аргументов и оставляем последний. shift $(( $OPTIND - 1 )) #shift `expr $OPTIND - 1` # Проверка аргументов и важных переменных. [ -z \" $1 \" ] && usage 'ОШИБКА! Не задан каталог для обработки.' [ -z \" $db_FILE \" ] && usage 'ОШИБКА! Не задана опция -f.' [ $c_FLG = 0 -a $d_FLG = 0 ] && usage 'ОШИБКА! Не указана ни одна из опций -c или -d.' # Запуск фукций в зависимости от установленных переменных. [ \" $c_FLG \" = 1 ] && build_hash_db \" $1 \" [ \" $d_FLG \" = 1 ] && find_and_delete_duplicates_by_hash_from_db \" $1 \"","tags":"Bash","title":"sh скрипт для поиска и удаления одинаковых файлов по md5. (script for delete duplicates files by md5 hash)."},{"url":"blog/ubuntu-1204-samba/","text":"После установки samba обнаружил проблему - после перезагрузки системы демон smbd запускается, но пользователи не могут получить доступ к шарам. Поиск по интернетам особо не дал результатов, пришлось разбираться самому. Проблема заключалась в том, что демон стартует после инициализации файловых систем и поднятия сетевых интерфейсов. И похоже smbd стартовал сразу, как только поднимался lo0 , не дожидаясь пока остальные интерфейсы получат ip адреса по DHCP и тоже перейдут в состояние up . Подсмотел в скрипт запуска nmbd и обнаружил, что группа интерфейсов lo игнорируется. Этот же прием применил и для smbd , отредактировав файл /etc/init/smbd.conf : start on ( local-filesystems and net-device-up IFACE! = lo ) #start on (local-filesystems and net-device-up)","tags":"Ubuntu","title":"Ubuntu 12.04 samba не работает при старте системы"},{"url":"blog/freebsd-dos2unix-unix2dos-bom/","text":"Замена текста: Способ 1: Замена подстроки с помощью perl : perl -e 's/foo/bar/g' -pi ./index.html Способ 2: Замена с помощью sed : sed -e 's/foo/bar/g' ./index.html > index_new.html Способ 3: Замена с помощью awk awk '{gsub(\"foo\", \"bar\", $0); print > FILENAME}' ./index.html Полезные функции для работы с файлами: dos2unix () { sed -i '' -e 's/' \" $( printf '\\015' ) \" '$//g' \" $2 \" } unix2dos () { sed -i '' -e 's|$|' \" $( printf '\\015' ) \" '|g' \" $2 \" } delete_BOM () { #awk '{sub(/&#94;\\xEF\\xBB\\xBF/,\"\",$0); print > FILENAME}' \"$1\" awk '{sub(/&#94;\\xEF\\xBB\\xBF/,\"\",$0); print}' \" $1 \" >> \" ${ 1 } .awkbak\" mv \" ${ 1 } .awkbak\" \" $1 \" } #По 1 файлу dos2unix -o russian.php delete_BOM russian.php # Найти и обработать все *.tpl и *.php файлы от текущего каталога. for i in $( find . -type f \\( -name '*.tpl' -o -name '*.php' \\) -print ) ; do echo 'Working: ' $i '...' dos2unix -o $i delete_BOM $i done dos2unix -o для обратной совместимости с одноименной консольной утилитой /usr/ports/converters/unix2dos , но зачем засорять систему лишними пакетами, если можно обойтись встроенными средствами? P.S. Если кто-то подскажет более изящное решение на awk , sed или еще чем-то, что идет штатно во FreeBSD для удаления BOM , буду только рад :) Варианты с perl не предлагать, они очевидны и не интересны :) Первый вариант с awk почему-то не работает, часть файла теряется. FreeBSD Подсказывает в motd вариант на sed : sed -e '1s/&#94;\\xef\\xbb\\xbf//' < bomfile > newfile","tags":"FreeBSD","title":"Работа с текстом во FreeBSD dos2unix, unix2dos, удаление BOM в консоли."},{"url":"blog/freebsd-isc-dhcpd-dhcpdleases/","text":"Скрипт парсит dhcpd.leases файл и отображает список подсетей 0/24 на выбор, после выбора подсети выдается список арендованных ip со статусом free или active , где можно выбрать один или несколько ip и удалить. Скрипт использует dialog , за счет чего меню получается очень привлекательным :) - писал под FreeBSD , на Linux не тестировал (возможно будут проблемы из-за несовместимости BSD awk и GNU awk ), хотя думаю, что должен работать и под Linux . #!/bin/sh # загружаем /etc/rc.conf. . /etc/rc.conf #TODO - установить имя файла более точнее, см. /usr/local/etc/rc.d/isc-dhcpd. file = $dhcpd_rootdir /var/db/dhcpd/dhcpd.leases tempfile = $( mktemp 2 >/dev/null ) || tempfile = /tmp/ $( basename $0 ) _ $$ trap \"rm -f $tempfile \" 0 1 2 5 15 ### functions: BEGIN # Функция запуска команд в информационном окошке. exec_fun () { dialog --sleep 1 --title \" $2 \" \\ --msgbox \"`echo ; $1 2>&1;echo`\" 15 85 } # Функция удаления lease. del_lease () { exec_fun \"service isc-dhcpd stop\" \"Status Daemon:\" #TODO - убедиться, что демон остановлен. # Бекап базы. DATE = $( date \"+%Y%m%d%H%M\" ) cp -vf $file ${ file } . $DATE for i in $1 ; do awk 'BEGIN { FLG=0; } { if ($0==\"lease ' $i ' {\") FLG=1; if (FLG==\"0\") printf \"%s\",$0\"\\n\"; if ($0==\"}\" && FLG==\"1\") FLG=0; }' $file > ${ file } .new mv -vf ${ file } .new $file done [ -f \" ${ file } ~\" ] && rm -vf \" ${ file } ~\" exec_fun \"service isc-dhcpd start\" \"Status Daemon:\" #TODO - убедиться, что демон запущен. } # Функция получения списка subnet из dhcpd.leasees файла. get_subnet_list () { grep -oE '&#94;lease [0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.' $file | sort -u \\ | awk 'BEGIN { n=1; }{ print n\" \"$2\"0/24 off\"; n++; }' } # Функция получения списка ip по subnet'у /24 и вывод списка в виде dialog. get_leases () { while [ true ] ; do LIST = ` awk '{ out=\"\"; sub(/[;#].*/,\"\",$0); \\ if ($1\" \"$2\" \"$3 ~ /&#94;lease ' $( echo $1 | sed 's|\\.|\\\\.|g' ) '[0-9]?[0-9]?[0-9] \\{$/ ) { out=\" \"$2; FLG=1; } \\ if ($1==\"binding\" && FLG==\"1\") out=\" \"$3; \\ if ($1==\"}\" && FLG==\"1\") { out=\"\\n\"; FLG=0; } \\ printf out,\" \"; }' $file | \\ sort -un -t . -k 1 ,1 -k 2 ,2 -k 3 ,3 -k 4 ,4 | \\ awk 'BEGIN { n=1; }{ print n\" \\\"\"$1\" \"$2\"\\\" off\"; n++; }' ` DIALOG = 'dialog --backtitle \"Редактирование ' $file '\" --cancel-label Back --ok-label Delete --title \"Редактирование ' $1 '0/24\" --clear --checklist \"Выбор lease\" 20 61 10 ' $LIST ' 2> ' $tempfile eval $DIALOG # Собственно удаление выбранных lease. $(cat $tempfile) if [ \" $? \" -eq 0 ] ; then # Формируем и передаваем в функцию удаления список ip. DEL_LIST = '' for i in $( cat $tempfile ) ; do DEL_LIST = \" $DEL_LIST \" $( echo \" $LIST \" | awk '{ if ($1==\"' $i '\") { sub(/0\\/24$/,\"\",$2); sub(/\"/,\"\",$2); print $2; } }' ) done del_lease \" $DEL_LIST \" else break ; # Выходим из while [true]. fi done } ### functions: END [ ! -f $file ] && echo 'ERROR: File \"' $file '\" not exist or not readable!' && exit 1 while [ true ] ; do LIST = \" $( get_subnet_list ) \" dialog --backtitle \"Редактирование $file \" \\ --cancel-label Exit \\ --title \"Редактирование $file \" --clear \\ --radiolist \"Выбор subnet\" 20 61 10 \\ $LIST 2 > $tempfile if [ \" $? \" -eq 0 ] ; then $( echo \" $LIST \" | awk '{ if ($1==\"' $( cat $tempfile ) '\") { \\ sub(/0\\/24$/,\"\",$2); print \"get_leases \"$2 }}' ) else break ; # Выходим из while [true]. fi done","tags":"FreeBSD","title":"isc-dhcpd - Скрипт для просмотра и удаления арендованных адресов из файла dhcpd.leases."},{"url":"blog/windows-7-internet-connectivity/","text":"После установки контент фильтра по статье Контент фильтр и статистика посещенных сайтов Squid + rejik + ipcad + Free-SA + nginx у пользователей Windows 7 возникли проблемы с сетевым апплетом в трее - он стал ошибочно показывать, что подключение к интернету отсутствует, хотя интернет работает. После недолгих поисков в интернете было найдено 2 решения. Первое [1] связано с разблокировкой сайта msftncsi.com , который windows 7 проверяет на доступность и в случае, если она не смогла получить к этому сайту доступ - выдает пользователю, что интернета нет! :) А так же Windows 7 проверяет резолв доменого имени dns.msftncsi.com - оно должно быть 131.107.255.255 . Хоть и пишут в [1] , что Windows 7 проверяет оба варианта и, если хотябы один из них пройдет проверку, то Windows 7 определит, что интернет есть, но у меня это на всех машинах не работало, пока не занес адрес msftncsi.com в список исключений на Rejik 'e. Для любителей поковырять и оптимизировать свою ОС в интернете предлагается [2 вариант] - отключить в самой ОС проверки интернета и апплет всегда будет считать, что интернет есть. Ссылки по теме: Appendix H: Network Connectivity Status Indicator and Resulting Internet Communication in Windows 7 and Windows Server 2008 R2 Как убрать восклицательный знак со значка подключения к сети в трее в Windows 7 http://www.msftncsi.com/ncsi.txt","tags":"Windows","title":"Windows 7 ошибочно полагает что нет доступа к internet или желтый восклицательный знак в трее"},{"url":"blog/hex-to-string-cmd-bat-function/","text":"@ ECHO OFF : : Включение расширенной обработки команд. SETLOCAL ENABLEEXTENSIONS ENABLEDELAYEDEXPANSION : : Строка в hex - в данном случае dlink. SET \"x16=646c696e6b\" CALL : Hex_To_String \" %x16% \" str ECHO . %str% PAUSE EXIT : Hex_To_String : : Вызывать так: CALL :Hex_To_String %hex_x16_string% value_name : : Где %hex_x16_string% - строка в 16-ричном hex формате : : value_name - имя переменной, в которую вернуть значение вычисленной строки. SETLOCAL & SET \"x16= %~1 \" SET n = 45 FOR %% A IN ( - . / 0 1 2 3 4 5 6 7 8 9 ) DO SET \"s.!n!= %% A\" & SET /A n += 1 SET n = 65 FOR %% A IN ( A B C D E F G H I J K L M N O P Q R S T U V W X Y Z ) DO SET \"s.!n!= %% A\" & SET /A n += 1 SET n = 97 FOR %% A IN ( a b c d e f g h i j k l m n o p q r s t u v w x y z ) DO SET \"s.!n!= %% A\" & SET /A n += 1 SET \"xs=\" FOR /L %% C IN ( 0 , 2 , 8184 ) DO ( IF \"!x16:~ %% C,1!\" == \"\" GOTO _ex_Hex str SET /A x10 = 0 x ! x16: ~%% C , 2 ! CALL SET xs = !xs! %% s.!x10! %% ) : _ex_Hex ENDLOCAL & SET \" %~2 = %xs% \" GOTO : EOF Ссылки по теме: CMD/BAT: hex дампер Полезные BAT/CMD скрипты Hex to string converter Online String to hex converter Online","tags":"Bat-cmd","title":"Hex to string cmd, bat \"function\""},{"url":"blog/create-shorcut-cmd-bat-in-windows/","text":"Для создания ярлыка в Windows на сетевую папку использую такой bat скрипт: @ ECHO OFF SET \"PATH_TO_URL=Server.url\" ( ECHO .[InternetShortcut] ECHO .URL=file://server/ ECHO .IconFile= %windir% \\system32\\SHELL32.dll ECHO .IconIndex=17 )> %PATH_TO_URL% Ссылки по теме: forum.oszone.net: CMD/BAT - создать ярлык","tags":"Bat-cmd","title":"Создание ярлыка .url в Windows из cmd\\bat"},{"url":"blog/log-rotation-named-bind/","text":"Ротация логов bind средствами самого bind, создаем конфиг: logging { channel update_debug { file \"/var/log/named-update.log\" versions 6 size 512K ; severity debug 3 ; print-category yes ; print-severity yes ; print-time yes ; } ; channel security_info { file \"/var/log/named-auth.log\" versions 6 size 512K ; severity info ; print-category yes ; print-severity yes ; print-time yes ; } ; # channel queries { # file \"/var/log/queries\" versions 6 size 10m; # print-time yes; # print-category yes; # print-severity yes; # }; # category queries { queries; }; category update { update_debug ; } ; category security { security_info ; } ; } ; Обратите внимание на опцию: file \"/var/log/named-update.log\" versions 6 size 512K ; Директива file указывает на файл, куда нужно писать логи, а опция versions задает количество лог-файлов, size задает размер лог файла, при достижении которого нужно произвести ротацию. И подключаем в named.conf include \"/etc/namedb/log.conf\" ; ! ! ВАЖНО ! ! ! Не используйте newsyslog для ротации логов bind , т.к. он не поддерживает переоткрытие лог-файла, а после того как newsyslog произведет ротацию и создаст новый файл bind потеряет дескриптор (inode) прежнего лог-файла и перестанет писать логи, мало того bind перестанет еще и обновлять ddns зону! Поэтому разумнее использовать либо встроенные средства ротации логов, либо перенаправить логи в syslog . Ссылки по теме: BIND Configuration File Guide - logging Statement Bog BOS: DNS сервер BIND","tags":"Bind","title":"Ротация логов named Bind и newsyslog"},{"url":"blog/asterisk-wav-to-alaw-ulaw-gsm-sox/","text":"Скрипт для пакетного конвертирования из wav в alaw , ulaw , gsm . #!/bin/sh IN = 'IN' # Входная папка. OUT = 'OUT' # Выходная папка. [ ! -d \" $IN \" ] && mkdir -v \" $IN \" && echo \"Create dir: $IN \" # Создаем папку для входных файлов. #[ -d \"$OUT\" ] && rm -vrf \"$OUT\" && echo \"Delete dir: $OUT\" # Чистим папку OUT. [ ! -d \" $OUT \" ] && mkdir -v \" $OUT \" && echo \"Create dir: $OUT \" # Создаем папку для выходных файлов. [ -d \" $OUT /wav\" ] && rm -vrf \" $OUT /wav\" && echo \"Delete dir: $OUT /wav\" # Чистим папку для wav файлов. [ ! -d \" $OUT /wav\" ] && mkdir -v \" $OUT /wav\" && echo \"Create dir: $OUT /wav\" # Создаем папку для wav файлов. convert_to () { #$1 - Output format file. #$2 - IN file. [ -z \" $1 \" ] && echo 'ERROR: $1 is empty!' && exit 1 [ -z \" $2 \" ] && echo 'ERROR: $2 is empty!' && exit 1 case $1 in alaw ) SOX_OPT = '-t al' ;; ulaw ) SOX_OPT = '-t ul' ;; gsm ) SOX_OPT = '' ;; * ) echo \"ERROR: fromat $1 is not supported!\" ; exit 1 ;; esac # Если нужные директории не существуют, то создаем их. if [ ! -d \" $OUT /wav $D_OUT \" ] ; then echo \"Create dir: $D_IN -> $OUT /wav $D_OUT \" ; mkdir -vp $OUT /wav $D_OUT echo '------------------------' fi if [ ! -d \" $OUT / $1$D_OUT \" ] ; then echo \"Create dir: $D_IN -> $OUT / $1$D_OUT \" ; mkdir -vp $OUT / $1$D_OUT echo '------------------------' fi F_OUT = $( basename $2 .wav ) echo \"Processing: $2 -> $OUT / $1$D_OUT / $F_OUT . $1 \" # Проверим, существует ли входной файл. if [ -f \" $2 \" ] ; then # Если нету wav, то для начала сконвертим в wav. if [ ! -f $OUT /wav $D_OUT / $F_OUT .wav ] ; then echo 'Convert to 8bit wav first at 8000Hz - this can take a while...' sox \" $2 \" -r 8000 -c1 \" $OUT /wav $D_OUT / $F_OUT .wav\" fi #Проверяем имеется ли входной wav файл. if [ -f $OUT /wav $D_OUT / $F_OUT .wav ] ; then # Если файл в нужном формате $1 уже существует, то сперва удаляем его, потом конвертим if [ -f $OUT / $1$D_OUT / $F_OUT . $1 ] ; then echo \"INFO: File exist! $OUT / $1$D_OUT / $F_OUT . $1 remove...\" rm -vf $OUT / $1$D_OUT / $F_OUT . $1 fi sox \" $OUT /wav $D_OUT / $F_OUT .wav\" $SOX_OPT \" $OUT / $1$D_OUT / $F_OUT . $1 \" else echo \"ERROR: Input wav file $OUT /wav $D_OUT / $F_OUT .wav is not exist!\" exit 1 fi else echo \"ERROR: Input file $2 not exists!\" fi } find $IN -type d -depth -print | while read D_IN ; do # ищем сперва самые \"глубокие Директории\" D_OUT = $( echo \" $D_IN \" | sed -e 's/' $IN '//' ) # Получаем имя выходного каталога. # Ищем во входном каталоге wav файлы. find $D_IN -type f -name \"*.wav\" -print -maxdepth 1 | while read file ; do convert_to alaw \" $file \" convert_to ulaw \" $file \" convert_to gsm \" $file \" done done # TIP - Увеличение громкости #sox file1.wav -v 5 file2.wav #ffmpeg myfile.wav $i -vol 256 -acodec pcm_s16le -ar 8000 -ac 1 -y filename_out\"${i%wav}wav\" -vol volume change audio volume (256=normal)","tags":"FreeBSD","title":"Скрипт для пакетного конвертирования из wav в alaw, ulaw, gsm через sox."},{"url":"blog/squid-rejik-ipcad-free-sa-nginx/","text":"Для организации логирования, статистики посещенных сайтов и других сетевых соединений я воспользовался связкой Squid + Free-SA + ipcad Squid - Прокси сервер, который работает у меня в прозрачном ( transparent или intercept ) режиме - пользователям ничего настраивать не придется. Более подробно о нем писать не вижу смысла. Free-SA - Анализатор логов Squid написан на языке Си, по функциональности и назначению похож на LightSquid . Главное отличие - скорость формирования отчетов от 7 до 20 раз выше по сравнению с LightSquid (7х - для 50 Мб файла access.log , 20x - для 1 Гб). Присутствуют дополнительные отчеты (в том числе для оценки эффективности сервера), изменяемые \"на лету\" темы оформления, имеется поддержка различных форматов файлов журналов ( Squid , CLF , Postfix , Qmail , CGP ). Имеет мало зависимостей в отличие от того же LightSquid и малые требования к веб серверу! В настройках можно много чего интересного покрутить, об этом ниже. Еще хотелось бы отметить полезного из функционала - опционально можно включить в отчеты полные URL - для подробной отчетности, либо наоборот отключить (будет быстрее формироваться статистика). Rejik - redirector для Squid , выполняющий функции контент фильтра. Поддерживает регулярные выражения, и просто списки сайтов. Можно добавлять исключения, применять правила по времени или ip адресам. Из плюсов - высокая скорость работы. Из минусов, чтобы скачать базы, нужно либо поработать - проверить несколько сотен сайтов на принадлежность, либо просто купить списки \"плохих\" сайтов. ipcad - Коллектора для сбора трафика, идущего в обход прокси-сервера. Остается только взять извлечь из него статистику и записать в лог Squid . Скрипт для этого есть ниже. nginx - Легковесный и производительный веб-сервер. Для запуска CGI скриптов/программ лучше всего использовать fcgiwrap , о настройке ниже. Более подробно расписывать не вижу смысла. Весь выбранный софт бесплатный и имеется в портах FreeBSD и под Linux , думаю тоже все эти пакеты есть. Итак по порядку, первым делом обновляем порты и устанавливаем весь перечисленный софт: FreeBSD# cd /usr/ports FreeBSD# portsnap fetch update FreeBSD# cd /usr/ports/www/squid FreeBSD# make config && make config-recursive [ x ] SQUID_IDENT [ x ] SQUID_KQUEUE [ x ] SQUID_LARGEFILE FreeBSD# make install clean FreeBSD# cd /usr/ports/www/free-sa FreeBSD# make install clean FreeBSD# cd /usr/ports/www/rejik FreeBSD# make config & amp ;& amp ; make config-recursive [ x ] BAN [ x ] DBL [ x ] WWW FreeBSD# make install clean FreeBSD# cd /usr/ports/www/nginx FreeBSD# make config & amp ;& amp ; make config-recursive [ x ] HTTP [ x ] HTTP_CACHE [ x ] HTTP_REWRITE [ x ] HTTP_STATUS [ x ] WWW FreeBSD# make install clean FreeBSD# cd /usr/ports/www/fcgiwrap FreeBSD# make install clean FreeBSD# cd /usr/ports/net-mgmt/ipcad FreeBSD# make install clean Когда все успешно установится переходим к настройкам: Листинг free-sa.conf : # # Sample configuration file for free-sa(1) # # copy to /usr/local/etc/free-sa/free-sa.conf # ######### # FILES # ######### log = \"/var/log/squid/access.log\" #usertab=\"/usr/local/etc/free-sa/users\" downloads = \"/usr/local/etc/free-sa/downloads.sample\" #local_filter=\"\" #global_filter=\"\" ############### # DIRECTORIES # ############### targetdir = \"/usr/local/www/data/free-sa\" tmpdir = \"/var/cache/free-sa\" ##################### # REPORTS SELECTION # ##################### ts = \"true\" paf = \"true\" saf = \"true\" pdn = \"true\" sdn = \"true\" cct = \"true\" pst = \"true\" dld = \"true\" fullurl = \"true\" users = \"true\" #email=\"\" ################## # REPORTS LIMITS # ################## #paf_limit=\"50\" #saf_limit=\"50\" #pdn_limit=\"50\" #sdn_limit=\"50\" #cct_limit=\"50\" #pst_limit=\"50\" #dld_limit=\"50\" #lcf_limit=\"50\" #url_limit=\"50\" #ts_limit=\"0\" #dld_min=\"0\" #rtr_timeout=\"5000\" #################### # OTHER PARAMETERS # #################### name = \"free-sa.conf\" logformat = \"0\" #skip_errors=\"false\" fulltraffic = \"true\" inameuser = \"true\" #user_unescape=\"false\" indicators = \"true\" overwrite = \"2\" resolveip = \"true\" showinfo = \"true\" #site=\"\" #logo=\"\" locale = \"ru_RU.KOI8-R\" #rotate=\"\" divisor = \"b\" #tz_shift=\"0\" Создаем каталог для скриптов: mkdir /usr/local/etc/squid/scripts И создаем в этой папке скрипты: Листинг ipcadstat.sh : #!/bin/sh # Диапазон адресов локальной cети, указываем подсеть. net = \"192\\.168\\.[0-9]?[0-9]?[0-9]\\.[0-9]?[0-9]?[0-9] $ \" # 192.168.0.0/16 #net=\"192\\.168\\.0\\.[0-9]?[0-9]?[0-9]$\" # 192.168.0.0/24 # Каталог с логами squid'а squid_DIR = '/var/log/squid/' ttime = ` rsh localhost sh ip acco | grep 'Accounting data saved' | awk '{print ($4)}' ` rsh localhost clear ip accounting > /dev/null rsh localhost show ip accounting checkpoint | awk -v vtime = $ttime '{ if ( $2 ~ /&#94;' $net '/ ) print (vtime\".000\",1,$2,\"TCP_MISS/200\",$4,\"CONNECT\",$1\":\"$5,\"-\",\"DIRECT/\"$1,\"-\") }' >> \" $squid_DIR /access.log\" #TODO - если ошибок не было, то продолжаем. /usr/local/bin/free-sa Листинг rotate_log.sh : #!/bin/sh # Ротация логов Squid /usr/local/sbin/squid -k rotate for i in $( ls $squid_DIR | grep -i '\\.log\\.[4-9]' ) ; do rm -f $squid_DIR / $i done Добавляем эти скрипты в планировщик заданий /etc/crontab : # rotate squid logs 0 0 */1 * * root /usr/local/etc/squid/scripts/rotate_log.sh >>/var/log/squid/rotate_log.log 2 > & 1 # Наполнение лога squid данными из ipcad. */5 * * * * root /usr/local/etc/squid/scripts/ipcadstat.sh >>/var/log/squid/ipcadstat.log 2 > & 1 Привожу только те строки, которые изменил в дефолтном конфиге Squid - /usr/local/etc/squid/squid.conf : http_port 3129 transparent cache_mem 500 MB maximum_object_size_in_memory 64 KB cache_dir ufs /var/squid/cache 20480 16 256 maximum_object_size 100 MB access_log /var/log/squid/access.log squid cache_log /var/log/squid/cache.log logfile_rotate 100 strip_query_terms off url_rewrite_program /usr/local/rejik/redirector /usr/local/rejik/redirector.conf url_rewrite_children 10 header_access Via deny all cache_mgr Тут@Мое.мыло visible_hostname имя.сервера.сквида error_directory /usr/local/etc/squid/errors/Russian-1251 dns_nameservers Тут.ip.вашего.DNS.сервера append_domain .local forwarded_for off Страницу блокировки я предпочитаю отдавать самим Squid , как это описано в FAQ по rejik 'у - А нельзя ли обойтись без установки локального web сервера? Добавляем строки в /usr/local/etc/squid/mime.conf : # Для rejik dfgxfdgdfg-squid-porno dfgxfdgdfg-squid-deny/dfgxfdgdfg-squid-porno-html rejik/porno.html - ascii dfgxfdgdfg-squid-deny dfgxfdgdfg-squid-deny/dfgxfdgdfg-squid-deny-html rejik/deny.html - ascii dfgxfdgdfg-squid-banner dfgxfdgdfg-squid-banner/dfgxfdgdfg-squid-banner-1px rejik/1x1.gif - image dfgxfdgdfg-squid-js dfgxfdgdfg-squid-js/dfgxfdgdfg-squid-js-js rejik/js.js - ascii Файл 1x1.gif - это пустая gif картинка размером 1x1 пиксель. Файл js.js - это пустой текстовый файл. Файлы porno.html , deny.html - произвольный html документ, который будут видеть те, кто откроет запрещенный сайт. Например у меня deny.html выглядит так: <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"> < html xmlns = \"http://www.w3.org/1999/xhtml\" > < head > < meta http-equiv = \"Content-Type\" content = \"text/html; charset=UTF-8\" /> < title > Доступ ограничен </ title > < style type = \"text/css\" > <! -- body , td , th { font-family : Verdana , Arial , Helvetica , sans-serif ; font-size : 14 px ; color : #FFFFFF ; } body { background-color : #000000 ; margin-top : 100 px ; margin-left : 100 px ; margin-right : 100 px ; } . style1 { color : #FF0000 ; font-size : 16 px ; font-weight : bold ; } . style2 { font-size : 10 px } -- > </ style > </ head > < body > < div align = \"center\" > &nbsp; < p class = \"style1\" > Содержимое данного сайта заблокировано! </ p > &nbsp; < p > Система контентной фильтрации определила, < br /> &nbsp; что материалы запрашиваемого вами ресурса < br /> &nbsp; могут противоречить целям и задачам < br /> &nbsp; образовательного процесса. </ p > &nbsp; < hr width = \"400\" size = \"3\" /> &nbsp; < p >< span class = \"style2\" > Если вы уверены, что сайт не содержит недопустимой информации, < br /> &nbsp; обратитесь к системному администратору. После проверки адрес < br /> &nbsp; будет добавлен в список разрешенных ресурсов. </ span ></ p > </ div > </ body > </ html > Листинг /usr/local/rejik/redirector.conf : error_log /usr/local/rejik/redirector.err change_log /usr/local/rejik/redirector.log make-cache /usr/local/rejik/make-cache allow_urls /usr/local/rejik/banlists/allow_urls # Список ip - исключений. (для кого НЕ будут применяться правила фильтрации) allow_ip f:/usr/local/rejik/ip/allow #<audio-video> #ban_dir /usr/local/rejik/banlists/audio-video #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off #<avto-moto> #ban_dir /usr/local/rejik/banlists/avto-moto #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off <banner> ban_dir /usr/local/rejik/banlists/banners #файлы смотри в каталоге /usr/local/etc/squid/icons/rejik + mime.conf файл сквида url http://127.0.0.1:3126/squid-internal-static/icons/rejik/1x1.gif log off #<chats> #ban_dir /usr/local/rejik/banlists/chats #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off #<dating> #ban_dir /usr/local/rejik/banlists/dating #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off <extremism> ban_dir /usr/local/rejik/banlists/extremism url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off #<icq> #ban_dir /usr/local/rejik/banlists/icq #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off #<jobsearch> #ban_dir /usr/local/rejik/banlists/jobsearch #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off <online-games> ban_dir /usr/local/rejik/banlists/online-games url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off <phishihg> ban_dir /usr/local/rejik/banlists/phishing url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off #<photogallery> #ban_dir /usr/local/rejik/banlists/photogallery #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off <porno> ban_dir /usr/local/rejik/banlists/porno url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off <socnet> ban_dir /usr/local/rejik/banlists/socnet url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html work_ip f:/usr/local/rejik/ip/deny_socnet log off <spyware> ban_dir /usr/local/rejik/banlists/spyware url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off <torrents> ban_dir /usr/local/rejik/banlists/torrents url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off <virus-detect> ban_dir /usr/local/rejik/banlists/virus-detect url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off <warez> ban_dir /usr/local/rejik/banlists/warez url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off #<web-mail> #ban_dir /usr/local/rejik/banlists/web-mail #url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html #log off <web-proxy> ban_dir /usr/local/rejik/banlists/web-proxy url http://127.0.0.1:3126/squid-internal-static/icons/rejik/deny.html log off Так как rejik из текстовых файлов со списками плохих сайтов делает файлы бинарные файлы, от после внесения изменений в списки, нужно обновлять *.cache файлы rejik 'а, для этого я использую скрипт: #!/bin/sh # Путь до rejik REJIK_PATH = /usr/local/rejik # Найдем и удалим файлы кеша rejik find $REJIK_PATH -name '*.cache' -exec rm {} \\; # Создадим снова кеш rejik $REJIK_PATH /make-cache # говорим squid перечитать новую конфигурацию /usr/local/sbin/squid -k reconfigure Листинг с описанием виртуального хоста squid.local : server { #-------------------------- Options --------------------------# listen *:80 ; server_name squid.local squid ; open_file_cache max=100000 inactive=40s ; open_file_cache_valid 60s ; open_file_cache_min_uses 2 ; open_file_cache_errors on ; # Logs access_log /var/log/nginx/squid.local_http_access.log ; error_log /var/log/nginx/squid.local_http_error.log ; #-------------------------- Configs --------------------------# # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html ; location = /50x.html { root /usr/local/www/nginx-dist ; } # deny access to .htaccess files, if Apache's document root concurs with nginx's one location ~ /\\.ht { deny all ; } index index.html free-sa.cgi ; #-------------------------- Locations ------------------------# location ~ &#94;/favicon.ico$ { root /usr/local/www/data/free-sa ; log_not_found off ; access_log off ; expires max ; } # Main location location / { root /usr/local/www/data/free-sa ; location ~ \\.cgi$ { gzip off ; #gzip makes scripts feel slower since they have to complete before getting gzipped fastcgi_pass unix:/var/run/fcgiwrap/lightsquid.socket ; fastcgi_index free-sa.cgi ; fastcgi_param SCRIPT_FILENAME /usr/local/www/data/free-sa/ $fastcgi_script_name ; fastcgi_param QUERY_STRING $query_string ; fastcgi_param REQUEST_METHOD $request_method ; fastcgi_param CONTENT_TYPE $content_type ; fastcgi_param CONTENT_LENGTH $content_length ; fastcgi_param GATEWAY_INTERFACE CGI/1.1 ; fastcgi_param SERVER_SOFTWARE nginx ; fastcgi_param SCRIPT_NAME $fastcgi_script_name ; fastcgi_param REQUEST_URI $request_uri ; fastcgi_param DOCUMENT_URI $document_uri ; fastcgi_param DOCUMENT_ROOT $document_root ; fastcgi_param SERVER_PROTOCOL $server_protocol ; fastcgi_param REMOTE_ADDR $remote_addr ; fastcgi_param REMOTE_PORT $remote_port ; fastcgi_param SERVER_ADDR $server_addr ; fastcgi_param SERVER_PORT $server_port ; fastcgi_param SERVER_NAME $server_name ; } } } Конечно же каталог с логами должен существовать и права должны быть такие же как у nginx : mkdir /var/log/nginx chown www:www /var/log/nginx Не забываем про ротацию логов - добавляем в /etc/newsyslog.conf : # nginx /var/log/nginx-error.log www:www 644 7 900 * XC /var/run/nginx.pid 30 /var/log/nginx/*.log www:www 644 7 900 * GXC /var/run/nginx.pid 30 # rejik /usr/local/rejik/redirector.err squid:squid 644 10 300 * XC # crontab for Squid /var/log/squid/rotate_log.log 644 3 100 * XC /var/log/squid/ipcadstat.log 644 3 100 * XC И перезапускаем демона newsyslog : service newsyslog restart В качестве бонуса привожу скрипт для удобной перезагрузки конфига Squid . Так как после внесения изменений в конфигурацию Squid , нужно перезапускать сервис, либо из консоли давать команду squid -k reconfigure , что не всегда удобно + если мы допустили ошибку в конфиге ничего хорошего не будет от такой команды и уж темболее от перезагрузки сервиса - он не запустится, а у людей не будет интернета, чтобы всего этого избежать я написал простенький скриптик: #!/bin/sh # Функция вывода цветных сообщений COLOR_STR () { case $2 in red ) printf %b \"\\033[1;31m $1 \\033[0m\" ;; green ) printf %b \"\\033[1;32m $1 \\033[0m\" ;; esac } squid -k check if [ $? = 0 ] ; then squid -k reconfigure COLOR_STR 'SUCCESS' green echo ': Squid config reloaded.' else COLOR_STR 'ERROR' red echo ': in Squid config file.' fi В кратце как это работает - скрипт сперва проверяет синтаксис конфига squid -k check , и если ошибок небыло, то выполняет загрузку нового конфига squid -k reconfigure , если были ошибки, то он выдаст ошибку и Squid останется работать со старым конфигом, следовательно у всех будет интернет, а у вас будет время все исправить. И последний конфиг - листинг файла конфигурации IpCad /usr/local/etc/ipcad.conf : capture-ports enable ; interface lan0 filter \"ip and dst net 192.168.0.0/16 and not src net 192.168.0.0/16 and not src port 80\" ; aggregate 0 .0.0.0/0 strip 32 ; /* Drop the last octet of all other IPs */ aggregate 110 into 110 ; aggregate 443 into 443 ; aggregate 3129 into 0 ; aggregate 3128 into 0 ; aggregate 3130 -65535 into 65535 ; rsh enable at 127 .0.0.1 ; rsh root@127.0.0.1 admin ; rsh root@127.0.0.1 backup ; rsh root@127.0.0.1 ; rsh 127 .0.0.1 view-only ; rsh ttl = 3 ; rsh timeout = 30 ; chroot = /var/log/ipcad ; dumpfile = ipcad.dump ; pidfile = ipcad.pid ; Обратите внимание на строку interface lan0 filter \"ip and dst net 192.168.0.0/16 and not src net 192.168.0.0/16 and not src port 80\"; Эта строка предписывает ipcad собирать статистику пакетов попадающих в локальную сеть извне (из интернет) на LAN -интерфейсе. При этом в статистику не должны попадать пакеты от squid (т.е. те, порт источника которых равен 80 - у нас же прозрачный прокси) т.к. squid сам отразит их статистику в своем логе. Дублирование статистики нам ни к чему. Как и чем заворачивать всех клиентов в Squid выбирайте сами - в интернете полно информации по этому поводу, я приведу 2 примера заворота при помощи pf и ipfw : Пример для pf : # редиректим всех, кроме таблицы <no_www_proxy> на наш Proxy сервер, чтобы отфильтровать \"Плохие сайты\" rdr proto tcp from !<no_www_proxy> to !lan0:network port http -> 127 .0.0.1 port 3129 Пример для ipfw : # Squid transparent redirect add fwd 127 .0.0.1,3129 tcp from any to not 192 .168.0.0/16 http via lan0 Где lan0 - имя локального интерфейса. Теперь можно все это добавить в автозагрузку и запустить. Вырезка из /etc/rc.conf : #------------------------------ squid ------------------------------------# squid_enable = \"YES\" # Прозрачный прокси, для ведения статистики посещенных сайтов. ipcad_enable = \"YES\" # Для записи в статистику squid'а, всего остального трафика. #-------------------------------------------------------------------------# #------------------------------ nginx ------------------------------------# nginx_enable = \"YES\" # (bool) Set to \"NO\" by default. Set it to \"YES\" to enable nginx #php_fpm_enable=\"YES\" fcgiwrap_enable = \"YES\" fcgiwrap_profiles = \"lightsquid\" fcgiwrap_flags = \"-c 4\" fcgiwrap_lightsquid_socket = \"unix:/var/run/fcgiwrap/lightsquid.socket\" fcgiwrap_lightsquid_user = \"www\" #-------------------------------------------------------------------------# Запускаем всех демонов: service squid start service ipcad start service fcgiwrap start service nginx start Пробуем выйти в интернет, открыть запрещенные сайты - все должно работать как и предполагали. Через пять минут пробуем зайти в Free-SA http://squid.local/ и посмотреть статистику. Чтобы посмотреть статистику в режиме реального времени нужно открыть ссылку http://squid.local/cgi-bin/ , где squid.local - имя вашего сервера с nginx . Ссылки по теме: Rejik FAQ: А нельзя ли обойтись без установки локального web сервера? Wiki - IT рабочие заметки: ipcad lissyara.su: Анализатор статистики Free-SA rootmaster.at.ua: шлюз для небольшой сети на основе FreeBSD. Подсчет трафика с помощью Squid и ipcad в pfSense 1.2.3 coolchevy's blog: Simple CGI support for Nginx Habrahabr: Вебсервер nginx + fastcgi-wrapper + matlab nginx.localdomain.pl: Simple CGI support for Nginx (fcgiwrap) Rejik: DBL листы - что это и где взять? Free-SA log processor","tags":"FreeBSD","title":"Контент фильтр и статистика посещенных сайтов Squid + rejik + ipcad + Free-SA + nginx"},{"url":"blog/freebsd-chroot-sftp-chroot-ssh/","text":"Для предоставления доступа через ssh и sftp например к файлам сайта, можно использовать штатный для FreeBSD демон sshd . Для начала добавим в конфиг демона /etc/ssh/sshd_config строки: ############## : BEGIN #pw usermod sftponly -d /usr/local/www/ #chown root:wheel /usr/local/www/ #AllowGroups wheel sftp #AllowUsers user1 user2 user3@192.168.1.1 user3@192.168.2.* Match User web ChrootDirectory /home/%u X11Forwarding no AllowTcpForwarding no Match Group sftp ChrootDirectory %h X11Forwarding no AllowTcpForwarding no ForceCommand internal-sftp ############## : END Добавляем в систему пользователя sftp и web : FreeBSD# adduser Username: sftp Full name: Uid ( Leave empty for default ) : Login group [ sftp ] : Login group is sftp. Invite sftp into other groups? [] : Login class [ default ] : Shell ( sh csh tcsh nologin ) [ sh ] : nologin Home directory [ /home/sftp ] : /usr/local/www Home directory permissions ( Leave empty for default ) : Use password-based authentication? [ yes ] : Use an empty password? ( yes/no ) [ no ] : Use a random password? ( yes/no ) [ no ] : Enter password: Enter password again: Lock out the account after creation? [ no ] : Username : sftp Password : ***** Full Name : Uid : 1002 Class : Groups : sftp Home : /usr/local/www Home Mode : Shell : /usr/sbin/nologin Locked : no OK? ( yes/no ) : y adduser: INFO: Successfully added ( sftp ) to the user database. Add another user? ( yes/no ) : y Username: web Full name: Uid [ 1003 ] : Login group [ web ] : Login group is web. Invite webb into other groups? [] : Login class [ default ] : Shell ( sh csh tcsh nologin ) [ sh ] : csh Home directory [ /usr/local/web ] : /home/web Home directory permissions ( Leave empty for default ) : Use password-based authentication? [ yes ] : Use an empty password? ( yes/no ) [ no ] : Use a random password? ( yes/no ) [ no ] : Enter password: Enter password again: Lock out the account after creation? [ no ] : Username : web Password : ***** Full Name : Uid : 1003 Class : Groups : web Home : /home/web Home Mode : Shell : /bin/csh Locked : no OK? ( yes/no ) : y adduser: INFO: Successfully added ( web ) to the user database. Add another user? ( yes/no ) : n Goodbye! Теперь нужно создать chroot окружение для пользователя web , для этого я написал скрипт add_ssh_chrootuser.sh : #!/bin/sh # Проверка задано ли имя пользователя if [ -z \" $1 \" ] ; then echo \" Usage: $0 [ username ]\" exit 1 fi USER = $1 GID = $( id -g $USER ) HOMEDIR = /home/ $USER # Задаем список каталогов в chroot окружении. SKEL = \"/bin /sbin /etc /home/ $USER /lib /libexec /tmp /usr/bin /usr/share /usr/local/bin /usr/local/etc /usr/local/share /usr/local/libexec\" # Создаем структуру каталогов внутри `chroot` окружения for i in $SKEL ; do [ ! -d $HOMEDIR$i ] && mkdir -pv $HOMEDIR$i done # Определяем какие библиотеки необходимо скопировать for item in sh csh zcat cat tbl groff chmod cp echo \\ ln ls date expr mkdir mv pwd locale \\ rm rmdir awk bzip2 diff du \\ ee fetch find grep gunzip gzip \\ more less sed sort tail head \\ tar touch vi ee mc mcedit \\ mysql mysqldump clear tput reset man zcat troff grotty ; do p = $( whereis -q $item | awk '{print $1}' ) if [ -n \" $p \" ] ; then # Копируем бинарники внутрь chroot окружения cp -vf $p $HOMEDIR$p ldd $p | awk '{print $3}' | grep '.' >>/tmp/chroot_liblist #ldd $CMD_LIST|grep -v ':$'|grep -v \"not a dynamic executable\"|cut -f 3 -d \" \"|sort|uniq|sed 1d else echo \" $item is NOT found, skip!\" fi done # Копируем библиотеки for item in $( cat /tmp/chroot_liblist | sort | uniq ) ; do cp -vf $item $HOMEDIR /lib/ done # Подчищаем за собой [ -f /tmp/chroot_liblist ] && rm -vf /tmp/chroot_liblist # Копируем оставшиеся необходимые файлы и библиотеки for i in /etc/termcap \\ /etc/resolv.conf \\ /etc/nsswitch.conf \\ /libexec/ld-elf.so.1 \\ /libexec/ld-elf32.so.1 ; do cp -vf $i $HOMEDIR$i done # если копировали mc, то копируем все необходимые для mc файлы. for i in /usr/local/share/mc \\ /usr/local/libexec/mc \\ /usr/local/etc/mc \\ /usr/local/man \\ /usr/share/man \\ /usr/share/groff_font \\ /usr/share/tmac ; do cp -vfR $i $HOMEDIR$i done # Если копировали mysql клиента, то настроим дефолтные опции. cat > $HOMEDIR /usr/local/etc/my.cnf <<-_EOF [client] port=3306 host=192.168.120.2 _EOF # Генерируем /etc/motd для chroot окружения echo 'Welcome to chroot environment' > $HOMEDIR /etc/motd # Генерируем csh.cshrc для chroot окружения echo 'setenv TERMCAP /etc/termcap' > $HOMEDIR /etc/csh.cshrc cp -fv /.cshrc $HOMEDIR /home/ $USER / #т.к. man требует зачем-то наличие /sbin/sysctl, то создаем заглушку - пустой файл с правами запуска. [ ! -d $HOMEDIR /sbin/ ] && mkdir -pv $HOMEDIR /sbin [ ! -x $HOMEDIR /sbin/sysctl ] && chmod -v +x $HOMEDIR /sbin/sysctl # Генерируем /etc/group для chroot окружения grep $GID /etc/group > $HOMEDIR /etc/group # Переносим запись о пользователе grep \"&#94; $USER :\" /etc/master.passwd > $HOMEDIR /etc/master.passwd pwd_mkdb -d $HOMEDIR /etc $HOMEDIR /etc/master.passwd # Выставляем права chown root:wheel $HOMEDIR chmod 755 $HOMEDIR chmod 777 $HOMEDIR /tmp for i in $SKEL ; do chown -vR $USER : $GID $HOMEDIR$i done Затем запускаем скрипт, указывая пользователя web: sh add_ssh_chrootuser.sh web В каталоге /home/web будет создана структура каталогов системы и будут скопированы программы и все необходимые для их запуска библиотеки. В скрипте я копирую минимальный набор, которого хватает для чтения логов nginx , работы с mysql и некоторые другие программки - например mc . Перезапускаем демона sshd : FreeBSD# service sshd restart Stopping sshd. Starting sshd. Все готово! Можно подключаться под созданными учетными записями. Пользователь web при подключении по ssh , попадет в chroot окружение, которое было создано скриптом, а пользователь sftp не сможет входить по ssh , но сможет сводобно работать по sftp протоколу, и самое главное, для него будет коневым каталогом /usr/local/www , за его пределы он не сможет выйти. P.S. Важно, чтобы права на chroot директории были chmod 755 и владелец root:wheel , в противном случае пользователи не смогут войти. Ссылки по теме: lissyara.su - \"Использование sftp+chroot из openssh в качестве альтернативы ftp-серверу.\" WOLAND's blog - \"BASH. Создание chroot окружения для SSH chroot в FreeBSD.\" Forums.freebsd.org - [Solved] sftp/scp chroot solution? Hilink - \"chroot ssh доступ. Настройка.\" Под защитой песочного демона (Евгений Зобнин) - Хакер, номер #093, стр. 093-118-4 opennet.ru - \"ssh chroot\"","tags":"FreeBSD","title":"FreeBSD chroot sftp и chroot ssh"},{"url":"blog/microsoft-office-starter-2010-file-associations/","text":"@ ECHO OFF : : http://support.microsoft.com/KB/323526 ASSOC .doc=Word.Document.8 ASSOC .docx=Word.Document.12 ASSOC .xls=Excel.Sheet.8 ASSOC .xlsx=Excel.Sheet.12 PAUSE : :.mdb=Access.MDBFile : :.ppt=PowerPoint.Show.8 : :.doc=Word.Document.8 : :.docx=Word.Document.12 : :.xls=Excel.Sheet.8 : :.xlsx=Excel.Sheet.12 Ссылки по теме: ПРАКТИЧЕСКОЕ руководство: Использование команды ASSOC для отображения и изменения связей расширений имен файлов в Windows 2000","tags":"Windows","title":"Восстановление ассоциаций офисных документов в Microsoft Office Starter 2010"},{"url":"blog/windows-skype-disable-ad/","text":"Для блокировки назойливой рекламы, которая к тому же сделана на * Flash , что сильно мешает нормальной работе за комптютером, был написан простенький bat файл: @ ECHO OFF CHCP 866 > nul FOR %% a IN ( rad.msn.com apps.skype.com ) DO ( TYPE \" %SystemRoot% \\system32\\drivers\\etc\\hosts\" | FIND /I \" %% a\" | FIND \"127.0.0.1\" > nul && ECHO . %% a уже заблокирован! || 1 >> \" %SystemRoot% \\system32\\drivers\\etc\\hosts\" ( ECHO .127.0.0.1 %% a ) && ECHO . %% a заблокирован! || ECHO .Ошибка записи! && PAUSE && EXIT ) : : Reset DNS cache IPCONFIG /flushdns PAUSE EXIT Скопировать текст скрипта, сохранить как Block_SkypeAD.bat в кодировке cp866 ( DOS ) и запустить. Ссылки по теме: Реклама в скайпе Как отключить дурацкую рекламу в скайп???????","tags":"Bat-cmd","title":"Блокирование рекламы в Skype 6.11.66.102 bat,cmd файл."},{"url":"blog/ubuntu-gnome-terminal-enable-system-beep/","text":"Первым делом необходимо установить утилиту beep : sudo apt-get install beep Затем нужно разрешить загрузку модуля pcspkr : sudo sed -i '' -e 's/blacklist pcspkr/#blacklist pcspkr/' /etc/modprobe.d/blacklist.conf Либо, если Beep поддерживает звуковая карта ноутбука, попробовать активировать эту функцию: cat >>/etc/modprobe.d/alsa-base.conf <<-_EOF #Enable Beep #https://bugs.launchpad.net/ubuntu/+source/beep/+bug/144022 options snd-hda-intel power_save=10 power_save_controller=Y index=0 beep_mode=1 _EOF Для включения сигналов в gnome-terminal нужно включить в metacity параметр audible_bell и в самом gnome-terminal проверить наличие галочки \" Подавать гудок \". Я сделал это через консоль: gconftool-2 --set --type bool \"/apps/gnome-terminal/profiles/Default/silent_bell\" \"false\" gconftool-2 --set --type string \"/apps/metacity/general/audible_bell\" \"on\" gsettings set org.gnome.desktop.wm.preferences audible-bell 'true' gconftool-2 --set --type string \"/desktop/gnome/peripherals/keyboard/bell_mode\" \"on\" gsettings set org.gnome.settings-daemon.peripherals.keyboard bell-mode 'on' Проверяем: echo -e \"\\a\" echo -e '\\a' ping -a ya.ru У меня после этих манипуляций был слышен звук, как и в системной консоли. Регулировать громкость сигнала можно через alsamixer в консоли - параметр Beep , у меня он почему-то был почти около нуля и я добавил громкости. Но радоваться рано, после перезагрузки гудок пропал. Выяснилось, что если отключить гудок и включить его снова, то все работает, но до следующей перезагрузки :( gsettings set org.gnome.desktop.wm.preferences audible-bell 'false' gsettings set org.gnome.desktop.wm.preferences audible-bell 'true' echo -e '\\a' Немного подумав, сделал такой костыль: cat >>~/.bashrc <<-_EOF if [ -n \"$DISPLAY\" ]; then gsettings set org.gnome.desktop.wm.preferences audible-bell 'false' gsettings set org.gnome.desktop.wm.preferences audible-bell 'true' fi _EOF Буду крайне признателен, если кто-то подскажет более изящное решение. P.S. Может кому пригодится, приведу еще дополнительные опции из gconftool и gsettings : Ubuntu~$ gsettings list-recursively | grep bell org.gnome.desktop.wm.preferences audible-bell true org.gnome.desktop.wm.preferences visual-bell false org.gnome.desktop.wm.preferences visual-bell-type 'fullscreen-flash' org.gnome.settings-daemon.peripherals.keyboard bell-custom-file '' org.gnome.settings-daemon.peripherals.keyboard bell-duration 100 org.gnome.settings-daemon.peripherals.keyboard bell-mode 'on' org.gnome.settings-daemon.peripherals.keyboard bell-pitch 400 Ubuntu~$ gconftool -R /desktop | grep -B4 bell /desktop/gnome/peripherals: /desktop/gnome/peripherals/keyboard: repeat = true delay = 500 bell_mode = off bell_custom_file = ( значение не установлено ) remember_numlock_state = true click_volume = 0 click = true bell_pitch = 400 bell_duration = 100 Ubuntu~$ gconftool -R /apps | grep -B20 bell Ссылки по теме: Comment 50 for bug 486154 Trying to ENABLE bell in gnome-terminal Comment 18 for bug 144022","tags":"Linux","title":"Ubuntu Gnome-Terminal - включение beep enable system-beep, audible ping, bell, подавать гудок."},{"url":"blog/linux-ubuntu-swap-to-file/","text":"Обычно swap создают размером в 2 раза превышающим размер доступной оперативной памяти. Шаг первый: Создадим файл с помощью команды низкоуровневого копирования dd Файл забьём нулями из /dev/zero и разметим на 256 блоков по 1Мб каждый: sudo dd if = /dev/zero of = /swap256.swap bs = 1M count = 256 Шаг второй: отформатируем получившийся файл как swap устройство: sudo mkswap /swap256.swap Шаг третий: подключаем отформатированный файл (после второго шага это уже полноценный swap ) с помощью команды swapon которая как раз для этого и предназначена. sudo swapon /swap256.swap Четвёртый шаг: делаем так чтобы swap файл подключался каждый раз при загрузке системы. Для этого в /etc/fstab добавляем одну строчку: /swap256.swap none swap sw 0 0 Контролировать использование swap можно как обычно через опцию sysctl vm.swappiness У меня в /etc/sysctl.conf прописано: vm.swappiness = 10 Это значит, что система будет использовать swap , если останется 10% от объема оперативной памяти. Ссылки по теме: Ubuntu. Как создать swap файл подкачки Swappiness","tags":"Linux","title":"Linux Ubuntu создаем файл подкачки Swap"},{"url":"blog/freebsd_asterisk-18-snmp-zabbix/","text":"Прежде чем начинать собирать статистику с Asterisk по протоколу snmp , нужно чтобы в нем был модуль res_snmp.so : FreeBSD# asterisk -rvvvv ... pbx*CLI> module show like snmp Module Description Use Count res_snmp.so SNMP [ Sub ] Agent for Asterisk 0 1 modules loaded Как видим, все на месте. Для тех, у кого это нет этого модуля, нужно пересобрать порт с нужной опцией: FreeBSD# make config ... [ * ] SNMP SNMP protocol ... Когда разобрались с наличием модуля, идем в конфиг /usr/local/etc/asterisk/res_snmp.conf и включаем SNMP : [ general ] ; We run as a subagent per default -- to run as a full agent ; we must run as root ( to be able to bind to port 161 ) subagent = yes ; SNMP must be explicitly enabled to be active enabled = yes Как видим, Asterisk не может открыть 161 порт (на этом порту работает протокол snmp ), если он запущен не от пользователя root . Но не беда, по умолчанию asterisk работает как суб-агент snmp это значит, что он может отдавать данные в демон snmpd через сокет и ему не надо будет открывать 161 порт. Готовим конфиг для snmp , вот мой конфиг /usr/local/etc/snmp/snmpd.conf : syslocation \"Univers Server Room\" syscontact admin@my_organization_dom rocommunity public ТУТ_IP_сервера_zabbix master agentx agentXPerms 0660 0550 asterisk asterisk agentXSocket /var/agentx/master Если с запуском Asterisk 1.8 в jail не возникло проблем, то с запуском snmpd было 2 проблемы: Не запускался демон snmpd : FreeBSD# service snmpd restart snmpd not running? (check /var/run/net_snmpd.pid). Starting snmpd. /usr/local/etc/rc.d/snmpd: WARNING: failed to start snmpd Сообщение об ошибке как-то не особо помогло в решении проблемы, но все-же рискнем заглянуть в логи: FreeBSD# cat /var/log/snmpd.log init_kmem: kvm_openfiles failed: /dev/mem: No such file or directory Agent initialization failed Решение оказалось простым man snmpd : FreeBSD# man snmpd .... -r Do not require root access to run the daemon. Specifically, do not exit if files only accessible to root (such as /dev/kmem etc.) cannot be opened. ..... Как сказано в мане, говорим демону snmpd запускаться с опцией -r , добавляем в /etc/rc.conf строку: #----------------------------- SNMP ---------------------------------------# snmpd_enable=\"YES\" snmpd_flags=\"-r\" #--------------------------------------------------------------------------# И пробуем еще раз, теперь должно все запуститься: FreeBSD# service snmpd restart Stopping snmpd. Waiting for PIDS: 27711. Starting snmpd. Error 2 (No such file or directory) could not get the assoclist Опять какая-то ошибка, немного погуглив яндексом в рамблере нашел страничку с описанием бага #2311 , там говорится про ядро FreeBSD и отсутствие в нем SCTP (У меня в ядре как раз небыло этого SCTP ) и эту ошибку можно спокойно проигнорировать. Ну чтож, если говорят, что все должно работать, то проверяем: FreeBSD# sockstat | grep snmpd root snmpd 27758 6 udp4 *:161 *:* root snmpd 27758 7 stream /var/agentx/master root snmpd 27758 8 tcp4 *:199 *:* root snmpd 27758 9 stream /var/agentx/master Как видим, `snmpd` слушает `161` порт и **UNIX**-сокет `/var/agentx/master`. Значит мы все сделали правильно, и теперь двигаемся дальше к настройке **zabbix**. ...... Тут должна быть часть о настройке Zabbix :) Когла-нибудь допишу. ...... Настройка сервера Zabbix Основную работу мы проделали. Теперь нам нужно подключить сервер к Zabbix и добавить туда шаблон. Сначала добавим шаблон, это делается в меню Настройки – Шаблон – Импорт шаблона. Шаблон можно скачать тут. Перед тем, как импортировать его, все значения PASSWORD нужно сменить на тот пароль, который вы указали в snmpd.conf. Теперь добавим наш сервер Настройка – Узлы сети – Создать узел сети. Заполняем поля, вводим название хоста, его ИП адрес, присоединяем шаблон, который мы импортировали. Все, теперь все должно работать. Шаблон умеет показывать количество каналов, версию , аптайм , ИД процесса, количество загруженных модулей. Так же в шаблоне есть встроенный график, отображающий количество каналов. Ссылки по теме: FreeBSD jails and net-snmp SourceForge SNMPd bug: #2311 5.7.1 errors at startup on FreeBSD systems without SCTP Asterisk MIB Definitions asterisk-users mailing list - ASTERISK and SNMP Мониторим Asterisk при помощи snmp и Zabbix","tags":"FreeBSD","title":"Asterisk 1.8 и статистика по SNMP в zabbix"},{"url":"blog/freebsd-git-gitweb-nginx-fcgiwrap/","text":"Понадобился репозиторий для хранения конфигов серверов и активного сетевого оборудования. Почитав про системы контроля версий и немного поразмыслив выбрал git . У меня уже имелся готовый веб хостинг на nginx под FreeBSD - решил использовать его. Итак смотрим что есть в составе порта git : cd /usr/ports/devel/git/ make config [ * ] CONTRIB Install contributed scripts [ * ] CURL Data transfer via cURL [ * ] CVS Enable CVS support [ ] ETCSHELLS Modify /etc/shells [ * ] GITWEB Install gitweb [ ] GUI GUI ( Graphical User Interface ) [ ] HTMLDOCS Install additional documentation [ * ] ICONV Encoding conversion via iconv [ * ] NLS Native Language Support [ * ] P4 Enable Perforce support [ * ] PERL Perl scripting language [ ] SVN Subversion support Меня интересовали 2 вещи, какая-нибудь простенькая веб морда интерфейс и собственно сам git . Видим, что в составе порта есть GITWEB , как говорит wikipedia \" gitweb - написан на Perl (Kay Sievers). Большинство приведённых ниже крупных публичных git -репозиториев его и применяет.\" Настраиваем по вкусу и ставим: make config-recursive make install clean Затем идем в /etc/rc.conf и приводим блок с веб сервером примерно к такому виду: #----------------------------- nginx --------------------------------------# nginx_enable = \"YES\" # (bool) Set to \"NO\" by default. Set it to \"YES\" to enable nginx nginx_profiles = \"\" # (str) Set to \"\" by default. Define your profiles here. nginxlimits_enable = \"NO\" # (bool) Set to \"NO\" by default. Set it to yes to run `limits $limits_args` just before nginx starts. nginx_flags = \"\" # (str) Set to \"\" by default. Extra flags passed to start command. nginxlimits_args = \"-e -U www\" # (str) Default to \"-e -U www\" Arguments of pre-start limits run. php_fpm_enable = \"YES\" fcgiwrap_enable = \"YES\" fcgiwrap_user = \"www\" # (str) run fcgiwrap as user #fcgiwrap_socket=\"unix:/var/run/fcgiwrap/fcgiwrap.sock\" #this could also be: tcp:[ipv4_addr]:port (for ipv4) | tcp6:[ipv6_addr]:port (for ipv6) #fcgiwrap_flags=\"-c 4\" fcgiwrap_profiles = \"gitweb\" fcgiwrap_gitweb_socket = \"unix:/var/run/fcgiwrap/gitweb.socket\" #--------------------------------------------------------------------------# Я специально запускаю отдельный экземпляр fcgiwrap для каждого \"сайта\". Если не дай бог упадет, то упадет только один сайт, а не все сразу. :) Теперь настройки nginx: server { #-------------------------- Options --------------------------# listen 192.168.4.27 : 443 ; server_name git.local git ; open_file_cache max=100000 inactive=40s ; open_file_cache_valid 60s ; open_file_cache_min_uses 2 ; open_file_cache_errors on ; #ssl # ssl on; # ssl_certificate ssl/git/git.local.crt; # ssl_certificate_key ssl/git/git.local.key; #logs access_log /var/log/nginx/git.local_https_access.log ; error_log /var/log/nginx/git.local_https_error.log ; #-------------------------- Configs --------------------------# # Default config include confs/main.conf ; gzip off ; #-------------------------- Locations ------------------------# # Main location location / { root /usr/local/www/gitweb ; index gitweb.cgi ; location ~ &#94;/(.*\\.cgi)$ { include fastcgi_params ; fastcgi_pass unix:/var/run/fcgiwrap/gitweb.socket ; fastcgi_index gitweb.cgi ; fastcgi_param SCRIPT_FILENAME /usr/local/www/gitweb/gitweb.cgi ; fastcgi_param DOCUMENT_ROOT /usr/local/www/gitweb ; } } } Теперь самое интересное, после установки порта devel/git в каталоге веб сервера /usr/local/www ничего не появилось, хотя опция GITWEB была отмечена, беглый анализ логов установки и поиск по винту навел на папочку: FreeBSD# find /usr -name gitweb /usr/local/share/examples/git/gitweb FreeBSD# ls /usr/local/share/examples/git/gitweb gitweb.cgi static Вот оно! Копируем всю найденную папку gitweb в каталог веб сервера: cp /usr/local/share/examples/git/gitweb /usr/local/www Запускаем сервисы: FreeBSD# service nginx reload Performing sanity check on nginx configuration: nginx: the configuration file /usr/local/etc/nginx/nginx.conf syntax is ok nginx: configuration file /usr/local/etc/nginx/nginx.conf test is successful FreeBSD# service fcgiwrap start === > fcgiwrap profile: gitweb Starting fcgiwrap. Переходим по ссылке http://git.local - все работает, ура! :) P.S. Памятка работы с git репозиторием: Создаю на сервере новую папку (например /git/www/test ). mkdir -p /git/www/test Делаю в ней инициализацию пустого репозитория git init : cd /git/www/test git init На локальной машине скачиваю созданный репозиторий: git clone git@git.local:/git/www/test/.git Это создаст локальную копию удалённого репозитория (пока пустого). Накидываю кучу файлов в локальную папку, которую мы создали на предыдущем шаге. Делаю, так сказать, каркас проекта. Если нужно — добавляю исключения в файл ( .gitignore ) Выполняю: cd /git/www/test git add . git commit git push Обязательно ввожу комментарий к своим изменениям - желательно писать всегда что-то адекватное, чтобы потом можно было понять что именно было изменено. git add . - добавляет новые файлы в репозиторий от текущего каталога. `git commit - Фиксирует новую ревизию кода - тут-то и спросит ввести комментарий. `git push - Отправляет изменения на сервер. Всё. Локальный и удалённый репозиарии обновлены и синхронизированы. Если вы веб-разрабочик и вам нужно довольно часто показывать текущий результат работы — очень полезно будет положить файл post-receive в папку .git/hooks какого-либо проекта с таким содержимым: #!/bin/sh cd .. env -i git checkout -f echo \"Удалённый репозиторий успешно обновлён!\" И дайте ему права на исполнение. Теперь после каждого обновления (шаг 5) будет также обновляться рабочее дерево проекта и реальные файлы всегда будут последней, актуальной версии (а этого почти все и ожидают, когда обновили удалённый репозиторий, но так по умолчанию не происходит). UPD : 21.06.2014 Если после настройки появляется ошибка: 404 - No projects found. Возможно причина в правах на репазитории, необходимо, чтобы владельцем файлов в репазиториях был тот же пользователь, что и у fcgiwrap . Если репазитории храятся в /git-repos, то решением будет: cd /git-repos chown -R www:www . Ссылки по теме: Wikipedia - Git HOWTO: GIT hosting = nginx + cgit + gitosis + ssh Устанавливаем и настраиваем cGit на Ubuntu Собственный сервер Git на базе Ubuntu или Debian/GNU Linux Tip по использованию Git под Windows Installing Git and Gitweb on FreeBSD Simple CGI support for Nginx (fcgiwrap) 4.1 Git на сервере - Протоколы Configuring GitWeb - 404 - No projects found","tags":"FreeBSD","title":"Установка git + gitweb + nginx + fcgiwrap на FreeBSD."},{"url":"blog/freebsd-virtualbox-autostart-vm-on-boot/","text":"Столкнулся с проблемой на FreeBSD - не запускаются виртуальные машины при загрузке системы. Все оказалось довольно просто - нужные модули ядра не подгружались при загрузке системы, выход оказался очень прост - при запуске скрипта /usr/local/etc/rc.d/vboxheadless подгружать эти модули, если они вдруг не загружены. Открываем стартовый скрипт /usr/local/etc/rc.d/vboxheadless , находим там строки: vboxheadless_start () { local machine mpidfile pid vmname vmuser vmflags vmdelay И добавляем заветные строки, которые будут проверять и загружать необходимые модули ядра, если потребуется: vboxheadless_start () { local machine mpidfile pid vmname vmuser vmflags vmdelay ( ! kldstat | grep vboxnetflt >/dev/null ) && kldload vboxnetflt ( ! kldstat | grep vboxnetadp >/dev/null ) && kldload vboxnetadp Ну и не забываем в /etc/rc.conf указать нужные настройки: #---------------------- VirtualBox ----------------------------------------# vboxnet_enable = \"YES\" vboxheadless_enable = \"YES\" # (bool): Set to \"NO\" by default. Set it to \"YES\" to enable vboxheadless. vboxheadless_user = \"root\" # (str): Default user account to run with. (default: vboxusers) vboxheadless_stop = \"poweroff\" # (str): Default stop cmd for VBoxManage controlvm. (default: savestate) vboxheadless_delay = \"0\" # (int): Default startup/shutdown delay in seconds. (default: 0) vboxheadless_machines = \"Win7\" # (str): Space separated list of machines. #--------------------------------------------------------------------------# А так же в файле /boot/loader.conf добавляем строку: vboxdrv_load = \"YES\" Теперь все будет само запускаться, при загрузке системы!","tags":"FreeBSD","title":"VirtualBox и FreeBSD, не запускаются виртуальные машины при загрузке системы."},{"url":"blog/logging-in-isc-dhcp-server-freebsd/","text":"После установки и настройки порта isc-dhcpd-server очень захотелось, чтобы логи от этого демона складировались в отдельный файлик, например /var/log/dhcpd.log , а не в общий системный лог /var/log/messages . Как этого достичь описано ниже. Первым делом добавляем строку в конфиг демона dhcpd /usr/local/etc/dhcpd.conf : log-facility local7 ; # куда в syslog шлем логи Теперь в syslog принимаем от демона dhcpd логи - добавляем строки в файл /etc/syslog.conf : !dhcpd local7.* /var/log/dhcpd.log # Если встретили эту сроку (я имею ввиду это -> !*), то закоментируйте, а то не заработает :) #!* А так же рассказываем syslog 'у, что у нас есть dhcpd демон, для этого добавляем опцию в /etc/rc.conf : syslogd_flags = \"-l /var/db/dhcpd/var/run/log -ss\" И не забываем про ротацию логов в /etc/newsyslog.conf добавляем строки: # dhcp /var/log/dhcpd.log 644 15 300 * XC Ссылки по теме: FreeBSD: DHCP-сервер для локальной сети на базе ISC DHCP Server Cisco DHCP Snooping with ISC DHCPd Reagent Team - dhcp opt 82","tags":"FreeBSD","title":"Настраиваем запись логов в isc-dhcp-server под FreeBSD"},{"url":"blog/windows-migrate-to-hardware-raid/","text":"Уменьшить размер раздела через Gparted через Ubuntu Live CD . Загрузиться и проверить, что все ОК. Скорей всего запустится chkdsk и будет испрвлять ошибки. Сделать образ РАЗДЕЛОВ в clonezilla . Собрать рейд и установить винду на рейд, используя драйвера. Отключить рейд контроллер и подключить винты в материнскую плату. Восстановить из образа clonezilla содержимое разделов, не трогая MBR ! Возможно 100Мб раздел не нужно восстанавливать, т.к. туда были установлены драйвера для рейда, а в сохраненном образе их НЕТ! Следовательно средство восстановления запуска не получится запустить в дальнейшем... Чтобы избежать этой проблемы лучше не восстаналивать 100Мб раздел... Хотя не уверен! Нужно проверить. Подключить обратно рейд контроллер и винты. Загрузиться и проверить, что все работает :) Скорей всего запустится chkdsk и будет испрвлять ошибки. P.S. Это сырая статья.","tags":"Windows","title":"Перенос Windows на RAID контроллер."},{"url":"blog/ubuntu-system-vnc/","text":"Выкладываю функцию добавления VNC сервиса. Данная функция используется в моем скрипте lentayka_14.04.sh . Функция была проверена на Ubuntu 12.04 LTS install_vnc_service () { apt-get purge vino apt-get install x11vnc mkdir /etc/x11vnc chmod 755 /etc/x11vnc sudo x11vnc -storepasswd YouPasswordHere /etc/x11vnc/passwd chmod 644 /etc/x11vnc/passwd cat > /etc/init/x11vnc.conf <<-_EOF start on login-session-start script x11vnc -xkb -bg \\ -noxrecord \\ -noxfixes \\ -noxdamage \\ -display :0 \\ -auth /var/run/lightdm/root/:0 \\ -rfbauth /etc/x11vnc/passwd \\ -forever \\ -o /var/log/x11vnc.log end script _EOF } Данная функция настраивает запуск x11vnc через upstart . Ссылки по теме: How to setup VNC server for remote desktop in Ubuntu 11.10 Oneiric Remote VNC login to Ubuntu 11.10 Запуск VNC-сервера в Ubuntu 11.10 (LightDM) Быстрая настройка x11vnc","tags":"Ubuntu","title":"Ubuntu установка VNC сервера не зависимого от пользователей."},{"url":"blog/ddos-nginx-linux/","text":"Однажды мой знакомый написал мне, что его сайт перестал открываться сказал, что на сайт обрушилась DDoS атака. Полез я разбираться, в чем дело и в итоге суть проблемы была найдена - куча ip адресов с различными User Agent 'ами приходили на сайт и делали очень много различных запросов... В общем нужно было этих ботов отлавливать и блокировать им доступ к сайту, сперва подумал об iptables и ConfigServer Firewall ( csf ), но хостинг был внутри OpenVZ , а это означало невозможность использования более 120 правил, а так же невозможность установки модулей ядра и вообще каких либо изменений опций ядра. Потому стандартные подходы для решения проблемы сразу отпадали. А время шло, и переписываться с тех поддежкой хостинга небыло времени, а платить огромные суммы за защиту от такой примитивной атаки небыло никакого желания. Решение пришло в голову неожиданно, при перечитывании man ip , вспомнить зачем я его читал затрудняюсь, но решение было на редкость извращенским , но вполне рабочим :) Решением было добавление маршрута проблемного IP в blackhole . В следствие чего пакеты от этих адресов будут молча отбрасываться (the rule prescribes to silently drop the packet.). Сперва конфигурируем nginx : ... worker_rlimit_nofile 200000 ; events { worker_connections 1024 ; use epoll ; } .... http { index index.html index.htm index.php ; ## # Basic Settings ## sendfile on ; send_timeout 5 ; tcp_nopush on ; tcp_nodelay on ; keepalive_timeout 30 15 ; types_hash_max_size 2048 ; server_tokens off ; client_header_timeout 15 ; client_body_timeout 15 ; # лимитируем для зоны one 10 конектов в 1 сек. limit_req_zone $binary_remote_addr zone = one:16m rate = 10r/s ; # В ситуации когда сервер записал в сокет данные, но клиент не хочет # их забирать, после таймаута по закрытию соединения в ядре # данные будут держаться еще несколько минут. В nginx если директи ва # для принудительного сброса всех данных после закрытия по таймаут у. reset_timedout_connection on ; include /etc/nginx/mime.types ; default_type application/octet-stream ; # Logging Settings access_log /var/log/nginx/access.log ; error_log /var/log/nginx/error.log ; gzip on ; gzip_disable \"msie6\" ; ... server { listen 80 ; server_name my.site ; open_file_cache max = 100000 inactive = 40s ; open_file_cache_valid 60s ; open_file_cache_min_uses 2 ; open_file_cache_errors on ; # это значит что законектится с лимитом в 3 подключения за 1 сек можно 3 раза, а дальше 503 ошибка. Что и пишется в лог access. limit_req zone = one burst = 10 ; # Default locations config. include conf.std ; ... } ... } Файлик /etc/nginx/conf.std : ####### STANDART # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html ; location = /50x.html { root /usr/share/nginx/html ; } # Deny access to .htaccess files, if Apache's document root concurs with nginx's one location ~ / \\. ( ht | hg | git | svn ) { deny all ; } location ~ / \\< { deny all ; } С конфигурацией nginx все, теперь скрипты. Добавляем в файл /etc/crontab строки: # parse nginx logs and ban bad ip via nullroute * * * * * root /root/ddos/parse_nginx.log.sh >/root/ddos/parse_nginx.log.log 2 > & 1 Содержимое скрипта /root/ddos/parse_nginx.log.sh : #!/bin/sh ADMINS_IP = 'ip.ip.ip.ip' echo $( date ) echo '--- запускаем систему парсинга nginx лога---' echo ' ищем ботов' cat /var/log/nginx/access.log \\ | grep -E -e 'HTTP/1.(0|1)\" (400|403|405|499|503)' -e '] \"-\" 400 0 \"-\" \"-\"' \\ | awk '{print $1}' \\ | sort -nr | uniq -c \\ | awk '{if($1>10)print $1\" \"$2}' \\ > /root/ddos/banlist.txt cat /var/log/nginx/error.log \\ | grep -E '(limiting requests|limiting connections)' \\ | awk -F \"client: \" '{print $2}' \\ | awk -F \",\" '{print $1}' \\ | sort -nr | uniq -c \\ | awk '{if($1>10)print $1\" \"$2}' \\ >> /root/ddos/banlist.txt # get unique ip cat /root/ddos/banlist.txt \\ | grep -v $ADMINS_IP \\ | uniq | sort -nr \\ > /root/ddos/banlist_uniq.txt echo '------ очищаем tmp file бана-' cat /dev/null > /root/ddos/banlist.txt echo ' создаем DROP правила для 50 самых агрессивных ботов' awk '{print $2}' /root/ddos/banlist_uniq.txt | uniq | head -n 150 > /root/ddos/banlist.txt #т.к. iptables полнейшее УГ, особенно внутри OpenVZ, баним ip вот таким извращенским методом... через nullroute #ip route flush type blackhole for ip in $( cat /root/ddos/banlist.txt ) ; do ip route add blackhole ${ ip } /32 done #echo 'записываем злобных ботов в csf.deny' #cat /etc/csf/csf.deny >> /root/ddos/banlist.txt #cat /root/ddos/banlist.txt | uniq | sort -nr > /etc/csf/csf.deny #echo 'csf релоад, внесение в iptables ботов' #/usr/sbin/csf -r sleep 5 echo '-- делаем ротацию лога--------' test -x /usr/sbin/logrotate || exit 0 /usr/sbin/logrotate /etc/logrotate.conf echo '=====злобные боты в списке бана=====' sleep 1 Для мониторинга состояния сервера используем такой скрипт: #!/bin/sh while true ; do netstat_str = $( netstat -an ) echo -n 'SYN_RECV: ' echo \" $netstat_str \" | grep 80 | grep -c SYN_RECV echo -n 'TIME_WAIT: ' echo \" $netstat_str \" | grep 80 | grep -c TIME_WAIT echo -n 'FIN_WAIT: ' echo \" $netstat_str \" | grep 80 | grep -c FIN_WAI1 echo -n 'ESTABLISHED: ' echo \" $netstat_str \" | grep 80 | grep -c ESTABLISHED echo -n 'BLOCKED_IP to Black-route: ' ip route list | grep -c blackhole sleep 2 echo '------------------------- for stop this script Press Ctrl+C' done Еще понадобится настроить ротацию логов, приводим файл /etc/logrotate.d/nginx к такому виду: /var/log/nginx/*.log { size 1M missingok rotate 52 compress delaycompress notifempty create 640 nginx adm sharedscripts postrotate [ -f /var/run/nginx.pid ] && kill -USR1 ` cat /var/run/nginx.pid ` endscript } Поменялся метод ротации вместо daily теперь используется size 1M , это позволит уменьшить объем лог файла, т.к. за сутки он может очень сильно вырасти в объеме, что замедлит парсинг и увеличит нагрузку на сервер, а использование ротации по размеру исправит эту ситуацию. Еще я использовал встроенные средства iptables для борьбы с DDoS : #!/bin/sh iptables -F iptables -N syn_flood iptables -A INPUT -p tcp --syn -j syn_flood iptables -A syn_flood -m limit --limit 100 /s --limit-burst 150 -j RETURN iptables -A syn_flood -j DROP Данный скрипт спокойно блокировал DDoS примерно в 10 000 ботов , при этом сайт был полностью доступен и атака вообще не чувствовалась. Прошу обратить внимание на то, что скрипт запускается раз в минуту, и блокирует ip адреса по заданным критериям в скрипте /root/ddos/parse_nginx.log.sh . В моем случае атака была \"вялой\" и одной минуты вполне хватало для сбора ip адресов ботов. В первые минуты сайт \"туго\" работал, но спустя минут 10 , когда список заблокированных вырос сайт начал свою штатную работу, а список блокированных с течением времени увеличивался все медленнее и в итоге совсем перестал расти - у атакующего закончились боты.","tags":"Linux","title":"Борьба с DDoS SYN-Flood штатными средствами и nginx в Linux"},{"url":"blog/rdp-windows-easy-print-driver/","text":"Для работы перенаправленных принтеров через RDP сессию в Windows 2008 нужно, чтобы у клиента были установлены: Microsoft .NET Framework 3.5. Клиент служб терминалов версии 6.1, для Windows XP (KB952155). В этом случае принтеры имеющиеся у клиента, будут автоматически перенаправлены через RDP сессию на сервер терминалов. ВАЖНО! Чтобы не расшаривать каждый принтер у клиента, нужно включить Брандмауэр и выбрать тип сети - \" Сеть Предприятия \". P.S. Что самое замечательное , у клиентов видны только их принтеры, и они не смогут распечатать случайно на чужом принтере! И еще больше всего мне понравилось то, надобность установки драйверов отпадает для многих принтеров - практически все заводятся через Easy Print драйвер. Ссылки по теме: Подключение к удаленному рабочему столу (клиент служб терминалов версии 6.1) для Windows XP (KB952155) Microsoft .NET Framework 3.5","tags":"Windows","title":"RDP Windows, перенаправленные принтеры, Easy Print Driver."},{"url":"blog/KIASUO-1252-windows-server-x64-corflags-exe/","text":"Дело в том, что программа КИАСУО ниже версии 1280 откомпилирована с опцией \"для всех архитектур\", и при запуске на 64 разрядных ОС не запускается. Лечится это довольно просто, ниже описана методика. Смотрим статус: C:\\Users\\Администратор>cd \"C:\\Program Files (x86)\\КИАСУО3\\OuServer\\bin\\Release\" C:\\Program Files (x86)\\КИАСУО3\\OuServer\\bin\\Release>CorFlags.exe OuServer.exe Microsoft (R) .NET Framework CorFlags Conversion Tool. Version 2.0.50727.42 Copyright (c) Microsoft Corporation. All rights reserved. Version : v2.0.50727 CLR Header: 2.5 PE : PE32 CorFlags : 9 ILONLY : 1 32BIT : 0 Signed : 1 Видим, что флаг 32BIT : 0 не установлен. Для запуска КИАСУО на Windows Server 2008 X64 нужно найти утилитку CorFlags.exe — 73.7 КБ , скопировать ее в папку с файлом OuServer.exe и проделать следующее: C:\\Users\\Администратор>cd \"C:\\Program Files (x86)\\КИАСУО3\\OuServer\\bin\\Release\" C:\\Program Files (x86)\\КИАСУО3\\OuServer\\bin\\Release>CorFlags.exe OuServer.exe /32BIT+ /Force Microsoft (R) .NET Framework CorFlags Conversion Tool. Version 2.0.50727.42 Copyright (c) Microsoft Corporation. All rights reserved. corflags : warning CF011 : The specified file is strong name signed. Using /For ce will invalidate the signature of this image and will require the assembly to be resigned. Проверяем результат: C:\\Program Files (x86)\\КИАСУО3\\OuServer\\bin\\Release>CorFlags.exe OuServer.exe Microsoft (R) .NET Framework CorFlags Conversion Tool. Version 2.0.50727.42 Copyright (c) Microsoft Corporation. All rights reserved. Version : v2.0.50727 CLR Header: 2.5 PE : PE32 CorFlags : 11 ILONLY : 1 32BIT : 1 Signed : 1 Видим флаг 32BIT : 1 установлен, приятной работы! После этого сервер запускается нормально. У меня заработал как в ручном режиме запуска, так и в режиме сервиса. Ссылки по теме: CorFlags.exe (CorFlags Conversion Tool) Flipping bits on managed images to make them load with the right bitness...","tags":"Windows","title":"Запуск КИАСУО 1252 на Windows Server x64, corflags.exe, NetFramework 3.5"},{"url":"blog/ubuntu-dns-suffix_etc-nsswitch.conf/","text":"Столкнулся с проблемой, когда Ubuntu при работе по DHCP неправильно работала с DNS -суффиксом, а именно работала только с суффиксами, а полные доменные имена ( FQDN ) не понимала, как следствие некорректно работали некоторые локальные сайты в браузерах, да и банальные пинги работали как-то не совсем правильно: ping server PING server.local ( 192 .168.0.2 ) 56 ( 84 ) bytes of data. 64 bytes from server.local ( 192 .168.0.2 ) : icmp_req = 1 ttl = 64 time = 0 .131 ms &#94;C ping server.local ping: unknown host server.local При этом DNS сервер отлично обрабатывает запросы: nslookup server Server: 192 .168.0.254 Address: 192 .168.0.254#53 Name: server.local Address: 192 .168.0.2 И для доменного имени полностью: nslookup server.local Server: 192 .168.0.254 Address: 192 .168.0.254#53 Name: server.local Address: 192 .168.0.2 Погуглив немного, решил, что проблема в NetworkManager 'е, на старых версиях Ubuntu он неправильно генерировал /etc/resolv.conf , проверил свой: cat /etc/resolv.conf # Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8) # DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 192 .168.0.254 search local Как оказалось, в моем случае NetworkManager вовсе не виноват! Но в чем же тогда проблема? Еще раз погуглил яндексом в рамблере и пришел к выводу, что виноват конфиг /etc/nsswitch.conf , сравнил его с FreeBSD 'шным, где все работает как надо и пришел к выводу, что нужно строку hosts: привести к такому виду: # НЕ работает! #hosts: files mdns4_minimal [NOTFOUND=return] dns mdns4 # работает! hosts: files dns Что такое mdns4 разбираться не стал (позже узнал, что это avahi так делает), без него все работает так, как надо и это главное. Ссылки по теме: Debian/Ubuntu - [решено] Не распознаёт имя контроллера домена","tags":"Ubuntu","title":"Ubuntu и DNS-Суффикс, /etc/nsswitch.conf, NetworkManager"},{"url":"blog/freebsd4-migrate-to-virtualbox/","text":"Заходим по ssh на машину, которую будем переносить, останавливаем все процессы, которые могут использовать hdd и писать туда важную информацию (например MySQL и т.п.) и делаем дампы всех важных разделов: dump -0uan -f - /usr | ssh -c blowfish user@ip.ip.ip.ip dd of = /home/user/oldsrv/var.dd dump -0uan -f - /var | ssh -c blowfish user@ip.ip.ip.ip dd of = /home/user/oldsrv/var.dd Грузимся с LiveCD FreeBSD у меня уже была загрузка по сети FreeBSD 9.0 (но думаю подойдет и любой другой дистрибутив, Frenzy например). Восстанавливаем корневой раздел: mkdir /tmp/oldsrv cd /tmp/oldsrv scp user@ip.ip.ip.ip:/home/user/oldsrv/*.dd dd if = from_real_srv/rootfs.dd | restore -rf - ... Убедиться, что все необходимые каталоги, куда будем восстанавливать остальные разделы имеются: ls usr ls var ... И начинаем восстанавливать остальные разделы: dd if = from_real_srv/usr.dd | ( cd usr ; restore -rf - ) dd if = from_real_srv/var.dd | ( cd var ; restore -rf - ) ... Ссылки по теме: 17.12. Основы технологии резервного копирования. Перенос FreeBSD с одного жёсткого диска на другой.","tags":"FreeBSD","title":"Перенос FreeBSD 4 на VirtualBox"},{"url":"blog/ubuntu-midnight-commander/","text":"Вот такой нехитрый скрипт установит и избавит от проблем с F10 при работе в терминале с mc в Ubuntu . #!/bin/sh sudo apt-get install mc gconftool-2 --set --type string \"/apps/compiz-1/plugins/unityshell/screen0/options/panel_first_menu\" \"Disabled\" # Unity Panel 3D gconftool-2 --set --type bool \"/apps/gnome-terminal/global/use_menu_accelerators\" \"false\" # Gnome-Terminal # И последний штрих для Ubuntu 12.04-LTS [ ! -d ~/.config/gtk-3.0/ ] && mkdir -p ~/.config/gtk-3.0/ cat >~/.config/gtk-3.0/gtk.css <<_EOF @binding-set NoKeyboardNavigation { unbind \"<shift>F10\" } * { gtk-key-bindings: NoKeyboardNavigation } _EOF После чего придется закрыть все открытые окна терминала, чтобы изменения вступили в силу.","tags":"Ubuntu","title":"Ubuntu и Midnight Commander, mc и Unity 3D исправляем проблему с F10 в терминале"},{"url":"blog/custom-user-fonts-in-ubuntu-linux/","text":"Extract the ttf file and copy into .fonts via: Go to your home folder Enable \" Show Hidden Files \" option from Nautilus View menu Then create new folder with name .fonts (with dot in front) Now in new folder copy all your true type fonts. If you want to copy your Windows fonts, you can find it in Windows/Fonts folder. Now restart and new fonts will be in use.","tags":"Ubuntu","title":"Custom user fonts in Ubuntu Linux"},{"url":"blog/disable-ipv6-ubuntu/","text":"Для начала открываем, а если его еще нет, то создаем файл /etc/modprobe.d/aliases и добавляем такие строки: alias net-pf-10 ipv6 off alias net-pf-10 off alias ipv6 off Далее правим /etc/modprobe.d/blacklist.conf : echo \"blacklist ipv6\" >> /etc/modprobe.d/blacklist.conf И наконец редактируем файл /etc/default/grub , добавляя в конец опции GRUB_CMDLINE_LINUX_DEFAULT строку ipv6.disable=1 , в итоге получаем: GRUB_CMDLINE_LINUX_DEFAULT = \"quiet splash ipv6.disable=1\" После чего даем команду sudo update-grub и перезагружаем систему. На этом все, ipv6 будет отключен в системе. Для проверки отключен ли ipv6 выполняем: sudo netstat -npl | grep -E \"tcp6|udp6\" | wc -l Если видим 0 , значит все сделано правильно. Ссылки по теме: 1. Отключение ipv6 в Ubuntu / Debian","tags":"Ubuntu","title":"Отключение ipv6 в Ubuntu"},{"url":"blog/javascript-formatted-date/","text":"< script language = \"JavaScript\" > <!-- var month = new Array ( 12 ); month [ 0 ] = \"Января\" ; month [ 1 ] = \"Февраля\" ; month [ 2 ] = \"Марта\" ; month [ 3 ] = \"Апреля\" ; month [ 4 ] = \"Мая\" ; month [ 5 ] = \"Июня\" ; month [ 6 ] = \"Июля\" ; month [ 7 ] = \"Августа\" ; month [ 8 ] = \"Сентября\" ; month [ 9 ] = \"Октября\" ; month [ 10 ] = \"Ноября\" ; month [ 11 ] = \"Декабря\" ; var lastmoddate = Date . parse ( document . lastModified ); // Получает строку даты последней модификации var d = new Date (); d . setTime ( lastmoddate ); // lastmoddate приводим к типу данных Date if ( lastmoddate == 0 ) { // неизвестная дата (или 1 июля, 1970 GMT) var datestr = \"Неизвестна\" ; } else { var datestr = d . getDate () + ' ' + month [ d . getMonth ()] + ' ' + d . getFullYear (); } document . write ( \"Дата последнего изменения: \" + datestr ); //-->; </ script > Ссылки по теме: 1. Отображаем точное время и дату с помощью JavaScript. 2. Date.parse Синтаксис, Описание, примеры.","tags":"JavaScript","title":"JavaScript вывод даты модификации html документа в форматированном виде"},{"url":"blog/freebsd-90-gpt-gmirror/","text":"Столкнулся с проблемой реализации подобной связки GPT и gmirror на FreeBSD 9.0 . Методом проб и ошибок получилась вот такая пошаговая инструкция: Загружаемся с диска FreeBSD 9.0 amd64 в режиме LiveCD , система спросит логин, вводим root , а вместо пароля просто жмем Enter. Удаляем все GPT данные с дисков: gpart destroy -F ada0 gpart destroy -F ada1 Создаем GPT на 1 диске: bash gpart create -s gpt ada0 Создаем GPT разметку на 1 диске: 3.1 Загрузочный раздел gpart add -b 34 -s 94 -t freebsd-boot ada0 3.2 Раздел подкачки gpart add -s 5G -t freebsd-swap ada0 3.3 Файловую систему UFS gpart add -t freebsd-ufs ada0 3.4 Проверяем все ли так, как мы задумали gpart show = > 34 2930277101 ada0 GPT ( 1 .4T ) 34 94 1 freebsd-boot ( 47k ) 128 2097152 2 freebsd-swap ( 1 .0G ) 2097280 2928179855 3 freebsd-ufs ( 1 .4T ) 3.5 Записываем загрузчик gpart bootcode -b /boot/pmbr -p /boot/gptboot -i 1 ada0 3.6 Копируем разметку GTP с 1 диска на 2 диск gpart backup ada0 | gpart restore -F ada1 3.7. Проверяем что теперь получилось: gpart show = > 34 2930277101 ada0 GPT ( 1 .4T ) 34 94 1 freebsd-boot ( 47k ) 128 2097152 2 freebsd-swap ( 1 .0G ) 2097280 2928179855 3 freebsd-ufs ( 1 .4T ) = > 34 2930277101 ada1 GPT ( 1 .4T ) 34 94 1 freebsd-boot ( 47k ) 128 2097152 2 freebsd-swap ( 1 .0G ) 2097280 2928179855 3 freebsd-ufs ( 1 .4T ) загружаем gmirror : gmirror load 4.1 Создаем RAID1 для SWAP раздела gmirror label -v -b round-robin swap /dev/ada0p2 4.2 Добавляем 2 -ой диск в зеркало: gmirror insert swap /dev/ada1p2 4.3 Создаем RAID1 для UFS раздела: gmirror label -v -b round-robin rootfs ada0p3 4.4 Добавляем 2 -ой диск в зеркало: gmirror insert rootfs /dev/ada1p3 4.5 Удалить случайно созданные RAID1 разделы(если вдруг чего-то напутали выше) gmirror remove swap ada0p2 ada1p2 Создаем файловые системы на RAID1 разделах newfs -m 1 -U /dev/mirror/rootfs УСТАНОВКА FreeBSD : 6.1 Монтируем созданную файловую систему в /mnt mount /dev/mirror/rootfs /mnt 6.2 Устанавливаем FreeBSD 9.0 cd /usr/freebsd-dist sh export DESTDIR = /mnt for file in base.txz kernel.txz lib32.txz ; do ( cat $file | tar --unlink -xpJf - -C ${ DESTDIR :- / } ) ; done 6.3 Создаем /etc/fstab для установленной системы: cat > /mnt/etc/fstab <<-__EOF__ #dev #mount #fs #opts #dump #pass /dev/mirror/rootfs / ufs rw 1 1 /dev/mirror/swap none swap sw 0 0 __EOF__ 6.4 Создаем /boot/loader.conf cat > /mnt/boot/loader.conf <<-__EOF__ geom_mirror_load=\"YES\" __EOF__ Отмонтируем зеркало umount /mnt все готово, теперь можно перезагружаться и смотреть на результат Ссылки по теме: http://forums.freebsd.org/showthread.php?t=29098 HOWTO: Install FreeBSD 9.0 RELEASE (Root on UFS + ZFS, RAID1) http://bu7cher.blogspot.com/2011/03/freebsd-gmirror-gpt-ufs.html Варианты загрузки FreeBSD: gmirror + GPT + UFS http://www.lissyara.su/articles/freebsd/file_system/gmirror/ Использование gmirror для создания программного зеркалирования дисков http://forums.freebsd.org/showthread.php?t=28348 [Solved] No gmirror in 9.0, now what? http://www.wonkity.com/~wblock/docs/html/gmirror.html gmirror With Disk Partitions http://blather.michaelwlucas.com/archives/1071 mirroring FreeBSD-9 disks with GPT","tags":"FreeBSD","title":"FreeBSD 9.0 GPT + gmirror"},{"url":"blog/sed-dos2unix-unix2dos/","text":"Команда dos2unix служит для преобразования форматов текстовых файлов MSDOS к UNIX формату, а команда unix2dos служит для преобразования форматов текстовых файлов UNIX к формату MSDOS* и windows *. Известно, что форматы текстовых файлов в DOS и в UNIX немного отличаются: В DOS все строки заканчиваются парой символов CR и LF (возврат каретки /r и перевод строки /n ) А * UNIX использует только символ LF перевод строки /n , справедливо полагая, что второй символ совершенно излишен. Чтобы не устанавливать эти консольные утилиты dos2unix и unix2dos можно воспользоваться вот такими несложными функциями написанными с использованием sed в sh или bash : #!/bin/sh dos2unix () { sed -i '' -e 's/' \" $( printf '\\015' ) \" '$//' \" $1 \" } unix2dos () { sed -i '' -e 's|$|' \" $( printf '\\015' ) \" '|' \" $1 \" } # Сделать окончания строк LF (Unix) dos2unix file.test # Сделать окончания строк CR/LF (Win or Dos) unix2dos file.test Запустить аналог на sed для dos2unix прямо в консоли можно командой: sed -i '' -e 's/' \"`printf '\\015'`\" '$//' file.name А аналог на sed для `unix2dos прямо в консоли выглядит так: sed -i '' -e 's|$|' \"`printf '\\015'`\" '|' file.name Обработать рекурсивно все php файлы в текущем каталоге: find . -name \"*.php\" -type f -exec sed -i '' -e 's/' \"`printf '\\015'`\" '$//' {} \\; Причины НЕ устанавливать данные консольные утилиты могут быть разными, например невозможность их установить (случай с VPS или web хостингом), спортивный интерес ну или просто лень :)","tags":"Linux","title":"Аналоги на sed для dos2unix и unix2dos"},{"url":"blog/freebsd-pw/","text":"Просмотреть текущее состояние можно командой id id USER Сменить UID : pw usermod metall -u 1005 Сменить GID : pw groupmod metall -g 1005 Или: pw usermod metall -g 1005 Изменить список групп, к которым принадлежит пользователь: pw usermod USER -G vboxusers Или: pw usermod root -G operator,vboxusers Хочу обратить внимание на то, что группа \"по умолчанию\" не изменяется. Например для root такая группа будет wheel и ее указывать не нужно. Например, как добавить пользователя в группу vboxusers : pw usermod USER -G wheel,vboxusers Добавить в группу пользователя (Чаще бывает нужно добавить пользователя в группу, но команда дословно интерпретируется именно так): pw groupmod GROUP -m USER","tags":"FreeBSD","title":"FreeBSD утилита pw, управление пользователями и группами"},{"url":"blog/windows-hdd2hdd-gparted-dd/","text":"На работе часто бывает необходимо перенести или скопировать Windows 7 с одного HDD на другой по разным причинам, умирает HDD или нужно установить HDD с меньшим или наоборот с бОльшим объемом, в общем проблема решается довольно просто, при помощи 2 утилит dd и Gparted . Загружаемся в Ubuntu LiveCD , у меня была загрузка по сети образа Ubuntu 12.04 LTS Desktop . И первым делом копируем главную загрузочную запись ( MBR ): dd if = /dev/sda of = /dev/sdb bs = 512 count = 1 После чего запускаем Ggparted и копируем разделы (она имеется в обычном ISO ). Не забываем проверить флаг boot на 100М байтном разделе. Немного об утилите dd : if=/dev/sda -- i nput f ile (входной файл, в данном случае диск с Windows 7 ) of=/dev/sdb -- o utput f ile (выходной файл, в данном случае диск куда копируем) bs=512 -- b lock s ize ( Внимание ! Операнд count работает с блоками, а не с байтами! 512 блоков) count=1 -- count (количество раз проведения операции копирования буфером) MBR находится в 0 секторе первого раздела жесткого диска и занимает вместе с таблицей разделов ровно 512 байт. Поэтому и размер блока выбираем 512 , а количество count единица - получаем 512 байт. А если нам нужно не весь MBR , а только загрузочный код, который занимает первые 446 байт 0 сектора, то придется изменить размер блока: dd if = /dev/sda of = boot-code.mbr bs = 446 count = 1 Обратите внимание, на то, что сохраняем в файл, т.к. в устройство записать такой объем не получится, как уже говорилось выше, запись на устройства производится блоками по 512 байт. Чтобы теперь записать сохраненный загрузчик, нужно получить блок размером в 512 байт, для этого сохраняем в другой файл таблицу разделов - это оставшиеся 66 байт после загрузочного кода - 446 байт. dd if = /dev/sdb of = part-table.mbr bs = 1 count = 66 skip = 446 skip=n (блоков) Этот операнд пропускает n блоков от начала входного ( if ) файла(устройства), а затем копирует указанное количество блоков. Внимание ! Операнд skip (как и count ) имеет дело с блоками, а не с байтами! Поэтому размер блока следует выбирать вдумчиво. И еще обратите внимание на то, что сейчас мы выбрали устройство /dev/sdb , т.к. нам нужна таблица разделов именно этого устройства, ведь мы туда собираемся копировать загрузчик с устройства /dev/sda :) Теперь нужно \"собрать\" MBR из имеющихся кусочков: cat boot-code.mbr > mbr cat part-table.mbr >> mbr Теперь наконец-то мы можем записать загрузочный код на устройство! dd if = mbr of = /dev/sdb bs = 512 count = 1 Ссылки по теме: Команда dd и её использование. Как мне скопировать загрузочную запись линуха на дискету?","tags":"Windows","title":"Перенос Windows 7 с одного HDD на другой HDD меньшего объема. (dd + Gparted)"},{"url":"blog/grub-ubuntu/","text":"В некоторых версиях Ubuntu почему-то отсутствует файл локализации ru.mo в Grub : ls /boot/grub/locale/ en_AU.mo en_CA.mo en_GB.mo В результате мы видим меню граба на английском языке, хотя при этом язык установлен правильно: cat /boot/grub/grub.cfg | grep lang set lang = ru_RU ВНИМАНИЕ , перед дальнейшими действиями сделайте резервные копии всех модифицированных вами файлов от Grub 'а, например /etc/default/grub или /etc/grub.d/00_header , если вы счастливый обладатель нетбука с чипсетом i915 Ubuntu 11.10 на EeePC разрешение экрана 1024x600 в меню GRUB2 [1] . Чтобы меню граба снова стало на русском, нужно сперва удалить пакет grub-pc : sudo apt-get purge grub-pc Затем снова установить: sudo apt-get install grub-pc Теперь проверяем появился ли ru.mo : ls /boot/grub/locale/ en_AU.mo en_CA.mo en_GB.mo ru.mo Теперь можно перезагрузиться и проверить, что все нормально. P.S. думаю и обычное копирование этого файла с \"рабочей\" системы так же исправит ситуацию, но я такой метод не проверял. Ссылки по теме: Ubuntu 11.10 на EeePC разрешение экрана 1024x600 в меню GRUB2","tags":"Ubuntu","title":"Проблема с grub и русской локализацией в Ubuntu"},{"url":"blog/freebsd-tcp-timewait/","text":"TCP TIME_WAIT состояние характерно для завершающей стадии соединения. Рассмотрим пример: FIN 1 => 2 ACK 1 <= 2 FIN 1 <= 2 ACK 1 => 2 В первой строке хост 1 инициирует завершение соединение отправкой пакета с флагом FIN . Хост 2, получив такой пакет подтверждает его флагом ACK , после чего в свою очередь отправляет хосту 1 свой пакет с флагом FIN и закрывает соединение. С момента получения этого пакета хостом 1, соединение переходит в состояние TIME_WAIT . Это время дается на случай, если последний ACK не дойдет до хоста 2, тогда он снова отправит FIN , на который хост 1 еще раз отошлет ACK . Соединение может еще долгое время находится в состоянии TIME_WAIT , согласно RFC 1323 это время должно равнятся 2 минутам, двум msl ( Maximum Segment Lifetime ). MSL - это время, в течение которого сегмент может путешествовать по сети ( RFC рекомендует 60 секунд ). На загруженном сервере при таком значении msl число соединений time_wait расчет очень быстро, к тому же упомянутый RFC составлялся достаточно давно и пропускная способность каналов с тех пор возросла многократно, поэтому многие уменьшают это значение. Во FreeBSD есть переменная sysctl net.inet.tcp.msl , по умолчанию равная 30 секундам . Можно уменьшить его до 20 или даже 15 секунд . echo \"net.inet.tcp.msl=15000\" >> /etc/sysctl.conf /etc/rc.d/sysctl start В Linux немного сложнее, там msl спрятано в ядре в файле /net/tcp.h #define TCP_TIMEWAIT_LEN (60*HZ)","tags":"FreeBSD","title":"Уменьшение количества соединений в состоянии TCP TIME_WAIT"},{"url":"blog/jupiter-ubuntu-1110/","text":"Jupiter — апплет, разработанный для нетбуков и ноутбуков. Он позволяет переключаться между максимальной/высокой производительностью и энергосберегающим режимом, менять разрешение экрана и ориентацию, включать/отключать bluetooth , тачпад, WiFi и т.д. Если вы владелец нетбука ASUS EeePC , вам будет полезен отдельный пакет, добавляющий поддержку SHE ( ASUS Super Hybrid Engine ) и ряда тонких настроек EeePC . Но в нем есть одна проблема, при включении/отключении WiFi отображается неверный статус - WIFI Radio Off . Проблема заключается в том, что разработчики программы Jupiter используют неверные пути /sbin/rfkill в скриптах /usr/lib/jupiter/scripts/bluetooth , /usr/lib/jupiter/scripts/wifi чтобы исправить ошибку в Jupiter при работе с Wi-Fi в Ubuntu 11.10 нужно исправить в скриптах пути до rfkill , а лучше заменить /sbin/rfkill на $(which rfkill) - это более универсальный способ и работа скриптов не будет зависеть от версии Linux , либо смириться с текущим положением дел и выполнить в терминале такую команду: sudo ln -s /usr/sbin/rfkill /sbin/rfkill Такой вариант пока предпочтительнее, потому как при обновлении ОС, ваши изменения могут быть потеряны, и придется все повторить. Теперь исправляем проблему с файлом /usr/lib/jupiter/scripts/notify . Проблема связана с командой who в Ubuntu 11.10 , которая работает несколько иначе, чем в предыдущих выпусках. Открываем файл /usr/lib/jupiter/scripts/notify и ищем строку: USER = $( who -u | sed -n '/ (:0[\\.0]*)$\\| :0 /{s/ .*//p;q}' ) Заменяем ее на: USER = $( users /var/log/wtmp | sed 's| |\\n|g' | uniq ) И еще одну строку: USERCNT = $( who | wc -l ) заменяем на: USERCNT = $( users /var/log/wtmp | sed 's| |\\n|g' | uniq | wc -l ) Открываем еще один файл /etc/acpi/actions/eeepc-actions.sh и ищем строку: EEE_USER = $( who | sed -n '/ (:0[\\.0]*)$\\| :0 /{s/ .*//p;q}' ) Приводим к такому виду: EEE_USER = $( users /var/log/wtmp | sed 's| |\\n|g' | uniq ) Теперь при отключении Wi-Fi будут отображаться верные статусы: Очень надеюсь, что разработчики этой программки, исправят ситуацию, и данный прием не нужно будет применять. Если у вас нетбук Asus EeePC , также установите пакет jupiter-support-eee — необходимо для SHE ( Super Hybrid Engine ): sudo apt-get install jupiter-support-eee Если вы работаете в Unity , после первого запуска Jupiter вам необходимо перезайти, чтобы увидеть иконку апплета в области уведомлений. Конечно, в том случае, если в whitelist не занесен весь системный трей.","tags":"Ubuntu","title":"Jupiter на Ubuntu 11.10 и исправление проблем с ним."},{"url":"blog/qutim-02-ubuntu-1110/","text":"У qutim 0.2 в Ubuntu 11.10 Oneric Ocelot есть одна серьезная проблема, при закрытии окна со списком контактов его невозможно вызвать стандартными средствами. Контекстное меню трея панели индикаторов позволяет лишь открыть окно настроек или сменить статус. Опции \" показать список контактов \" или \" Открыть \" или чего-либо подобного нету. Контекстное меню открывается одинаковое и по правой, и по левой кнопке мыши. Фишка в том что qt -приложения в юнити рисуют иконку в трее через dbus и являются уже не обычными иконками в трее, а \" индикаторами \" гнома, отсюда и проблемы с исчезновениями иконки. Помогает либо перезапуск qutIM , либо стараться не закрывать, а сворачивать список контактов, что весьма неудобно в работе. Чтобы исправить ситуацию - нужно создать файл ~/.config/sni-qt.conf со следующим содержимым: [need-activate-action] qutim = 1 После чего придется перезапустить qutim , в контекстном меню появится пункт \" Активировать \", который будет работать как клик левой кнопкой мыши в обычном трее.","tags":"Ubuntu","title":"Список контактов qutim 0.2 в Ubuntu 11.10"},{"url":"blog/grub-linux-intel-915-1024x600/","text":"Как известно в нетбуках EeePC 1000 и им подобным используется чипсет i915 , максимальное разрешение матрицы такого нетбука 1024x600 . По умолчанию GRUB не умеет работать с таким разрешением, но ситуацию можно исправить, для этого существует специальный модуль GRUB 'а 915resolution.mod , с ним и будем работать. Чтобы установить разрешение экрана в меню GRUB 'а 1024x600 на EeePC 1000 и им подобным, выполняем следующее: Открываем файл /etc/grub.d/00_header : sudo mcedit /etc/grub.d/00_header Находим кусок кода: cat << EOF if loadfont `make_system_path_relative_to_its_root \"${GRUB_FONT_PATH}\"` ; then set gfxmode=${GRUB_GFXMODE} load_video insmod gfxterm EOF И приводим его к такому виду: cat << EOF if loadfont `make_system_path_relative_to_its_root \"${GRUB_FONT_PATH}\"` ; then # Fix resolution for EeePC: BEGIN insmod 915resolution 915resolution 5c 1024 600 # Fix resolution for EeePC: END set gfxmode=${GRUB_GFXMODE} load_video insmod gfxterm EOF Затем нужно обновить конфигурацию GRUB 'a командой: update-grub После проделанных манипуляций меню GRUB 'а будет иметь разрешение 1024x600 . Если просто загружать модуль 915resolution.mod , то разрешение не будет установлено, так как модуль будет просто загружен, а вот команда GRUB 'а 915resolution 5c 1024 600 выполнена не будет, а значит и разрешение не будет установлено, хотя оно станет доступным для ручной установки из командной строки GRUB . Способ с загрузкой модуля через конфиг НЕ подходит: GRUB_PRELOAD_MODULES = \"915resolution\" Бонус! Теперь самое время установить фоновую картинку в меню. Создаем картинку my_image.png размером 1024x600 и сохраняем ее в домашнем каталоге. Затем в терминале выполняем команды: sudo mkdir -p \"/usr/share/images/desktop-base/\" sudo cp my_image.png \"/usr/share/images/desktop-base/desktop-grub.png\" После этих команд картинку из домашнего каталога по желанию можно удалить, это никак не скажется на работе GRUB 'a. P.S. путь до картинки подсмотрел командой: cat /etc/grub.d/05_debian_theme | grep '.png' | grep 'usr' if set_background_image \"/usr/share/images/desktop-base/desktop-grub.png\" ; then Или можно воспользоваться более человечным способом: Добавляем в файл /etc/default/grub : # Grub Background GRUB_BACKGROUND = /путь/до/картинки P.S. Данный способ подошел и для ноутбука HP Compaq 6710b с разрешением 1280x800 и графическим адаптером GM965/GL960 Про /etc/grub.d/40_custom знаю, но вот беда, как пишут тут [1] у меня не заработало. Скорей всего потому, что все необходимые модули для работы видео в GRUB были загружены прежде (как раз то место, где я добавлял строки в /etc/grub.d/00_head ), чем сработал скрипт /etc/grub.d/40_custom , т.к. строки из него добавляются в самом конце grub.cfg . Поэтому мой метод наиболее предпочтителен, но при обновлении скрипта /etc/grub.d/00_head потребуется вновь его отредактировать. Ссылки по теме: AspireOne/AO751h","tags":"Ubuntu","title":"Ubuntu 11.10 на EeePC разрешение экрана 1024x600 в меню GRUB2"},{"url":"blog/freebsd-linux-external-ip/","text":"Бывает необходимость быстро узнать через какой ip выходит в интернет тот или иной сервер к которому вы подключены, ниже приведен простой способ решения данной задачи. Так как во FreeBSD в стандартной комплектации нет wget , но зато есть fetch , команда будет такой: fetch -qo - http://checkip.dyndns.org/ | grep -Eo '\\<[[:digit:]]{1,3}(\\.[[:digit:]]{1,3}){3}\\>' А для Linux подойдет вариант с wget : wget -qO- http://checkip.dyndns.org/ | grep -Eo '\\<[[:digit:]]{1,3}(\\.[[:digit:]]{1,3}){3}\\>' Еще один вариант с curl , может подойти для обоих платформ, если конечно установлен: curl -so- http://checkip.dyndns.org/ | grep -Eo '\\<[[:digit:]]{1,3}(\\.[[:digit:]]{1,3}){3}\\>'","tags":"Linux","title":"FreeBSD, Linux узнать внешний ip адрес с консоли."},{"url":"blog/ubuntu-usb-hdd-ntfs/","text":"Если при подключении внешнего USB HDD с файловой системой ntfs диск доступен только в режиме чтения, вероятнее всего не установлен пакет ntfs-3g apt-get -y install ntfs-3g После этого USB HDD с ntfs на борту будут монтироваться автоматически и в режиме записи.","tags":"Linux","title":"Ubuntu 11.10 USB HDD NTFS только в режиме чтения"},{"url":"blog/ubuntu-man/","text":"В Ubuntu есть некоторые маны на других языках. Все английские маны лежат в каталоге /usr/share/man/man{1..8} . А маны на других языках располагаются в /usr/share/man/ЯЗЫК/man{1..8} . У утилиты man есть ключ -L , которому передается нужный язык. Почитаем man mc на русском: man -L ru mc В репозиториях есть даже специальный пакет manpages-ru , установим его: sudo apt-get install manpages-ru Теперь у вас в системе русских man 'ов стало больше. :)","tags":"Linux","title":"Ubuntu и русские man'ы"}]}